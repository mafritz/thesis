# Emotional Awareness Tools in Computer-Mediated Learning Environments: Overview, Assumptions, Mechanisms, and Methodological Issues

```{r rationale-eat-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)

```

Whereas the previous chapter provided a *bona fide* overview of the growing consensus in integrating affective phenomena into computer-mediated learning environments, this chapter delves more specifically into the topic of emotional awareness in computer-mediated learning environments. This chapter provides an overview of different aspects, as well as their intrinsic complexity, that must be faced when considering aims and means of endowing a computer-mediated learning environment with explicit emotional awareness. The chapter starts with an overview of a selection of related works. The selected works serve as a basis from which, later in the chapter, three basic assumptions about an Emotion Awareness Tool (EAT) are deduced. From these assumptions, then, the chapter proposes a schema, in which different mechanisms at play in the implementation of an EAT in computer-mediated learning environments are organized in functional terms. At the end of the chapter, some methodological issues are raised.


The previous chapter has provided an overview of the different concepts that are at play when affective phenomena are intertwined with learning in general, and computer-mediated learning environments more specifically. Determining the boundaries of related work in such a fervent and dynamic *milieu* is not an easy task. The objectives, methods, learning settings, and technologies implemented may vary greatly on a case-by-case basis. This section therefore provides an overview of selected works in the past ten years that share some common ground with the purpose of the present contribution. More specifically, (1) they make use of *some form* of voluntary and explicit expression of affective phenomena ; and (2) they refer to a context that may be broadly related, either for the aim or for the conditions, to computer-mediated learning environments. As previously stated, the field of affective and emotion aware systems in computer-mediated learning environments is recent and spans many disciplines, which complicates the adoption of a more systematic review of the existing literature. Furthermore, the selected works will be used as abstraction to extrapolate a more general and multipurpose approach to emotional awareness in computer-mediated learning environments rather than a confirming direction to follow-through. Contributions are presented chronologically, even though connections and progressive enhancement of previous work is quite limited.

## Definition of Emotional Awareness in Computer-Mediated Learning Environments

Emotional awareness in computer-mediated learning environments is often proposed in the literature as self-explaining or defined somehow implicitly. For instance, as stated in the previous chapter, Feidakis and colleagues [-@feidakisReviewEmotionAwareSystems2016, p. 217] define emotion awareness, mainly from a *technical* viewpoint, as "the *implicit* or *explicit collection of emotion data* and the *recognition* of *emotion patterns*" (italics in the text). Cernea and colleagues [-@cerneaSurveyTechnologiesRise2015], in their overview of rising technologies in emotion-enhanced interaction, identifies the category of affective-aware systems as "designed to improve affective self-awareness of a user (i.e.,internal affective awareness) or awareness of the emotions of other users (i.e.,external affective awareness)" (*ibid.*, p.78). Examples of more precise attempts of definitions are provided by Lavoué and colleagues [-@lavoueEmotionAwarenessTools2020], who propose different definitions, partially derived from clinical psychology. They first propose a definition based upon @bodenFacetsEmotionalAwareness2015, which identifies emotional awareness as "the ability to perceive, identify, and understand emotions" [@lavoueEmotionAwarenessTools2020, p. 270]. Later in their article, Lavoué and colleagues (*ibid.*) propose another definition, based upon Rieffe and colleagues [-@rieffeEmotionAwarenessInternalising2008], referring to emotional awareness as "the attentional process by which individuals identify, explain and differentiate between their own emotions as well as the others' emotions" [@lavoueEmotionAwarenessTools2020, p. 270]. These two definitions resonate with socio-emotional competences briefly illustrated in the previous chapter. Finally, even further below their article, Lavoué and colleagues (*ibid.*) provide a more technical definition of emotion awareness tools: "[e]motion awareness tools can be defined as tools that display information on own' own [sic] or partners' emotions, circumstances and antecedents" [@lavoueEmotionAwarenessTools2020, p. 284]. Compared to the more abstract definition of Feidakis and colleagues (*ibid.*), Lavoué and colleagues (*ibid.*) imply that the tool shall also provide information about circumstances and antecedents.

## Emotional Awareness at the Intra-Personal Level

The first assumption about the instrumentality of emotional awareness implies that learners can benefit from it at the individual, intra-personal level.

### Theoretical Underpinnings

The role of emotion at the individual and intra-personal level has received over the last few decades extensive consideration from different perspectives and using different methods of investigation. A widespread consensus has emerged over the years about the fact that emotion, rather then disruptive of behavior and in antithesis with cognition, plays a prominent role in helping the organism to cope with a complex environment [@adolphsNeuroscienceEmotionNew2018; @armonyCambridgeHandbookHuman2013; @damasioDescartesError2006; @damasioStrangeOrderThings2018; @schererEmotionTheoriesConcepts2009; @immordino-yangEmotionsLearningBrain2016; @levensonAutonomicNervousSystem2014; @levensonIntrapersonalFunctionsEmotion1999; @leventhalRelationshipEmotionCognition1987; @pessoaCognitiveemotionalBrainInteractions2013; @sanderModelsEmotionAffective2013]. 

For instance, emotion is known to influence high-level cognitive functions such as attention, perception, memory, and decision-making [@broschImpactEmotionPerception2013], which are all implicated in learning processes. A large body of research suggests that a dedicated system to emotional attention may complement and interact with the exogenous and endogenous systems [@broschAdditiveEffectsEmotional2011]. Emotionally charged stimuli are often bestowed precedence in perception  [@broschPerceptionCategorisationEmotional2010]. Many links between emotion and memory have been established both in the encoding and retrieving of information [@sharotHowArousalModulates2004; @kensingerRetrievalEmotionalEvents2020], which may have important consequences on learning [@beegeMoodaffectCongruencyExploring2018; @tyngInfluencesEmotionLearning2017]. Finally, it has been determined that when emotion is not taken into account in decision-making, consequences can be highly disruptive for the person, since emotion may inform decision-making in functional terms [@becharaRoleEmotionDecisionmaking2004; @rollsEmotionDecisionmakingExplained2014]. 

Emotional awareness, though, goes a step forward in considering the importance of emotion at the intra-personal level, because it presupposes that learners can benefit from being aware of their emotions, adding therefore an additional layer of conscious information processing. Whether consciousness is a necessary condition for emotion to exist [@ledouxHigherorderTheoryEmotional2017; @liebermanBooConsciousnessProblem2019] is a debate outside the scope of the present contribution (see also next chapter): the use of voluntary self-report pragmatically requires consciousness for emotional awareness to emerge in the first place and therefore *dodges* the issue. Conscious processing derived from emotional awareness has been related more specifically to three overlapping factors in learning processes [@lavoueEmotionAwarenessTools2020]: emotion as useful information to direct or redirect cognitive resources; emotion as useful information to assess and guide learners' interest and motivation; and emotion as useful information to regulate one's own behavior, including one's own emotions. 

Learners may use their achievement, epistemic and topic emotions as useful cues to evaluate and direct cognitive processes [@pekrunControlValueTheoryAchievement2014]. The work of D'Mello and colleagues [-@dmelloConfusionCanBe2014], for instance, highlights how confusion is a signal of cognitive disequilibrium, which learners are therefore incited to re-balance. The work of Vogl and colleagues [-@voglSurpriseCuriosityConfusion2019] about the role of epistemic emotions suggests that experience of curiosity, pride and shame may inform learners about different reasons for knowledge exploration. 

Awareness of one's emotions may prompt learners to assess their motivation to keep engaged or disengage from a learning activity [@linnenbrink-garciaAdaptiveMotivationEmotion2016]. For instance, Baker and colleagues' work [-@bakerBetterBeFrustrated2010] draws attention on the importance of recognizing boredom and frustration as warnings of inefficient and potentially misleading efforts. 

A field of study that has received widespread attention is that of emotion regulation [@grossEmotionRegulationCurrent2015a; @grossHandbookEmotionRegulation2014], a process which, when performed explicitly rather than implicitly [@torrePuttingFeelingsWords2018], requires the person to be aware of the emotion to be regulated.  


### Related Works

## Emotional Awareness in Co-Regulation and Social Regulation of Learning

### Theoretical Underpinnings

Whereas the intra-personal function of emotion has received extensive attention in the last few decades, several researchers have more recently advocated the need for investigating the inter-personal function of emotion, especially in social interactions [@parkinsonEmotionSocialRelations2005; @rimePartageSocialEmotions2005; @vankleefInterpersonalDynamicsEmotion2018; @fischerWhereHaveAll2010]. Fisher and Van Kleef [-@fischerWhereHaveAll2010], for instance, posit that

> [i]t is an indisputable fact that emotions are mostly reactions to other people, that emotions take place in settings where other people are present, that emotions are expressed towards other people and regulated because of other people. It is hardly possible to imagine the elicitation of anger, shame, sadness, happiness, envy, guilt, contempt, love, or hatred without imagining other people as cause, target, or third-party observer of these emotions. In other words, the social constitution of emotions is beyond doubt -- @fischerWhereHaveAll2010, p. 208.

Keltner and Haidt [-@keltnerSocialFunctionsEmotions1999] identify four level of analysis in which emotion play a social function: (1) the individual level, whenever the source of the emotion is of a social nature -- which, for some scholars, means most if not all of the time [@fischerWhereHaveAll2010; @parkinsonEmotionsAreSocial1996; @rimeEmotionElicitsSocial2009]; (2) the dyadic level, such as in direct dialogue or collaboration; (3) the group-level, in which people share common identities and goals to attain; and (4) the cultural level, where the analysis focus on macro-elements such as history and tradition. A recent overarching synthesis on the social function of emotions across all levels proposed by Fischer and Manstead [-@fischerSocialFunctionsEmotion2016] identifies two complementary, but distinct, functions performed by emotions: affiliation and distancing. The affiliation function serves to form and maintain positive social relationship with others, whereas the distancing function helps in establishing and maintaining a social position relative to others (*ibid.*). Other social functions of emotions comprise the spontaneous tendency of people to share their emotions with others [@rimeEmotionElicitsSocial2009; @rimePartageSocialEmotions2005], the use of emotional information to better understand behavior and appropriate conduct in social situations [@parkinsonEmotionsInterpersonalInteractions2010; @vankleefHowEmotionsRegulate2009], or situation in which people voluntary attempt to act upon emotions in others [@netzerInterpersonalInstrumentalEmotion2015; @reeckSocialRegulationEmotion2016; @zakiInterpersonalEmotionRegulation2013].

### Related Works
The first contribution of interest as a related work is by Eligio, Ainsworth and Crook [-@eligioEmotionUnderstandingPerformance2012]. The authors highlight that awareness in computer-mediated collaboration focused primarily on behavioral and social functioning, whereas the affective dimension received at that time less attention. Eligio and colleagues (*ibid.*) therefore set forth two experiments aiming at exploring "what collaborators understand about each other's emotions and the implications of sharing information about them" (*ibid*, p. 2046).

In the first experiment, the authors asked pairs of same-sex, unacquainted participants to play a collaborative game in a co-located environment, where they shared the same computer equipment. At the end of the collaboration, participants were asked to fill in two questionnaires where they had to rate the intensity of 15 emotions: *happy*, *angry*, *sad*, *fearful*, *angry*, *bored*, *challenged*, *interested*, *hopeful*, *frustrated*, *contempt*, *disgusted*, *surprised*, *proud*, *ashamed* and *guilty*. In the *own* version of the questionnaire, they rated the intensity of each emotion as they have perceived it during the task. In the *partner* version of the questionnaire, participants had to project the intensity by which their partner in the dyad had experienced each of the listed emotion. The administration of the questionnaire was made individually, so that participants could not discuss the matter with their partner, and up until that moment, participants were not informed of the rating, so that they had no particular reason to pay attention to emotions. Comparison of consistency between the two questionnaires highlighted that, despite collaborating side-by-side, participants had little understanding of their partner's emotions. On the contrary, consistently with previous findings in the literature [@kruegerTrulyFalseConsensus1994; @tomaAnticipatedCooperationVs2010], participants tended to project their own emotional experience onto their partners. Eligio and colleagues (*ibid*) provides two possible explanations of the results. On the one hand, participants could simply not care about the emotions of their partner. On the other hand, participants could genuinely care about them, but lacked the means to focus on them, for instance because the task was too demanding, and they therefore decided to prioritize other mental states perceived as *more* instrumental to the task at hand. In both cases, the attribution of their own emotional experiences to the partner is caused by a lack of information available, but the reasons for this shortcoming are not the same depending on the intentions.

In the second experiment, Eligio and colleagues (*ibid*) therefore decided to intervene by providing (or not) participants with explicit awareness of their partner's emotions using a *scripting* strategy, that is, by interrupting the collaboration at specific moments for participants to express their emotions and projecting that of their partner. After filling the *own* and *partner* questionnaire, if participants disposed of awareness, they could look at the emotions of their partner's before resuming the task, otherwise they just continued with the collaboration. Furthermore, dyads were also assigned either in a co-located or a remote collaborative setting, resulting in a 2x2 factorial design with awareness vs. no-awareness, and co-located vs. remote conditions. Using experimental conditions similar to the ones of the first experiment (but with a slightly different collaborative task and with only women ), the authors found evidence suggesting that participants benefited of emotional awareness in terms of performance both in the co-located and remote conditions. Furthermore, participants in the remote condition were more accurate in understanding emotions of their partner and also experienced more *positive affect* (computed by averaging the intensity of *happy*, *interested*, *hopeful*, *excited* and *challenged*).

From the two experiments, Eligio and colleagues (*ibid.*) concluded that participants do not have an accurate understanding of the emotion of their partner if their attention is not explicitly driven to it. Providing emotional awareness seems thus a promising way to increase mutual modeling (even though Eligio and colleagues do not use the term in their article), especially in remote situations.

## Emotion in Computer-Mediated Learning Environments

### Theoretical Underpinnings

### Related Works

## Abstract Model of the Functions of an Emotion Awareness Tool

The information illustrated above, as well as in the previous chapter, can be integrated in an abstract model that depicts the mechanisms allegedly carried out by an EAT. The proposed abstract model does not have the pretension to establish an absolute reference; on the contrary, it aims at visually implementing the different passages that are (or may be) assumed in the instrumentality of an EAT as a support to learning activities in computer-mediated environments. The model, depicted in Figure \@ref(fig:intro-thesis-scm-model-figure), take the perspective of a learner that disposes of an EAT in its computer-mediated learning environment. The model comprises boxes for four conceptual elements: (a) the learning activity, which may refer broadly to any computer-mediated environment implementing an instructional design; (b) intra-personal emotion, representing a single event or a set of events corresponding to the learners' expressed-displayed emotions; (c) inter-personal emotion, representing a single event or set of events corresponding to emotions expressed-displayed by other learners sharing the same environment, that the learner herself can therefore perceive-monitor; and (d) an overarching *meaning-making* process, which encompasses learner's effort to extrapolate instrumental information from the emotional information available. The boxes are connected with directional arrows, numbered from 1 to 7, representing a series of processes that are (or may be) implicated in each passage. The numbers are used for identifying the passages, but do not imply a fixed order, even though some processes may be built upon previous passages. The next sections provides a discussion of each passage (*i.e.*, each numbered arrow) more specifically.

(ref:thesis-scm-caption) The EAT determines how an intra-personal emotion becomes inter-personal, and how the inter-personal emotions contribute to improve the shared understanding of the situation at hand. The situation may then trigger other intra-personal emotions.

```{r intro-thesis-scm-model-figure, fig.cap="(ref:thesis-scm-caption)", fig.align="center", out.width="100%" }
include_graphics(here("figure/intro/thesis-scm-model.png"))
```

### From the Learning Activity to Intra-Personal Emotion

Passage \#1 goes from the learning activity to an intra-personal emotion, implicating that the learning activity elicits emotions in oneself. An EAT may intervene in this passage in several ways, grouped here in a non exhaustive lists of X phenomena labeled for illustration purpose as *emotion alertness* and *emotion conceptualization*.

Emotion alertness broadly refers to the fact that the presence of the EAT represents a general reminder about paying attention to emotion during the learning activity, and therefore may increase the *sensitivity* about emotional experience. In other words, the presence of the EAT may push learners to bestow to emotional self-awareness more attention that they would normally do without the presence of the EAT [@brackettRULERTheoryDrivenSystemic2019; @lavoueEmotionAwarenessTools2020; @molinariEmotionFeedbackComputermediated2013]. Emotion alertness may be induced to different degrees, depending on, for instance, whether the EAT is always available or not, and whether explicit prompts are frequently sent to learners [@csikszentmihalyiValidityReliabilityExperienceSampling2014; @shiffmanEcologicalMomentaryAssessment2008]. As an example, Molinari and colleagues [-@molinariEmotionFeedbackComputermediated2013] implemented an EAT into a computer-mediated collaborative task that reminded participants to self-report their emotions after five minutes since the last emotion expressed.

Emotion alertness is not necessarily and automatically linked to concrete action of emotion display, that is, self-reporting the emotion into the system. In fact, even in the case of an increased alertness, learners could genuinely not feel any emotion, or decide not to express their emotion through the EAT for dispositional (*e.g.*, emotional expressivity, see @kringIndividualDifferencesDispositional1994) or contingent reasons (*e.g.*, bestow priority to the learning task at hand).

Emotion conceptualization broadly refers to the mechanisms by which learners are planned to self-report their emotions, which may vary greatly according to a number of theoretical and technical aspects. For instance, emotion self-report tools or questionnaires are very often divided in two categories, depending on whether they adopt a dimensional or a discrete perspective [@broekensAffectButtonMethodReliable2013; @fuentesSystematicLiteratureReview2017; @ritchieEvolutionSelfreportingMethods2016; @schererWhatAreEmotions2005].

In a dimensional approach, an emotion is conceptualized as a rating on a number of continuous criteria, among which the most frequently adopted ones are *valence* (also called *pleasure*) and *arousal* (also called *activation*) [*e.g.*, @russellCircumplexModelAffect1980; @stanleyTwodimensionalAffectiveSpace2009], but may also comprise different or additional dimensions. It is the case, for instance, of the Self-Assessment Manikin [@bradleyMeasuringEmotionSelfAssessment1994] or the AffectButton [@broekensAffectButtonMethodReliable2013], which both use the *valence*, *arousal*, and *dominance* dimensions, even if in different formats. The Self-Assessment Manikin [@bradleyMeasuringEmotionSelfAssessment1994] uses three rows of figures (*i.e.*, the *manikin*), where each rows represent one of the three dimensions. For each row, 5 figures, progressively modified in some features, represent the increasing or decreasing value on the specific dimension. The AffectButton [@broekensAffectButtonMethodReliable2013], on the other hand, uses a single iconic facial expression that changes according to the user's coordinates of the mouse on the surface of the icon: the horizontal movement determines the pleasure dimensions; the vertical movement the dominance dimension; and the arousal dimension is calculated according to the distance of the mouse from the central point of the image.

In a discrete approach, an emotion is conceptualized as a distinctive experience that can be identified through a verbal and/or graphical representation [@mortillaroEmotionsMethodsAssessment2015]. The number, kind and organization of the representations varies depending on several aspects. In the case of verbal representations that adopts natural language nouns or adjectives, for example, the list may be determined according to emotion theories -- as in the case of basic emotion theory [@ekmanArgumentBasicEmotions1992] -- or determined empirically according to previous (or pilot) studies, often with the aim of retaining a list of the most frequently experienced or expressed items. For instance, Molinari and colleagues [-@molinariEmotionFeedbackComputermediated2013] implemented in a self-report interface 20 buttons, 10 labeled with negative and 10 with positive emotion adjectives retrieved among the most frequently expressed during a computer-mediated collaborative task in a pilot study. The interface also provided -- as it is considered a good practice [@mortillaroEmotionsMethodsAssessment2015; @schererWhatAreEmotions2005] -- the possibility to provide another emotion not in the list. When emotion is conceptualized graphically, representations usually attempt at maintaining some degree of analogy with *reality*, for instance with respect to facial expressions [@desmet2003measuring; @lauransNewDirectionsNonVerbal2012].

Less frequently, self-report tools attempt to combine the two approaches, as it is the case in the Geneva Emotion Wheel [@schererGRIDMeetsWheel2013; @schererWhatAreEmotions2005], depicted in more details in the next chapter, or the Mood Meter application associated with the RULER approach [@brackettRULERTheoryDrivenSystemic2019] mentioned in the previous chapter. When the dimensional and discrete approaches coalesces, they create an underlying structure, which is often referred to as an *affective space* [*e.g.*, @davidsonParsingAffectiveSpace19940101; @gilliozMappingEmotionTerms2016; @schererWhatDeterminesFeeling2006; @stanleyTwodimensionalAffectiveSpace2009]

The Mood Meter application ...

The emot-control system implemented by Feidakis and colleagues [-@feidakisProvidingEmotionAwareness2014] shows on the same interface (a) a circumplex of 14 discrete affective states, represented by stylized, and colored faces similar to smileys/emoticons, organized according to the valence x activation orthogonal axis; (b) 5 additional images of similar kind, but representing moods in a sort of 5-point Likert scale (*sad*, *unhappy*, *neutral*, *happy*, and *very happy*); (c) a free text input to type-in another emotion not listed; and (d) another free text input introduced by the field legend *Write more about your feelings*.

Depending on how emotion is conceptualized and, by extension, planned for self-report, the intra-personal awareness of emotion may be more or less guided, inducing learners to pay attention to some elements of their emotional experience that they will not necessarily consider in the same way, or with the same weight, depending on the specifics of the EAT at hand. At the same time, emotion self-report also depends on the learner herself, for instance in terms of her ability to discriminate between emotion ... ...

### From Intra-Personal Emotion to Meaning-Making

Once an emotion or a set of emotions are self-reported, it is assumed that learners may extrapolate meaning from the emotional information available. In this regard, information may be punctual, for example the last emotion or set of emotions displayed concurrently. Conversely, the system may also implement some form of data persistence, which allows to observe the accumulation and the evolution of the emotional experience over a varying time span. Depending on the way emotion information is also graphically represented, emotional meaning-making can be guided by the system, which may privilege some form of representation (*e.g.*, changes over time) over another (*e.g.*, cumulative frequency of the same emotion expressed).

Meaning-making is also tightly related to the way emotion is displayed through the system (passage \#1), not only from a technical standpoint -- since the information available is determined by what information is inserted into the system -- but also conceptually. If emotion is considered from a dimensional standpoint, learners will extrapolate meaning from the extant criteria through which dimensions are rated. On the contrary, in a discrete emotion approach, learners extrapolate meaning from an *information unity* that is supposed to provide unique meaning compared to other possible choices. Finally, if the system combines dimensional and discrete approach, learners can extrapolate meaning from both.

The system may also influence meaning-making by adding contextual information to the way emotion is displayed. For instance, Molinari and colleagues [-@molinariEMORELOutilReporting2016] developed a self-reporting system from an Experience Sampling Method [@csikszentmihalyiValidityReliabilityExperienceSampling2014] perspective, the EMORE-L (EMOtion REport for E-Learning), which combine a discrete emotion approach with a series of contextual questions that learners are asked before and after selecting one or more discrete emotions between 8 possible choices, plus a neutral option. The system proposes 8 corollary questions spanning (a) situational aspects, *e.g.*, what they were doing; (b) evaluative circumstances, *e.g.*, to what extent learners felt in control of the situation; (c) social implications, *e.g.*, to what extent learner wishes to share her experience with other colleagues; and (d) mutual-modeling perspective, *i.e.*, does the learner know what other are experiencing, and does she thinks her colleagues know what she is experiencing.

### From the Learning Activity to Inter-Personal Emotion

Passage \#3 starts a complementary path with respect to passages \#1 and \#2, but from an inter-personal perspective, that is, concerning emotion in others learners sharing the same computer-mediated learning environment with the learner herself. This path may in fact be optional when the EAT is exclusively concerned with emotion self-awareness [*e.g.*, @lavoueEmotionAwarenessTools2020], whereas it becomes an integral part when the EAT is inspired from a Group Awareness Tool perspective [*e.g.*, @avrySharingEmotionsContributes2020; @eligioEmotionUnderstandingPerformance2012; @feidakisProvidingEmotionAwareness2014; @molinariEmotionFeedbackComputermediated2013].

### From Inter-Personal Emotion to Meaning-Making

Passage \#4 consists in extrapolating meaning from the emotion of other learners sharing the same computer-mediated learning environment and whose emotions have been monitored by the learner herself.

### From Intra-Personal Emotion to Inter-Personal Emotion

Expression of emotion: emotion is made available to others depending on learners willingness to disclose their emotional experience.

Emotion influence.

Emotion sharing.

### From Inter-Personal Emotion to Intra-Personal Emotion

Emotion comparison (e.g. affiliation or differentiation). Emotion contagion.

### From Meaning-Making to the Learning Activity

Emotion is integrated into the learning activity, it modifies behavior (self-regulation, co-regulation, socially shared regulation).

Modification of learning activity can trigger another emotion, creating cycle.

## Methodological Issues

For instance, Pekrun and Linnerbrink-Garcia [@pekrunIntroductionEmotionsEducation2014, p. 2] point out that "[i]n the broader education literature, affect is often used to denote a broad variety of noncognitive constructs including emotion but also including self-concept, beliefs, motivation, and so on [...]. In contrast, in emotion research, affect refers to emotions and moods more specifically".

## Synthesis