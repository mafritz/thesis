# Emotion Awareness in Asynchronous and Individual Settings

```{r s2-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)

Sys.setenv(LANG = "en")

# Load the relevant data and graphs from the study-1 folder
source(here("data", "study-2", "s2-export.R"))
```

The study illustrated in the previous chapter suggests the presence of a genuine interest in the use of an Emotion Awareness Tool (EAT) in a real-time, computer-mediated collaborative task. Nevertheless, this does not exclude the possibility that emotional awareness may be beneficial above and beyond these conditions, for instance in asynchronous and individual conditions. It is in fact widely accepted that one of the main drawbacks in remote learning is the lack of social presence: learners often feel alone, without any contact with their colleagues [*e.g.*, @jacquinotApprivoiserDistanceSupprimer1993; @paquelinDistanceQuestionsProximites2011; @parkinsonEmotionsDirectRemote2008; @sungFiveFacetsSocial2012]. An interest towards an EAT may therefore be motivated by the fact that emotions are used as a *proxy*, a strong reminder that there is someone else *out there*, even without the need to integrate the emotional information as instrumental to task at hand [@buderGroupAwarenessTools2011; @dourishAwarenessCoordinationShared1992]. In this regard, the use of an EAT may contribute to provide learners with a shared understanding of the affective implications of the distance learning conditions. For instance, sharing emotions with their colleagues may, one the one hand, provide useful information as social reference, on the basis of which learners can regulate their own emotions in facing the challenges of remote learning conditions [@fischerSocialFunctionsEmotion2016; @grossEmotionRegulationCurrent2015; @grossHandbookEmotionRegulation2014; @winneWhatStateArt2015]. On the other hand, the affective dimensions created through the EAT may contribute to foster a sense of belonging and cohesion to the group, even in the absence of face-to-face and/or synchronous exchanges [@barsadeGroupAffect2015; @barsadeRippleEffectsEmotional2002; @rimeEmotionElicitsSocial2009; @rimePartageSocialEmotions2005; @salasMeasuringTeamCohesion2015; @parkinsonInterpersonalEmotionTransfer2011; @parkinsonEmotionsDirectRemote2008; @vankleefEmotionalCollectivesHow2015; @vankleefEmotionalInfluenceGroups2017].

This second empirical study will investigate whether real-time collaboration represent a necessary condition for the usefulness of an EAT in distance learning, or whether the social and relational information it conveys can be useful even in an asynchronous and individual condition. In this regard, students of two classes following the same course in a blended Master in Learning and Teaching Technologies will be provided with the possibility to use an EAT during the periods of remote learning, through which they can share their emotional states with all the other members of the class. Their use of the tool and their attitude towards the usefulness of it will be monitored at different time during the semester in order to assess the usefulness of the EAT. In this intent, the chapter also introduces the Emotion Awareness Usefulness (EAU) survey, which is derived from dimensions described in the literature, and aims at investigating to what extent the presence of an EAT is instrumental in understanding, interpreting, and experiencing emotion [@boehnerHowEmotionMade2007].

The end of the chapter provides corollary analyses as a preliminary attempt in investigating whether the adoption, use and perception of the EAT are related to learners' emotional competence [@brackettEnhancingAcademicPerformance2012; @brackettRULERTheoryDrivenSystemic2019; @schererComponentialEmotionTheory2007; @schlegelGenevaEmotionalCompetence2018]. A link between three sub-competences -- namely the appraisal, the communication, and the regulation competences [@schererComponentialEmotionTheory2007] -- and the use of an EAT is also proposed.

By implementing the use of an EAT in longitudinal, collective, and ecological settings, the present chapter aims at investigating the adoption, use and perception of an EAT by learners in remote learning environment. The present chapter may therefore be of interest to the broader field of distance learning and, more specifically, to the investigation of the relationship between affective states and technology enhanced learning [@arguedasOntologyEmotionAwareness2015; @bakerBetterBeFrustrated2010; @dmelloDynamicsAffectiveStates2012; @dmelloSelectiveMetaanalysisRelative2013; @lehmanConfusionComplexLearning2012; @reisAffectiveStatesComputersupported2018; @reisAffectiveStatesCSCL2015]. The chapter also investigates emotions at the group level [*e.g.*, @barsadeRippleEffectsEmotional2002; @cheshinAngerHappinessVirtual2011; @keltnerSocialFunctionsEmotions1999; @parkinsonEmotionSocialRelations2005; @smithCanEmotionsBe2007; @vankleefEmotionalCollectivesHow2015; @vankleefEmotionalInfluenceGroups2017] and may therefore be of interest in studies using groups as unit of observation.

## Study Overview

At the origin, awareness in Computer-Supported Cooperative Working (CSCW) was limited to cues about the presence of other co-workers: whether they were online and on what they were working on [@grudinComputerSupportedCooperativeWork1994; @gutwinDescriptiveFrameworkWorkspace2002; @gutwinWorkspaceAwarenessRealtime1996]. Progressively, awareness has assumed a broader perspective and, especially in computer-mediated collaboration and Computer-Supported Collaborative Learning (CSCL), there is nowadays a consensus about the need to provide -- through awareness tools -- information about others, which is inherently linked to social and relational phenomena [@arguedasOntologyEmotionAwareness2015; @buderGroupAwarenessTools2011; @janssenCoordinatedComputerSupportedCollaborative2013; @janssenGroupAwarenessTools2011]. An Emotion Awareness Tool (EAT) is deeply rooted in this perspective, since the information shared is not directly part of the collaborative task. In other words, using Janssen and Bodemer [-@janssenCoordinatedComputerSupportedCollaborative2013] division between the *content* and the *relation* spaces already mentioned also in the previous chapter, an EAT may be limited to the *relational* space if learners do not make the effort to integrate that information also in the *content* space. This fact may therefore limit the usefulness of Emotional Awareness to enhancing the social presence. That is, emotions shared through the EAT are used as a *proxy*, a strong reminder of the presence of other learners, but without integrating the emotional information into the task at hand. This phenomenon would not be inherently bad, since it is widely accepted that one of the main drawbacks in distance learning is the sentiment of loneliness and isolation [*e.g.*, @carswellDistanceEducationInternet2000; @conradEngagementExcitementAnxiety2002; @jacquinotApprivoiserDistanceSupprimer1993], but it would question whether the result is worth the effort: social presence may be sustained with cues that are closer to the *content space* compared to the dual-task [@pashlerDualtaskInterferenceSimple1994] imposed by the use of an EAT while performing the learning activities. Performance-based indicators of interest in emotional information sharing, seeking and processing -- obtained in the randomized trial with three different interfaces illustrated in the previous chapter -- seem to corroborate a genuine interest in emotional awareness as instrumental to the task at hand. That does not exclude the possibility, though, of an interest in using the EAT exclusively as a form of social presence. Therefore, it is worth investigating the usefulness of an EAT in an asynchronous and individual situation: can it still be useful?

In order to investigate the matter, the adoption of an experimental approach as the one used in the previous study is nevertheless inadequate for at least the following reasons. First, using a task of a relatively short time may fail to produce a sense of belonging to a group, especially in a computer-mediated settings. It is therefore more reliable to measure the usefulness of the EAT in an extended period of time, ideally in order to assess whether the perception of usefulness evolves in time. Second, if collaboration is removed, participants would be sharing emotions with, and seeing emotional episodes of an estranged person, without any connection in time, space or purpose. Thus, the social presence should rather be elicited in a group that has already a *raison d'Ãªtre*, and whose members share as many elements as possible, even though they are not directly collaborating. Third, in an asynchronous and non collaborative situation, emotions may be elicited by a wide range of elements which are more difficult to pinpoint to something that has happened synchronously. It is thus important that the context in which emotional episodes emerge is as ecological as possible, for them to be representative as a *proxy* of the person.

For these reasons, the present study adopts a longitudinal plan [@fitzmauriceAppliedLongitudinalAnalysis2011] in which the use of the EAT is implemented in an ecological context of distance learning. The Master of Science in Learning and Teaching Technologies (MALTT) at Geneva University provides a blended learning program since more than 20 years. The planning divides each semester in three periods, in which a week of on-site classes is followed by 4-5 weeks of remote learning, during which students are often assigned a small project to submit before the following period begins. The use of the EAT will be implemented in one of the courses of the Master, named *Sciences et Technologies de l'Information et de la Communication I* (STIC I), which covers introductory web programming and computational thinking [@fritzPenseeComputationnelleAvec2019]. Students will use the EAT to express their emotions at any moment while they are working for the STIC I course, a mechanism comparable to the Experience Sample Method [ESM; @csikszentmihalyiValidityReliabilityExperienceSampling2014] or the Ecological Moment Assessment [EMA; @shiffmanEcologicalMomentaryAssessment2008] already used in distance learning situations (*e.g.*, @molinariEMORELOutilReporting2016, but see for instance @scollonExperienceSamplingPromises2003 for a critical assessment of the method). Contrary to some implementation of ESM or EMA, in which there is an external prompt that reminds participants of the recording activity, the use of the EAT is left to the spontaneous initiative of students, who can decide whether and when to use it based on the eliciting events during remote learning [@wheelerSelfRecordingEverydayLife1991].

Compared to the previous study, the emotional information of more than two students will be shown on the perceiving-monitoring part of the interface [@buderGroupAwarenessTools2011; @schmidtProblemAwareness2002]. As a consequence, the way emotional awareness is graphically represented on screen must also be adapted in order to convey a *grouped* representation of a whole class [@bersetVisualisationDonneesRecherche2018; @fritzRealTimeEmotionalAwareness2016]. This technical modification has consequences on a more abstract and theoretical level, since *individual* or *dyadic* emotions are replaced by *group* emotions [*e.g.*, @barsadeRippleEffectsEmotional2002; @keltnerSocialFunctionsEmotions1999; @parkinsonEmotionSocialRelations2005; @smithCanEmotionsBe2007; @vankleefEmotionalCollectivesHow2015; @vankleefEmotionalInfluenceGroups2017]. The use of the EAT may therefore be influenced by collective dynamics. For instance, Cheshin, Rafaeli and Bos [-@cheshinAngerHappinessVirtual2011] found supporting evidence that emotional contagion [@barsadeRippleEffectsEmotional2002; @hatfieldEmotionalContagion1993] can also happen in virtual teams, where computer-mediated communication is exclusively text-based.

In this regard, comparing two classes of the same course in different years may therefore also contribute to investigate to what extent the adoption, use and perception of the usefulness of an EAT is determined *mainly* by individual characteristics or is also influenced by *interactions* between the individual and the group [@boehnerHowEmotionMade2007; @dillenbourgSymmetryPartnerModelling2016]. Even though students would not be randomly assigned to the classes, it is difficult to figure out systematic factors at play, which would determine why particular students would apply in a specific year rather than another, especially in a Master that has always been very heterogeneous in the students' profile.

Finally, whereas the number of emotions expressed can be maintained as an indicator of the use of the EAT, the eye-tracking measures used to detect emotional information seeking and processing cannot be replicated in a longitudinal plan. For this reason, the study also implements a tentative survey aiming at measuring the perceived Emotion Awareness Usefulness (EAU). The survey -- thoroughly depicted in the material section -- combines 7 dimensions retrieved from the literature:

1.  *Frequency*. The frequency of use is a dimension used in different scales pertaining to Human-Computer Interaction and User Experience [@mackenzieHumanComputerInteractionEmpirical2013; @tullisMeasuringUserExperience2013], as it is the case in the System Usability Scale [@brookeSUSQuickDirty1996]. The more frequently a tool is used, the more useful it is perceived, especially when the use is voluntary.
2.  *Affordance*. Affordance in this context broadly refers to the actions available through the EAT and where they take place [@normanDesignEverydayThings2013]. The presence of an EAT may prompt users to share their emotions, something they would not do without the presence of the tool [*e.g.*, @parkinsonEmotionsDirectRemote2008; @rimeEmotionElicitsSocial2009; @vankleefInterpersonalDynamicsEmotion2018].
3.  *Social Presence*. Social presence is a pivotal dimension in remote learning, providing support for learners isolation and feeling of loneliness [*e.g.*, @gunawardenaSocialPresencePredictor1997; @tuRelationshipSocialPresence2002]. Perceiving the emotions of colleagues can help learners to remember there are others in the same condition as they are.
4.  *Self-Understanding*. Having emotions a strong influence on intra-personal functions [*e.g.*, @broschImpactEmotionPerception2013; @levensonIntrapersonalFunctionsEmotion1999; @schererWhatAreEmotions2005], the presence of an EAT may contribute to a better self-assessment of the situation and its consequences on learners' behavior.
5.  *Understanding Others*. The presence of the emotions of colleagues through the EAT may inform learners about what others are experiencing during the remote learning periods, providing information to build and update a mental model of the causes and consequences on their behavior [*e.g.*, @dillenbourgSymmetryPartnerModelling2016; @vankleefEmergingViewEmotion2010; @vankleefEmotionalInfluenceGroups2017; @vankleefInterpersonalDynamicsEmotion2018]
6.  *Self-Other Comparison*. Comparing one's own emotions with that of the colleagues can provide useful information, especially in situation of incertitude [*e.g.*, @eligioEmotionUnderstandingPerformance2012; @molinariEmotionFeedbackComputermediated2013; @vandevenEnvyAdmirationEmotion2017]. The presence of the EAT may facilitate and prompt this comparison.
7.  *Self-Regulation*. Emotion regulation is a pivotal phenomenon that allows learners to modify their emotional experience using different strategies, such as suppression or reappraisal, in order to maintain instrumental emotional states and modify disruptive ones [*e.g.*, @arguedasAnalyzingHowEmotion2016; @grossEmotionRegulationCurrent2015; @grossHandbookEmotionRegulation2014; @jarvenojaRegulationEmotionsSocially2013]. The presence of the EAT, both in terms of learners own emotions and that of the colleagues, may facilitate regulatory processes.

## Research Questions

The present study aims at investigating four main topics. The first consists in the assessment of whether synchronous collaboration is a *necessary* condition for emotional awareness to be perceived as an integrated information into the task. If an EAT is perceived useful even when participants are not directly collaborating, it will rather suggest that emotion awareness is a *sufficient* condition for enacting social presence of others, regardless of the collaborative or individual nature of the task [@mackieCausesConditions1965]. In other words, emotion awareness could act as a *proxy* for students not to feel alone during distance learning and provide social reference as to how colleagues are feelings [@barsadeGroupAffect2015; @hareliEmotionsSignalsNormative2013; @vankleefEmotionalInfluenceGroups2017], as well as enhancing group belonging and cohesion during remote learning [@andersonEmotionalConvergencePeople2003; @keltnerSocialFunctionsEmotions1999; @salasMeasuringTeamCohesion2015; @vankleefEmotionalCollectivesHow2015]. The first research questions (*Q1*) thus investigates what is the use and the perception of emotion awareness usefulness of students in a remote, individual learning environment, and whether the use or the perception of usefulness change over time.

The second purpose of the study is to contribute to assess whether the use of an EAT depends *mainly* on the individual characteristics of the students or is *also* determined by the interaction between students using the tool at the same time [@dillenbourgSymmetryPartnerModelling2016]. Taking advantage of the fact that two classes will use the EAT under *more or less* equivalent external conditions (same course, same program, same learning environment, ...) -- and assuming no systematic factor at play determining particular type of students in one class compared to the other -- differences in the use or perception of the tool between one class and the other should corroborate the effect of interaction rather than individual characteristics alone. The second research question (*Q2*) therefore investigates whether differences in the use or the perception of the EAT can be detected between one class and the other.

The third aim of the study is to assess the perceived usability [@tullisMeasuringUserExperience2013] of an EAT in a longitudinal and asynchronous context. The previous assessment of the tool was conducted in a usability test, with the same fixed time and simulated collaborative task as in the previous chapter (Fritz, 2014) and is therefore worth investigating what is the perceived usability of the EAT in an ecological context.

The forth and last purpose of the study is to assess to what extent the moment-to-moment emotions expressed by learners are then recollected correctly after a period of time, both with respect to their own expressed emotions and that of their colleagues. There is in fact evidence in the literature suggesting that emotional episodes have a privileged access to memory [@broschImpactEmotionPerception2013; @kensingerRetrievalEmotionalEvents2020; @montagrinGoalConducivenessKey2013; @poolAttentionalBiasPositive2015; @rimePartageSocialEmotions2005], and it is therefore worth exploring whether the presence of an EAT contributes in somehow in *anchoring* the individual and collective affective experience during distance learning.

No hypothesis is nevertheless posited for any research question, because the setting is too unpredictable. The EAT has never been used before in longitudinal studies, which are by nature more prone to unforeseen events. For instance, it is not even warranted that the EAT will be used in the first place. Furthermore, the measure of emotion awareness usefulness is tentative and non-validated. Consequently, positing hypothesis without pre-registering them would expose any finding to well-founded doubts of questionable research practices [@johnMeasuringPrevalenceQuestionable2012; @makelQuestionableOpenResearch2019], especially Hypothesizing After the Results are Known (HARKing; @kerrHARKingHypothesizingResults1998). All research questions should therefore be interpreted as non-confirmatory [@scheelWhyHypothesisTesters2020].

## Methods

I report how I determined the sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

`r s2.participants_aggregated_all %>% nrow()` students (`r (s2.participants_gender_age$gender == "F") %>% sum()` women, `r (s2.participants_gender_age$gender == "M") %>% sum()` men, and 5 missing values) of the course *Sciences et Technologies de l'Information et de la Communication I* [@fritzPenseeComputationnelleAvec2019] in the Master of Science in Learning and Teaching Technologies at Geneva University took part in the study ($M_{age} = `r s2.participants_gender_age$age %\>% mean(na.rm = TRUE) %\>% printnum()`$, $SD_{age} =`r s2.participants_gender_age$age %>% sd(na.rm = TRUE) %>% printnum()`$ with 7 missing values). Students belonged to two classes that took the one-semester course in two successive years during the period of the thesis (2015-2020): `r table(s2.participants_aggregated_all$group)[1]` students in the first class, and `r table(s2.participants_aggregated_all$group)[2]` students in the second, without overlapping. It is worth noting that a third cohort was originally planned to increase the sample size, but the study has not been implemented because this third cohort had to undergo an abrupt switch to an exclusive distance learning format due to the pandemic. Even though a completely online format would have been even more interesting for the purpose of the present study, the use of the EAT would have added up to an already complicated situation. Furthermore, the cohort would also differ with the other in the way social links could have been created, not disposing of the same weeks with on-site courses.

The use of the EAT was warranted as a pedagogical activity, since the use of technological tools in learning situations is an integral part of the Master's program. Given no participant can be forced to take part to a study, though, students had the choice, at the end of the course, either to sign a consent form allowing data to be used for research purposes, or to write on the same form only the ID they were given at the beginning of the study (without connection to their identity, see procedure below) so that all data associated with that ID could be erased. The overall sample size of the study is therefore determined by the number of students whose ID appears in at least one of the different sources of measure (see below) and has not been retracted via the *non-consent* form.

The population is clearly a convenience sample, but the choice has nevertheless both an explanation and a potential interest over and above the limitations. The explanation is preeminently of a technical nature. The EAT has never been adopted in a longitudinal study, where it must be seamlessly available even in the absence of the experimenter. Since the study implies comparison between two cohorts, it is therefore mandatory that technical problems should be signaled and repaired as soon as possible. In this regard, MALTT students possess the technical know-how to identify and accurately describe malfunctioning in a web application, as well as a quick access to the technical team.

The interest of the convenience sample is, ironically, its potential inconvenience. In fact, if the tool is adopted and considered as useful, results may be biased by the convenience sample, and therefore be taken with more than a grain of salt. On the other hand, if the tool is not adopted and considered of scarce usefulness, then the shortcomings are amplified, since even learners with an interest, habit, and technical know-how would not adopt it.

### Material

#### Configuration of the Emotion Awareness Tool

The Dynamic Emotion Wheel Research Toolbox (DEW-RT) was adopted for both cohorts. The configuration of the Dynamic Emotion Wheel (DEW), depicted in Figure \@ref(fig:s2-dew-interface-figure), is implemented as follows.

For the expressing-displaying function of awareness, the same EATMINT circumplex used in the study depicted in the previous chapter and also in Fritz (2015) was adopted. As a reminder, this affective space comprises 20 emotions organized over the two appraisal dimensions *Valence*, prompted with the question *is the situation pleasant?*, and *Control/Power*, prompted with the question *is the situation under your control?*. Both dimensions were characterized by two opposite poles, labeled *not at all* and *yes absolutely*. The choice and disposition of the subjective feelings is thoroughly depicted in the chapter about the DEW-RT, within the section dedicated to the EATMINT affective space.

For the perceiving-monitoring function of awareness, three *word clouds* were implemented. In a *word cloud*, words are depicted in a font whose size is proportional to the number of occurrences of that world in a specific context, such a text document or a categorization, so that the more frequently used words appear bigger than the less frequently used ones. The perceiving-monitoring interface of the EAT comprised the following elements:

1.  A *Self-Centered* word cloud, depicting the last 50 feelings expressed by the participant herself;
2.  A *Partners-Oriented* word cloud, depicting the last 100 feelings expressed by the other members of the class, that is all the feelings bar that of the participant herself;
3.  A *Collective-Oriented* word cloud, depicting all the emotions expressed by the whole class since the first use of the EAT, that is, the emotions of the participant herself, plus that of the other members.

(ref:s2-dew-interface-caption) Interface of the EAT for a participant, depicting the expressing-displaying and perceiving-monitoring parts of the tool.

```{r s2-dew-interface-figure, fig.cap="(ref:s2-dew-interface-caption)", fig.align="center", out.width="50%"}
include_graphics(here("figure/s2/dew-interface.png"))
```

The number of emotions proposed by each word cloud is arbitrary, since there is no previous benchmark about frequency of use in general, and expression in particular. The word cloud also present *a priori* shortcomings with respect to subjective feelings typed directly by participants, since for them to be grouped, they should be written in exactly the same way (*e.g.*, a small typo would isolate that expression). All things considering, though, word clouds are relatively known graphical representation, and convey an immediate and straightforward method of aggregation.

Compared with the interface used in the study illustrated in the previous chapter, thus, the differences concern only the perceiving-monitoring part of the EAT. First, all the emotional information was conveyed through the subjective feelings, with no trace of the cognitive evaluation. This choice is technically justified by the lack, at the time being, of a grouped representation of the appraisal dimensions, since the line charts used in the previous study are limited to individuals. It is also warranted by the fact that, in the usability test conducted about the DEW (Fritz, 2015) adopting the very same interface than in the previous study, eye-tracking measures clearly showed that the subjective feelings in the emotion time line were sought more often than the line charts with the appraisals dimensions. Second, no temporal reference appeared at all, since the subjective feelings were categorized based on the frequency alone. This choice is justified by the fact that, in an asynchronous context, the temporal reference conveys limited information, especially considered that there is no manifest link between the time and a specific task or situation involved. Third, except for the participant's own emotions, it was not possible to discern what specific colleague has expressed a particular feeling or cluster of feelings. Once again, this choice is technically imposed by the lack, at the time being, of a grouped representation of feelings, which is able to maintain agency without overcrowding the interface. The choice is nevertheless also a theoretical influence, since in such a setting, the emotions of the colleagues are *truly* at a group level. More generally, without a previous benchmark about the number and frequency of emotions expressed in an asynchronous, individual situation, it was also difficult to establish grouping criterion (e.g. group by hour, by day, or by week). The grouped representation of emotions in the DEW-RT is an open issue that has just started to be investigate [see for instance @bersetVisualisationDonneesRecherche2018].

#### Emotion Awareness Usefulness Rating

According to Boehner and colleagues [-@boehnerHowEmotionMade2007, p. 207], "success of [an affect-aware] system is measured by whether users find the system's responses useful for interpreting, reflecting on, and experiencing their emotions". Based upon this perspective, the study introduces a tentative scale that aims at measuring Emotion Awareness Usefulness (EAU) with respect to 7 dimensions identified in the literature (see also the study overview). The scale comprises 7 items expressing one of the 7 dimensions, for which participants expressed their accord on a scale from 1 (strongly disagree) to 10 (strongly agree) according to the item alone (*i.e.*, with no reference to the dimension):

1.  *Frequency*. I used the tool frequently (e.g. every time I worked for the course).
2.  *Affordance*. The use of the tool prompted me to share my emotions.
3.  *Social Presence*. The use of the tool allowed me to feel less lonely during remote learning periods.
4.  *Self-Understanding*. The use of the tool allowed me to better understand my emotions.
5.  *Understanding Others*. The use of the tool allowed me to better understand the emotions of my colleagues.
6.  *Self-Other Comparison*. The use fo the tool allowed me to compare my emotions with those of my colleagues.
7.  *Self-Regulation*. The use of the tool allowed me to regulate my emotions.

The scale is very straightforward and with only a few items, specifically only one per dimension. This is a potential shortcoming from a reliability and validity standpoint, but, especially in a repeated measure design, brevity is of essence. Once again, the convenience sample of the study provides some leverage on the formulation of items, since MALTT students are, for instance, familiar with terms such as *regulation*, which may be too technical for other populations and therefore require a more explicit formulation.

#### System Usability Scale

The System Usability Scale (SUS; @brookeSUSQuickDirty1996) is a widely adopted scale that measures the usability of a tool. It comprises 10 items, usually on a 5-point scale, but that can also be adapted to a 7-point range, which has been the case for this study. The 10 items are as follows:

1.  I think that I would like to use this system frequently
2.  I found the system unnecessarily complex
3.  I thought the system was easy to use
4.  I think that I would need the support of a technical person to be able to use this system
5.  I found the various functions in this system were well integrated
6.  I thought there was too much inconsistency in this system
7.  I would imagine that most people would learn to use this system very quickly
8.  I found the system very cumbersome to use
9.  I felt very confident using the system
10. I needed to learn a lot of things before I could get going with this system

The even items of the scale are reversed, so that a lower evaluation on the item corresponds to a greater perceived usability. The scale uses a system of coefficients that add up to obtain a score between 0 and 100. A more thorough discussion of the scale is available in the next chapter, where the usability score of the SUS will be compared between the usability test (Fritz, 2015) and the score obtained in the present study.

#### Geneva Emotional Competence Test

The Geneva Emotional Competence (GECo) test [@schlegelGenevaEmotionalCompetence2018] is a performance-based test that measures emotional competence as an ability, rather than a trait [@chernissEmotionalIntelligenceClarification2010; @saloveyEmotionalIntelligence1990; @schererComponentialEmotionTheory2007]. The test is primarily concerned with emotions in a workplace, which has relevant congruence with inter-personal dynamics in remote learning. The test is divided in 4 sub-competences tests, namely *emotion recognition*, *emotion understanding*, *emotion regulation*, and *emotion management*.

Emotion recognition determines the ability to infer the corresponding emotional state of a person using video clips of actors. Participants look and hear a professional actor expressing a pre-defined emotion using facial expression and pronouncing pseudo-words with a corresponding vocal prosody. Participants must then choose among different natural language words the one that best describe the displayed emotion.

Emotion understanding determines the ability to infer the corresponding emotional state of a person based on a description of a situation. Participants read the details of an event that occurs to another person and must infer which emotion, among a list of discrete options, has been elicited by that event.

Emotion regulation determines the ability in engaging in adaptive (vs. disruptive) strategies to modify one's own emotional state. Participants read the description of a situation they must imagine has happened to them, which is meant to trigger disruptive emotional episodes and must identify the two appropriate strategies vs. the two inappropriate ones.

Emotion management determines the ability to adopt the better strategy to handle situations eliciting disruptive emotions in others. Participants read a vignette depicting a situation in which they interact with another person. The situation is meant to elicit in that other person a disruptive emotional response such as anger, irritation or misplaced happiness. The participant can then choose between 5 different strategies to manage the emotional response of the other person, among which one is considered to be the more appropriate.

Each sub-test yields a score of accuracy ranging from 0 (low competence) to 1 (high competence). The 4 scores can be combined to obtain an overall emotional competence score.

#### Individual and Class Perceived Frequency of Feelings

Considering the fact that the *word clouds* adopted in the perceiving-monitoring part of the EAT clearly define which feelings have been experienced more frequently than others, the study comprises a survey that asks participants, at the end of the semester, to rate the frequency by which (1) they have felt each of the 20 subjective feelings of the EATMINT circumplex ; and (2) their colleagues have felt each of the same 20 subjective feelings. In the survey, each subjective feeling is presented with a 5-point scale comprising *never*, *seldom*, *sometimes*, *often* and *very often*. Participants were also allowed to skip each particular feeling without rating the frequency both in the individual and the class surveys.

### Procedure

All courses of the Master are organized in three periods per semester, which will defined by P1, P2 and P3. Each period is composed by a week of on-site courses, and 4-5 weeks of remote learning. In order to let students get familiar with distance learning, the use of the tool was integrated only from P2. In this way, students had P1 to get acquainted with the difficulties of distance learning, and could therefore better assess the usefulness of an awareness tool in general, and of an EAT in the specific case of this contribution.

During the on-site course of P2, students were informed that they would be asked to use the EAT as a corollary activity in the course. They were also informed that, beside the pedagogical interest of the activity, the use of the EAT was linked with my thesis and that data could be used for research. The distinction between the participation to the *compulsory* pedagogical activity and the voluntary participation to the research was clearly explained, and students were asked to read a consent form that was linked into the private work-space of the course. They then drew an ID from a urn, which they would use for any interaction with the EAT or with the surveys. With the ID, which was unique for each student, they also received a common code for each class.

#### Expectancy Survey

At this point, each student was asked to fill the *Expectancy* survey in order to collect their perception of the use of an EAT before actually using it. The survey was simply introduced by this description:

> An emotion awareness tool is a tool that allows to share one's own emotions with other people in a computer-mediated context. The tool has two main function: (1) it allows the user to express her own emotions and make them visible to the other users who are using the tool; and (2) it allows the user to perceive the emotions of the other users who have access to the same tool. You will have access to an emotion awareness tool for the two remote periods of the course, so that you can use it while you are working on STIC I: while you are reading the pedagogical material, you are coding the devices for your exercises, or you are contributing to the Wiki.

The questions of the EAU were the same as described in the material above, except that they were transformed in a prospective tense. For instance, *I think I will use this tool frequently* or *I think the tool will prompt me to share my emotions*. A scale from 1 to 10 allowed students to express their agreement which each dimension of the survey.

#### Demo Survey

Once filled the *Expectancy* survey, students were introduced to the EAT through a demo. They discovered the interface of the tool they will use throughout distance periods of the course, and they could directly test the functioning of the tool by expressing emotions, knowing those will not be recorded. The general functioning of the tool (i.e. the use of the appraisal dimensions and the choice of the subjective feeling) was explained. After 5 minutes of practicing with the tool, students took the *Demo* survey, which is exactly the same survey as the *Expectancy*, comprising the dimensions of the EAU in the prospective tense.

#### Set-Up the EAT for Distance Periods

Towards the end of the course, the set-up of the EAT for the actual use was organized. Since it was not possible to combine the EAT on the same interface with the various tools students use as part of the course, a generic web page was therefore the only flexible solution. Students saw how the window could be adapted and put beside another window (e.g. of a software or of another web page) in order to have the EAT close to the task at hand. To ease the access to the EAT, students created a bookmark in their browser that would automatically log them in with their unique ID and the code of the class.

Practically, then, students were supposed to open their browser, click on the bookmark pointing to the EAT, resize the window and place it beside the activity they were performing for the course. Or, alternatively, keep it minimized on their operating system task area and maximize it on recall. In both cases, the use of the EAT required a deliberate action outside the *normal* work-flow of the course.

#### Halfway Survey

During the on-site course of P3, students filled in the *Halfway* survey, after a whole period (i.e. 5 weeks) of use of the tool during remote learning. The survey comprised the EAU dimensions in retrospective tense (*e.g.*, *I have used the tool frequently* or *The tool has prompted me to share my emotions*), as well as an open-ended question in which students could provide additional information about their experience with the tool.

#### Final Survey

Students filled the *final* survey during the first on-site course of a follow-up course (STIC II) in the next semester, that is after 9 weeks from the *halfway* survey. The long period is the result of 5 weeks of *normal* remote learning, interrupted by 2 weeks of Christmas' leave in December (in which students often works, though), and 2 weeks of end-of-semester leave. The EAT was available until the formal end of semester. It has been decided to ask students to fill in the *Final* survey on-site, even with two weeks delay compared to the end of the semester, in order to maximize data collection. The *Final* survey comprised:

-   The EAU survey in retrospective tense (same as *Halfway* survey);
-   The System Usability Scale [@brookeSUSQuickDirty1996], but with a 7-point scale rather than the usual 5-point scale;
-   A survey asking participants to rate the frequency with which they have experienced the 20 subjective feelings belonging to the underlying affective space of the DEW;
-   A survey asking participants to rate the same feelings, but with respect to the frequency with which their colleagues have felt them during the remote periods;
-   An open-ended question in which students could provide additional information about their experience with the tool.

#### Reminders

Reminders to use the EAT during remote learning periods were dispatched twice per periods (P2 and P3) within messages in the private space of the course. The reminders were integrated into wider communications, for instance the feedback of an exercice.

#### Geneva Emotional Competence Questionnaire

In the private workspace of the course, students could find a link to the Geneva Emotional Competence (GECo, @schlegelGenevaEmotionalCompetence2018) test. The presence of the link was reminded at each on-site course, but students were clearly informed that the test was exclusively part of the research, so they were not forced to take it. Students could therefore take the test anytime during the P2 or P3 periods. Considering that there is no evidence yet that the use of an EAT in this context could improve the emotional competence of a person, especially in a performance-based test, this option left more time for students to take a long test during a very active period of learning. Students deciding to take the test had only to provide their anonymous ID in addition to the questions of the test.

### Exclusion Criteria

Having no previous reference for data collection, *a priori* exclusion criteria were difficult to formalize. Since there was the possibility of students dropping out either from the Master or from the research activity (e.g. refusing to fill-in the surveys), participants not having filled both the *Halfway* and the *Final* survey will be considered as if they dropped out and will thus be excluded from data analysis.

## Results

Results are based on $N = `r s2.participants_aggregated %>% nrow()`$ participants, having `r (s2.participants_aggregated_all %>% nrow()) - (s2.participants_aggregated %>% nrow())` students not filled both the *Halfway* and the *Final* survey, and were therefore excluded from the analysis considering they have dropped of the either from the course or the research. Table \@ref(tab:s2-descriptive-table) depicts the number of participants retained for each class across the 4 longitudinal surveys *Expectancy*, *Demo*, *Halfway* and *Final*, for which the two classes have very similar -- if not equal -- sample sizes.

(ref:s2-descriptive-table-caption) Number of participants retained for each class in total, and with respect to the 4 longitudinal surveys.

```{r s2-descriptive-table}
s2.valid_results_description %>% 
  kable(
    col.names = c(NULL, "Class 1", "Class 2"),
    booktabs = TRUE,
    digits = 2,
    caption = "(ref:s2-descriptive-table-caption)\\label{tab:s2-descriptive-table}",
    caption.short = "Study 2: Descriptive statistics",
    longtable = FALSE,
  )
```

### Expressing Emotions

Overall, participants expressed `r s2.participants_aggregated$num_emotions %>% sum()` emotions through the EAT, that is a mean of `r maf.print_m_sd(s2.participants_aggregated$num_emotions, TRUE, TRUE)`. One student in Class 1 and three students in Class 2 did not express any emotions at all. The fact that those students had not expressed emotions, though, does not systematically rule out the fact that they have not used the tool at all: potentially, they could have logged in just to see the emotions of others. Technically, the DEW-RT registers the log for every access, but students were not informed beforehand of this possibility. Thus, data about accesses has not been extracted -- and therefore not used -- and the 4 students are kept in the analysis.

In comparing the two classes, the number of emotions expressed is similar with respect to the central tendency ($M_{class1} = 11.47$ against $M_{class2} = 13.47$), but differs greatly in variation ($SD_{class1} = 21.69$ against $SD_{class2} = 11.79$). The greater SD of Class 1 results in particular by a single participant that expressed 86 emotions. In Class 2, the greatest number of emotions expressed is 34. Taking the median as a more robust reference of comparison, the difference between Class 1 ($Mdn = 3$) and Class 2 ($Mdn = 12$) is much more evident. Figure \@ref(fig:s2-graph-emotions-expressed-boxplot) compares the expression of emotions between the two classes.

(ref:s2-graph-emotions-expressed-boxplot-caption) Boxplot comparing the expression of emotions between the two classes.

```{r s2-graph-emotions-expressed-boxplot, fig.align="center", fig.width=4, fig.height=2.5, fig.cap="(ref:s2-graph-emotions-expressed-boxplot-caption)"}
s2.graph_expressed_emotions_boxplot
```

The use of the tool with respect to the longitudinal duration of the course is depicted in Figure \@ref(fig:s2-graph-expressed-emotions-over-time) The classes have similar profiles in the cumulative number of emotions expressed over time, alternating phases in which they express emotions with periods of pauses.

(ref:s2-graph-expressed-emotions-over-time-caption) Cumulative number of emotions expressed through the EAT

```{r s2-graph-expressed-emotions-over-time, fig.align='center', out.width="80%", fig.cap="(ref:s2-graph-expressed-emotions-over-time-caption)"}
s2.graph_expressed_emotions_over_time
```

Overall, it is safe to assume that Class 2 made a more thorough and homogeneous use of the EAT in expressing emotions compared to Class 1, even though the use in expressing emotions seems to be limited. It is nevertheless worth exploring whether the difference in expressing is also corroborated by differences in the perception of usefulness.

### Emotion Awareness Usefulness

Being the first adoption of the Emotion Awareness Usefulness (EAU) scale, it is worth beginning with some exploratory data analysis aiming at determining to what extent the self-reported rating over the 7 dimensions can contribute to assess (1) whether there is a change over time of the perceived EAU, and (2) whether the two classes differ in the perception of the EAU. In this regard, it is useful to start by evaluating the sensibility of the scale in terms of overall dispersion for each of the 7 underlying dimensions, namely *Frequency*, *Affordance*, *Social Presence*, *Self-Understanding*, *Understanding Others*, *Self-Other Comparison*, and *Self-Regulation*. In Figure \@ref(fig:s2-eda-dimensions-dispersion-graph) every circle represents one of the $N=`r s2.ea_usefulness %>% nrow()`$ ratings, which was made on a scale from 1 to 10, for each dimension across surveys and participants. The dispersion for each of the 7 dimensions spans over the entire range of the rating, suggesting that each dimension has a good sensibility.

(ref:s2-eda-dimensions-dispersion-graph-caption) Overall ratings of each of the 7 EAU dimensions, $N=`r s2.ea_usefulness %>% nrow()`$ ratings. Bars represent 95% confidence intervals around the overall mean.

```{r s2-eda-dimensions-dispersion-graph, fig.cap="(ref:s2-eda-dimensions-dispersion-graph-caption)", out.width="80%", fig.align='center'}
s2.eda.dimensions_dispersion
```

This preliminary assessment therefore corroborates the interest to investigate more specific patterns in the rating of each of the 7 dimensions with respect to the change over time and differences between classes. Table \@ref(tab:s2-description-EAU-stratified) depicts means and standard deviations of the 7 dimensions stratified for both classes across the 4 longitudinal surveys.

(ref:s2-description-EAU-stratified-caption) Means and (standard deviations) of the EAU ratings across longitudinal surveys.

```{r s2-description-EAU-stratified}
s2.ea_usefulness.descriptive_stratified %>%
  select(-dimension) %>% 
kable(
    booktabs = TRUE,
    digits = 2,
    caption = "(ref:s2-description-EAU-stratified-caption)\\label{tab:s2-description-EAU-stratified}",
    caption.short = "Study 2: EAU means and standard deviations",
    longtable = FALSE,
    linesep = c("", "", "\\addlinespace")
  ) %>% 
  kable_styling(
    latex_options = c("repeat_header")
  ) %>% 
  row_spec(c(3, 6, 9, 12, 15, 18, 21), bold = T) %>% 
  pack_rows(
    index = c(
      "Frequency" = 3, 
      "Affordance" = 3, 
      "Social Presence" = 3,
      "Self-Understanding" = 3,
      "Understanding Others" = 3,
      "Self-Other Comparison" = 3,
      "Self-Regulation" = 3
    )
  )

```

In order to assess the presence of effects in the above ratings, a linear mixed-model, also known as multilevel linear models [@finchMultilevelModelingUsing2019; @westLinearMixedModels2015] is fitted with the following components. The dependent variable is the singular value, from 1 to 10, expressed on each dimension of the EAU in the 4 surveys. The fixed covariates are (1) the longitudinal survey with 4 levels (*Expectancy*, *Demo*, *Halfway*, and *Final*); (2) the specific dimension of the EAU with 7 levels (*Frequency*, *Affordance*, *Social Presence*, *Self-Understanding*, *Understanding Others*, *Self-Other Comparison*, and *Self-Regulation*); and (3) the group each student belongs to with 2 conditions (*Class 1* or *Class 2*). All two-way interactions between pairwise covariates, as well as the three-way interaction, are also fitted in the model. The random covariates account for the nested structure of the observations: the repeated measure of the participant is nested inside the class to which the participant belongs.

The use of a linear-mixed model is warranted by a better flexibility compared to repeated-measure ANOVA, especially in case of missing data. Furthermore, linear-mixed models allow to account both for the repeated measures per participant and the nested structure of residuals, with participants potentially influenced by the use of the tool made by the colleagues in their class, which would violate the non-independence of residuals in ordinary least square regression. Finally, it allows to keep each dimension separate rather than averaging over a single score, which will loose an interesting source of variance with respect to the 7 dimensions of the EAU (see @finchMultilevelModelingUsing2019; @mcelreathStatisticalRethinkingBayesian2020; @singmannIntroductionMixedModels2020; @westLinearMixedModels2015 for a more comprehensive overview of linear mixed models compared to ordinary least square regression).

The linear mixed model analyzing the score on the EAU scale was fitted using the mixed function of the Afex [@singmannAfexAnalysisFactorial2020; @singmannIntroductionMixedModels2020] R package. A Type III analysis of variance of the multilevel linear model detects effects for the longitudinal survey and the dimension of the EAU scale, but not for the group. Two-way interactions were detected between the group and the EAU dimension as well as between the EAU dimension and the longitudinal survey, but not between the group and the longitudinal survey. Finally, a the three-way interaction between group, longitudinal survey and EAU dimension was not detected. Results are depicted in Table \@ref(tab:s2-mlm-eau-table) using Kenward-Roger approximation for computing the *p*-value [@lukeEvaluatingSignificanceLinear2017].

(ref:s2-mlm-eau-caption) Results of a Type III ANOVA on the fitted multilevel linear model using Kenward-Roger approximation for computing the *p*-value

```{r s2-mlm-eau-table}
s2.mlm.ea_usefulness.anova_table %>%
  kable(
    booktabs = TRUE,
    longtable = FALSE,
    digits = 3,
    caption = "(ref:s2-mlm-eau-caption)\\label{tab:s2-mlm-eau-table}",
    caption.short = "Study 2: Emotion Awareness Multilevel Linear Model",
    linesep = c("", "",  "\\addlinespace")
  )
```

Results are graphically depicted in Figure \@ref(fig:s2-graph-dimensions-and-survey), in which the EAU evaluation is stratified by the 7 dimensions of the scale and the 4 longitudinal surveys, as well as grouped by the 2 classes. Data show high *Expectancy* ratings for the *Frequency*. *Affordance*, *Social Presence*, *Understanding Others*, and *Self-Other Comparison* dimensions, but not for *Self-Understanding* and *Self-Regulation*. The ratings are generally maintained even after the *Demo* surveys and tend to decrease with the actual use of the tool in the *Halfway* survey, to remain then more or less stable even in the *Final* survey. Data also show that the two classes basically overlap on all dimensions and across longitudinal surveys. The group per dimension interaction is probably yielded by the *Frequency* and *Affordance* dimensions, for which the two classes differ the most, but it does not seem to play an important role in differentiating EAU ratings. As a consequence, the factor related to the class is dropped in post-hoc contrasts, which will focus only on the difference between the *Final* and the *Expectancy* surveys.

(ref:s2-graph-dimensions-and-survey-caption) EAU rating over longitudinal surveys stratified by dimensions and grouped by class. Bars represents 95% confidence interval and the dashed gray line the median point of the scale.

```{r s2-graph-dimensions-and-survey, fig.align="center", fig.cap="(ref:s2-graph-dimensions-and-survey-caption)"}
s2.ea_usefulness.graph
```

Results of the post-hoc contrasts averaged over group and stratified across EAU dimensions are illustrated in Table \@ref(tab:s2-eau-contrasts-table). Contrasts detect differences between the *Final* and the *Expectancy* surveys in every dimension except the *Self-Understanding* one. All detectable differences highlight a decrease in perceived EAU, with the greatest decrease for *Self-Other Comparison* and *Social Presence* (almost 3 rating points decrease), followed by *Understanding Others* and *Affordance* (more than 2 rating points decrease), and finishing with *Frequency* and *Self-Regulation* (more than 1 rating point decrease).

(ref:s2-eau-contrasts-caption) Contrasts between the Final and the Expectancy surveys for each of the 7 dimensions of the EAU scale averaged over the two classes.

```{r s2-eau-contrasts-table}
s2.mlm.ea_usefulness.comparison %>% 
  as_tibble() %>%
  mutate(
    p.value = round_ps_apa(p.value)
  ) %>% 
  kable(
    digits = 3,
    caption = "(ref:s2-eau-contrasts-caption)\\label{tab:s2-eau-contrasts-table}",
    caption.short = "Study 2: Contrasts between Final and Expectancy surveys per EAU dimension",
    longtable = FALSE,
    booktabs = TRUE
  ) %>% 
  kable_styling(
    latex_options = c("repeat_header")
  )
```

### Perceived Usability of the EAT

$N = `r s2.sus_total %>% nrow()`$ participants filled the System Usability Scale (SUS) survey [@brookeSUSQuickDirty1996] at the end of the semester. The observed score has been of `r maf.print_m_sd(s2.sus_total$score, TRUE, TRUE)`, which is considered *Good* according to the stratification proposed by Bangor, Kortum and Miller [-@bangorDeterminingWhatIndividual2009].

Figure \@ref(fig:s2-sus-items-graph) illustrates the score obtained on each of the 10 items of the SUS for the two classes. The score takes into account the reverse order for even items and is pondered on the 7-point scale used in the present study. Ad in the case of the EAU, ratings on the SUS are also consistent between classes. More specifically, data clearly show that the first item, inherent to the frequency of use, is far below the other items, which have received overall a high rating. Items 5 (integration of different functions of the system) and 9 (confidence in using the system) also have received lower ratings compared to the other items, even if not as low as the first item about frequency.

(ref:s2-sus-items-graph-caption) Rating of the individual items of the System Usability Scale (SUS) for N = 26 participants.

```{r s2-sus-items-graph, fig.align="center", fig.cap="(ref:s2-sus-items-graph-caption)"}
s2.sus_by_item.graph
```

A more detailed analysis on perceived usability is presented in the next chapter, which will compare the score with the usability test (Fritz, 2015). More accurate benchmarks will also be adopted to assess the individual items of the scale [@lewisItemBenchmarksSystem2018].

### Recollection of Individual and Collective Emotions

In the *Final* survey, that is approximately two weeks after the end of the semester -- and therefore the last day in which the EAT could be used by students during the STIC I course - participants were asked to recall the frequency with which (1) they have experienced the 20 subjective feelings of the underlying affective space as individuals, and (2) their class as a whole has experienced the same 20 subjective feelings. The sparse use in expressing emotions limits the interest in assessing whether there is a recollection of the individual and collective emotions shared with the EAT and is therefore reported here primarily to comply with the disclosure of all the measure collected. Figure ... compares three relative frequencies of the 20 subjective feelings of the underlying affective space adopted by the EAT. The first frequency is empirically retrieved using the relative frequency of expression of each subjective feelings compared to all the expressed feelings. The frequencies are mapped so that the most expressed feelings (e.g. *Attentive* and *Interested*) represent the upper bound, and correspond to the *Very often* frequency, whereas the least expressed feelings (e.g. *Surprised* and *Disgusted*) represent the lower bound, and correspond to the *Never* frequency. The second depicted frequency consists in how often participants recalled their colleagues have experienced the specific feelings. It is worth reminding at this purpose that from the interface of the EAT it was not possible to infer which specific colleague expressed a particular emotion, and therefore it was potentially possible to retrieve the frequency from the *word clouds* of the interface. Finally, the third frequency is the self-reported frequency by which participants experienced each subjective feeling themselves. The class and the self frequencies were collected by asking participants to rate the frequency on the same 5-point scale used in the graph (*i.e.*, from never to very often).

(ref:s2-recollection-feelings-graph) Comparison between the observed relative frequency of expressed feelings and the reported frequency recollected for the participants themselves, as well as the frequency attributed to the class as a whole.

```{r s2-recollection-feelings-graph, fig.align='center', fig.cap="(ref:s2-recollection-feelings-graph)"}
s2.perceived_emotions_frequency.graph
```

## Discussion

The overall picture emerging from the implementation of an EAT in asynchronous and individual settings can be roughly divided in two considerations. On the one hand, there is encouraging evidence about the expectations learners have towards the potential usefulness of an EAT. On the other hand, data highlight how these expectations are not sustained by the concrete use of the tool. Finally, the two classes showed consistency in both expectations and use, which is in itself a phenomenon worth discussing.

### *Great Expectations*

As a reminder, participants to the study were enrolled in a blended course organized over three periods of time. During the first period, students had the occasion to get familiar with distance, technology enhanced learning. When they filled the *Expectancy* survey, they therefore already had a fresh, first-hand experience of the difficulties they had to face during the remote period. Expectations were similar between classes and will therefore be discussed on the aggregated score (on a 1-to-10 range). In this regard, learners manifested the highest expectations about the usefulness of an EAT for the *Understanding Others* ($M_{total}=6.93$), and *Self-Other Comparison* ($M_{total}=7.70$), that is, the two more socially-oriented dimensions. Conversely, for the two more self-oriented dimensions, *Self-Understanding* and *Self-Regulation*, expectations were only moderate to low ($M_{total}=4.57$ and $M_{total}=4.23$ respectively). The *Affordance* dimension was rated high ($M_{total}=6.57$), suggesting that the tool is expected to serve its function of prompting learners to share their emotions. Finally, the *Frequency* and *Social Presence* dimensions are more difficult to assess, since they are the two dimensions on which the two classes have a lesser convergence. Frequency of use is notoriously a user-experience dimension that is difficult to foresee: oftentimes it is overestimated, as in this case ($M_{total}=5.57$), since the actual use turned out to be very limited. Finally, the moderate expectations for *Social Presence* ($M_{total}=5.83$), compared with higher expectations for the socially-oriented dimensions, may suggest that learners consider the EAT as a potential source of social reference rather than a way to perceive the presence of others.

All the expectations were basically confirmed in the *Demo* survey, once participants had tested the concrete use of the EAT, suggesting that the specific features of the tool neither increased, nor decreased the expectations about its usefulness. This is both good and bad news. On the bright side, learners seem to trust the tool's ability to sustain their expectations. This is also consistent with the overall perceived usability ($M_{SUS} =$).On the hand, though, the tool failed to change their mind on the dimensions there were rated moderate to low.

### Limited Use of Emotion Awareness

The *great expectations* did not stand the (longitudinal) test of time, though. Overall, the EAT has been adopted only by a handful of users throughout the course, with a mean of expressed emotions below 13. This mean is also inflated by a few participants expressing most of the emotions. The limited use of the EAT is corroborated by the Emotion Awareness Usefulness ratings, which all decreased between the *Expectancy* and the *Final* survey, except for the *Self-Understanding* dimension, which was already low.

### Consistency Between Classes

## Corollary Analysis

## Conclusion

## Chapter Summary
