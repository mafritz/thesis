---
bibliography: references.bib
---

# Emotional Awareness in Blended Learning: an Exploratory Analysis of the Use and Perception of an Emotion Awareness Tool Over Time {#study-2}

```{r s2-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)

Sys.setenv(LANG = "en")

# Load the relevant data and graphs from the study-2 folder
source(here("data", "study-2", "s2-export.R"), local = knitr::knit_global(), encoding = "UTF-8")
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

This chapter describes the second empirical contribution of the thesis, which investigates the longitudinal use of an EAT, in asynchronous and non-collaborative learning settings, made by two classes of a blended Master in education technology. As for the previous chapter, the presentation of the study follows the traditional structure of empirical contributions [@sollaciIntroductionMethodsResults2004] and therefore the outline of the chapter is not presented. The chapter starts directly by introducing the rationale of the study.

## Study Rationale

Even though there is nowadays a consistent agreement in considering emotions as bounded episodes unfolding over relatively short time [@sanderModelsEmotionAffective2013; @schererStudyingAppraisaldrivenEmotion2019; @pekrunIntroductionEmotionsEducation2014], the effects of emotional experiences also have consequences on the long term [@scherer2021; @rimePartageSocialEmotions2005; @pekrunEmotionsSchool2018; @brackettPermissionFeelUnlocking2019]. As stated by appraisal theories of emotions, for instance, emotions are elicited by the evaluation of events considered of major concern for the organism, and that evaluation can over time present regular patterns, for which a person may be more prone to evaluate events according to stable perspectives [@scherer2021]. Emotions play also a prominent role in the formation of meaningful and stable relationships with others [@rimePartageSocialEmotions2005; @rimeEmotionElicitsSocial2009; @vankleefEmotionalCollectivesHow2015; @barsadeGroupAffect2015; @smithCanEmotionsBe2007]. As already mentioned in Chapter \@ref(general-affective-background), there is also a growing consensus in learning and educational sciences to take a more holistic and integrated approach to students' emotions at various levels, from the everyday experience to the creation of curriculum that foster socio-affective competences [@pekrunEmotionsSchool2018; @brackettPermissionFeelUnlocking2019; @pekrunInternationalHandbookEmotions2014; @henritius2019].

In computer-mediated learning environments, especially applied to asynchronous and remote settings, the affective experience play a prominent role in determining whether students manage to *keep on track.* For instance, students may still manage to develop a sense of belonging to a group in spite of physical distance, but they may also risk to feel isolated and progressively loose momentum and motivation to follow through [@jezegouCreerPresenceDistance2010, @henritius2019; @lowenthalSearchBetterUnderstanding2017; @lavoueEmotionAwarenessTools2020]. In this regard, there is a growing consensus in considering that learners should be given the opportunity to self-reflect on their emotional experience [@ruizSupportingLearningConsidering2016; @lavoueEmotionAwarenessTools2020; @lavoueEmotionalDataCollection2017; @molinariEMORELOutilReporting2016], and at the same time project themselves socially and affectively into the computer-mediated learning environment as a means to enhance the *social presence* [@lowenthalSearchBetterUnderstanding2017 for an overview, see also Section \@ref(social-presence-distance-learning)].

As a consequence, scholars have started to upscale the investigation of emotion in learning, by tracking the emotional experience of students over longer period of times [@ruizSupportingLearningConsidering2016; @lavoueEmotionAwarenessTools2020; @lavoueEmotionalDataCollection2017; @molinariEMORELOutilReporting2016]. For instance, @ruizSupportingLearningConsidering2016 introduced the Twelve Academic Emotion Model (TEAM) mentioned in Section \@ref(affect-on-learning) during two semesters in on-site courses in Computer Science classes, during which teachers asked participants to rate their emotional experience at specific moments through a computer-mediated interface. The overt aim of the practice was to stimulate self-reflection on emotional experience, which was supported by the possibility to monitor the emotional information through a series of graphical representations. The authors report mixed results about how the usefulness of this process was rated by participants, even if, all things considering, they depict a favorable outlook overall. @lavoueEmotionAwarenessTools2020 followed 11 students at the University level for several weeks in the middle of the second semester. They provided students with a grid through which students could record their emotions from a list of 9 discrete emotions. Retrospective interviews were also conducted, which were focused on an appraisal-driven perspective. Students were asked about the causes and evaluation of the events they have been recording through the grid. Finally, as already mentioned in the related works of Section \@ref(ea-intra-personal), @molinariEMORELOutilReporting2016 used the the EMORE-L self-report tool to track the emotional experience of students over 15 days, but exclusively from an intra-personal perspective. In this regard, participants expressed the wish to dispose also of information about the emotional information of others.

In the same vein, it would be worth investigating whether the EAT implemented in the thesis may serve as a viable instrument for students to self-reflect on their emotional experience over a longer period of time, and also assess whether the tool allows them to project themselves socially and affectively in a computer-mediated learning environment in an asynchronous and non-collaborative situation. Such a setting is particularly relevant, since it does not structurally demand social interaction between learners [@kreijnsIdentifyingPitfallsSocial2003; @jezegouCreerPresenceDistance2010; @kirschnerAwarenessCognitiveSocial2015; @henritius2019]. As a consequence, socio-affective interaction is not stimulated the instructional design *script*. The introduction of an EAT may therefore serve to accomplish this function.

In this regard, the present study adopts a longitudinal plan [@fitzmauriceAppliedLongitudinalAnalysis2011] in which the use of the EAT is implemented in an ecological context of distance learning. The Master of Science in Learning and Teaching Technologies (MALTT) at Geneva University provides a blended learning program since more than 20 years. The planning divides each semester in three periods, in which a week of on-site classes is followed by 4-5 weeks of remote learning. The use of the EAT will be implemented in one of the courses of the Master, named *Sciences et Technologies de l'Information et de la Communication I* (STIC I), which covers introductory web programming and computational thinking [@fritzPenseeComputationnelleAvec2019]. Students will use the EAT to express their emotions at any moment while they are working for the STIC I course -- outside the on-site sessions -- for which they will be implicated in individual assignements. The collection of data is therefore comparable to the Experience Sample Method [ESM; @csikszentmihalyiValidityReliabilityExperienceSampling2014] or the Ecological Moment Assessment [EMA; @shiffmanEcologicalMomentaryAssessment2008] already used in distance learning situations (*e.g.*, @molinariEMORELOutilReporting2016, but see also @scollonExperienceSamplingPromises2003 for a critical assessment of the method). There are nevertheless two important distinctions. First, contrary to some implementation of ESM or EMA, in which there is an external prompt that reminds participants of the recording activity, the use of the EAT is left to the spontaneous initiative of students, who can decide whether and when to use it based on the eliciting events during remote learning [@wheelerSelfRecordingEverydayLife1991]. In this way, the use of the tool remains closer to the purpose of an awareness tool. Second, the information will not only be collected, but also available both to the learner herself and to the other students of the class. In other words, all the passages of the abstract model of emotional awareness depicted in Section \@ref(abstract-model-of-ea) are implicated in the process.

## Research Questions

The overall settings in which the study takes place can therefore contribute to assess whether and, possibly, why the EAT is adopted in the first place, as well as the evolution of its use and perception of its usefulness over time. Given that the EAT has never been adopted before in longitudinal settings, though, the overall character of the study is overtly exploratory, without any hypothesis stated beforehand [@scheel2020; @haeffelPsychologyNeedsGet2022]. The research questions addressed in this study can be grouped in five main topics, detailed hereafter.

### Use of the EAT Over Time

A first topic of interest concerns, bluntly, whether the EAT is used in the first place. One thing is to dispose of a tool for a limited period of time, as in the experiment of the previous chapter, where novelty and curiosity can play a prominent role. Another is to sustain the effort of producing and perusing emotional information over a longer period of time, during which resources are dedicated to the coordination of different tasks (reading learning material, design a project, debug code, etc.). The subject is particularly relevant from an awareness tool perspective, where learner are bestowed with the responsibility of adopting the tool if and when they see fit, rather than being guided by the instructional design [@millerScriptingAwarenessTools2015].

The interest of a longitudinal plan also relates to the possibility that the use changes over time. Novelty and curiosity can induce the initial adoption of the tool, but, at length, the EAT may progressively be dismissed. On the contrary, it may also be envisaged that an initial reluctance can be then steered in a more convinced use after acknowledging its benefits. Question 1 (Q1) can therefore be stated in the following terms: is the EAT adopted in the first place, and does its use evolve over time?

### Perception of the Usefulness of the EAT Over Time

As highlighted in the previous experiment, which was mainly focused on the concreted use of the tool (i.e. the left-hand side of the abstract model), the meaning-making function of emotional awareness cannot be inferred exclusively from performance-based indicators. The assessment of the right-hand side of the abstract model can benefit from an assessment based on the perception learners have of the EAT's usefulness. As it is the case for the use, also the perception can vary over time, and the two may not be necessarily linked. One can stop using the EAT even though the perception of its usefulness may remain high, for instance because the learner has too many things to do and therefore needs to sacrifice a *side activity*. On the contrary, one can continue to use the tool for normative (task compliance) or social pressure (the colleagues use it), but without perceiving any real value.

On this topic, the contribution introduces a tentative scale, named Emotion Awareness Usefulness. The scale attempts to provide cues that accounts for the many facets of emotional awareness illustrated by the abstract model, including the right-hand side more tightly linked to meaning-making, which is more difficult to assess with pure performance-based indicators. The scale consists in seven dimensions -- frequency, affordance, social presence, self-understanding, understanding others, self-other comparison, and self-regulation -- derived from the literature and/or by the functions of emotional awareness. The scale is presented and discussed in the Material part of the Methods section below. The use of a validated usability scale, the System Usability Scale (SUS) by @brookeSUSQuickDirty1996, will also be used in this perspective. Question 2 (Q2) is stated as follows: what is the perception of usefulness of an EAT in asynchronous and non-collaborative settings, and does the perception of usefulness of different functions of an EAT change over time?

### Emotional Competence as an Intervening Factor {#ec-cycle-dew}

As discussed in various parts of the thesis (see for instance Sections \@ref(socio-affective-competences) and \@ref(emotional-competence-cpm)), some for of emotional expertise/competence/intelligence [@schererComponentialEmotionTheory2007; @hoemann2021; @brackettRULERTheoryDrivenSystemic2019] may play a prominent role in determining whether an EAT can be instrumental in a computer-mediated learning environment. If, for instance, the definition and composition of emotional competence as derived from the Component Process Model [@schererComponentialEmotionTheory2007] is retained, it is possible to overlap the three sub-competences (appraisal, communication, and regulation) with specific functions of the Dynamic Emotion Wheel:

-   The use of the sliders, corresponding to the cognitive evaluation of the situation, relies on the appraisal competence. An *adequate* assessment of the situation on relevant appraisal criteria can be helpful to initiate the meaning-making process.

-   The expression of the subjective feeling through a lexicalized emotion or custom emotion term relies to the communication competence. The formulation of an accurate integration/categorization of the whole emotional experience is instrumental both from the internal, symbolic processing of emotional information (intra-personal meaning-making), but also from the inter-personal perspective of sending a strategic signal for others to understand.

-   The emotion information available through the perceiving-monitoring side of the tool, at last, necessitates of an accurate reverse-engineering communicative strategy to infer the message behind the graphical representation, which can then be used for emotion regulation at the intra-personal or inter-personal levels.

Question 3 (Q3) therefore attempts at investigating whether some indicators of the use and/or perception of the EAT can be related to emotional competence. In this regard, congruently with the overall stance of the thesis that considers emotional competence something malleable, that can be acted upon, the construct will be measured through the use of a validated, performance-based test: the Geneva Emotion Competence (GECo) test [@schlegelGenevaEmotionalCompetence2018], illustrated in the Material part of the Methods section.

### Recollection of Individual and Collective Emotional Experience

An assumption that may be subsumed from the importance of emotional awareness is that the emotional experience can have lasting effects on the meaning that is attributed to a (computer-mediated) learning experience [@broschImpactEmotionPerception2013; @kensingerRetrievalEmotionalEvents2020; @montagrinGoalConducivenessKey2013; @poolAttentionalBiasPositive2015; @rimePartageSocialEmotions2005]. Question 4 (Q4) therefore aims at exploring whether the presence of an EAT contributes in *anchoring* the individual and collective affective experience during distance learning.

### In Search of Emotion-As-Interaction Cues: Comparing Two Different Classes

Finally, a last topic of interest explored in the present contribution is in somehow transversal to the four previous questions. It concerns whether the use and perception of an EAT depends *mainly* on the individual characteristics of the students or are *also* determined by the interaction between students using the tool at the same time [@dillenbourgSymmetryPartnerModelling2016; @boehnerHowEmotionMade2007]. Interacting factors may relate, for instance, to learners not using the tool because nobody else does, or, on the contrary, because everybody else does. Another possible interacting factor may concern a general pattern in the emotional experience, which may result from a group-level form of influence [@cheshinAngerHappinessVirtual2011; @barsadeGroupAffect2015; @vankleefEmotionalInfluenceGroups2017; @smithCanEmotionsBe2007]. For instance, @cheshinAngerHappinessVirtual2011 claim that emotional contagion can happen on virtual teams even if the communication between members is based only on text. One may therefore assume that the emotions of others can be all the more influencing on one's own emotional experience if there is a dedicated tool, overtly aimed at producing and perusing emotional information.

Taking advantage of the fact that two classes will use the EAT under very similar conditions -- and assuming no systematic factor at play determining particular type of students in one class compared to the other [@pearl2018; @pearl2018book; @rohrerThinkingClearlyCorrelations2018] -- wide differences between one class and the other would suggest the potential effect of interaction rather than individual characteristics alone. As previously stated, though, the exploratory nature of the study lacks the precision to quantify what is meant by *wide* differences. Consequently, results will be interpreted with respect to the available measures.

## Methods

Following @simmons21WordSolution2012 suggestion to increase transparency in experimental contributions, I report how I determined the sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

`r s2.participants_aggregated_all |> nrow()` students (`r (s2.participants_gender_age$gender == "F") |> sum()` women, `r (s2.participants_gender_age$gender == "M") |> sum()` men, and 5 not discoled) of the course *Sciences et Technologies de l'Information et de la Communication I* [@fritzPenseeComputationnelleAvec2019] in the Master of Science in Learning and Teaching Technologies at Geneva University took part in the study ($M_{age} =$ `r s2.participants_gender_age$age |> mean(na.rm = TRUE) |> printnum()`, $SD_{age} =$ `r s2.participants_gender_age$age |> sd(na.rm = TRUE) |> printnum()` with 7 not discolsed). Students belonged to two classes that took the one-semester course in two successive years during the period of the thesis: `r table(s2.participants_aggregated_all$group)[1]` students in the first class, and `r table(s2.participants_aggregated_all$group)[2]` students in the second, without overlapping. It is worth noting that a third cohort was originally planned to increase the sample size, but the study has not been implemented because this third cohort had to undergo an abrupt switch to an exclusive distance learning format due to the pandemic. Even though a completely online format would have been interesting for the purpose of the present study, the use of the EAT would have added up to an already complicated situation. Furthermore, the cohort would also have differed from the others in creating social links ,without the weeks with on-site sessions.

The use of the EAT during the course was warranted as a pedagogical activity, since the use of technological tools in learning situations is an integral part of the Master's program. Students had the choice, at the end of the course, either to sign a consent form allowing data to be used for research purposes, or to write on the same form only the ID they were given at the beginning of the study (without connection to their identity, see procedure below) so that all data associated with that ID could be erased. The overall sample size of the study is therefore determined by the number of students whose ID appears in at least one of the different sources of measure (see below) and has not been retracted via the *non-consent* form.

The population is clearly a convenience sample, but the choice has nevertheless both an explanation and a potential interest over and above the limitations. The explanation is preeminently of a technical nature. The EAT has never been adopted in a longitudinal study, where it must be seamlessly available even in the absence of the experimenter. Since the study implies comparison between two cohorts, it is therefore mandatory that technical problems should be signaled and repaired as soon as possible to maintain comparable settings. In this regard, MALTT students possess the technical know-how to identify and accurately describe malfunctioning in a web application, as well as a quick access to the technical team. The students are also exposed during the Master to an extensive use of different software and web applications, which helps to mitigate intervening factors related to technical skills.

The interest of the convenience sample is, ironically, its potential inconvenience. In fact, if the tool is adopted and considered as useful, results may be biased by the convenience sample, and therefore be taken with more than a grain of salt. On the other hand, if the tool is not adopted and considered of scarce usefulness, then the shortcomings are amplified, since even learners with an interest, habit, and technical know-how would not adopt it.

### Material

#### Configuration of the Emotion Awareness Tool

The toolbox was configured to take into account the longitudinal use of the EAT, which may happen at any time during any day of remote learning, as well as with any number of students connected at the same time. The configuration of the toolbox, depicted in Figure \@ref(fig:s2-dew-interface-figure), is thus implemented as follows.

For the expressing-displaying function of awareness, the same EATMINT circumplex was adopted. As a reminder, this affective space comprises 20 emotions organized over the two appraisal dimensions *Valence* and *Control/Power*. The rating of *Valence* was maintained as in the previous use of the circumplex, whereas for *Control/Power*, an attempt was made to reformulate the way it was prompted to increase its understanding and *independence* from the *Valence* dimension (see Section \@ref(gew-limitations)). The new wording adopted consisted in *Can you modify the situation?* Both dimensions were characterized by two opposite poles, labeled *Not at all* and *Yes, absolutely*. The choice and disposition of the subjective feelings is thoroughly depicted in Section \@ref(eatmint-circumplex).

For the perceiving-monitoring function of awareness, three word clouds were implemented. In a word cloud, words are depicted in a font whose size is proportional to the number of occurrences of that world, so that the more frequently used words appear bigger than the less frequently used ones. The perceiving-monitoring interface of the EAT comprised the following elements:

1.  A *Self-Centered* word cloud, depicting the last 50 subjective feelings expressed by the participant herself;
2.  A *Partners-Oriented* word cloud, depicting the last 100 subjective feelings expressed by the other members of the class, that is all the subjective feelings bar that of the participant herself;
3.  A *Group-Oriented* word cloud, depicting all the subjective feelings expressed by the whole class since the first use of the EAT, that is, those of the participant herself, plus those of the other members.

(ref:s2-dew-interface-caption) Interface of the EAT for a participant, depicting the expressing-displaying and perceiving-monitoring parts of the tool. For the perceiving-monitoring parts, the word clouds refer to the social functions of emotions identified by Fischer and Mastead [-@fischerSocialFunctionsEmotion2016]: affiliation and distancing (details in the text).

```{r s2-dew-interface-figure, fig.cap="(ref:s2-dew-interface-caption)", fig.align="center", out.width="50%"}
knitr::include_graphics(here::here("figure/s2/dew-interface.png"))
```

The combination of the three word clouds sustain the two main social functions of emotions identified by Fischer and Mastead [-@fischerSocialFunctionsEmotion2016]: the affiliation and the distancing function (see Section \@ref(ea-inter-personal)). The top and center word clouds allow participant to compare her own emotions (top) with that of the class (center). In this way, the learner can position herself with respect to the other students (distancing). The bottom word cloud groups all the emotions of the class and is therefore more related to the affiliation function of emotions. In an attempt to increase the perception of others, the title of the central word cloud also reported how many other participants were currently online.

The number of emotions proposed by each word cloud is arbitrary, since there is no previous benchmark about frequency of use in general, and expression in particular. The word cloud also presents *a priori* shortcomings with respect to subjective feelings typed directly by participants, since for them to be grouped, they should be written in exactly the same way (*e.g.*, a small typo would isolate that expression). This is particularly relevant in French, since when emotion terms are used as adjectives, the declination changes according to the gender of the respondents (e.g. *intéressé* vs. *intéressée* with an addiontal letter *e* at the end). All things considering, though, word clouds are relatively known graphical representations, and convey an immediate and straightforward method of aggregation.

Compared with the interface used in the study illustrated in the previous chapter, thus, the differences concern only the perceiving-monitoring part of the EAT. First, all the emotional information was conveyed through the subjective feelings, with no trace of the cognitive evaluation. This choice is technically justified by the lack, at the time being, of a grouped representation of the appraisal dimensions, since the line charts used in the previous study are limited to individuals. Second, no temporal reference appeared at all, since the subjective feelings were categorized based on the frequency alone. This choice is justified by the fact that, in an asynchronous and non-collaborative context, the temporal reference conveys limited information, especially considering that there is no manifest link between the time and a specific task or situation involved. Third, except for the participant's own emotions, it was not possible to discern what specific colleague has expressed a particular feeling or cluster of feelings. Once again, this choice is technically imposed by the lack, at the time being, of a grouped representation of feelings, which is able to maintain agency without overcrowding the interface. The choice is nevertheless also a theoretical influence, since in such a setting, the emotions of the colleagues are *truly* at a group level [@barsadeGroupAffect2015; @smithCanEmotionsBe2007; @vankleefEmotionalCollectivesHow2015]. More generally, without a previous benchmark about the number and frequency of emotions expressed in an asynchronous, individual situation, it was also difficult to establish grouping criterion (e.g. group by hour, by day, or by week). The grouped representation of emotions is an open issue that has just started to be investigate [see for instance @bersetVisualisationDonneesRecherche2018].

#### Emotion Awareness Usefulness Rating

The exploratory nature of the study was also considered the occasion to further advance the thesis overall perspective aiming at improving construct and internal validity in research gravitating around the concept of emotional awareness as defined in learning contexts. A central tenet of investigating a scientific construct is certainly the ability to measure it accurately, a topic that is receiving lately renewed interest [@flakeMeasurementSchmeasurementQuestionable2020; @boatengBestPracticesDeveloping2018]. Validated scale that are close to the construct exists, but they are limited to some specific facets of emotional awareness. For instance, the Emotion Awareness Questionnaire [@rieffeEmotionAwarenessInternalising2008] and the Levels of Emotional Awareness Scale [@laneLevelsEmotionalAwareness1990], cited in @lavoueEmotionAwarenessTools2020, relate to the individual context under clinical and personality psychology perspectives. They are not concerned with the inter-personal and instrumental use of emotional awareness in learning situations. There are also existing scales that measure the *social presence* construct, such as in @tuRelationshipSocialPresence2002 or @kreijnsMeasuringPerceivedSocial2011, but they do not specifically target the affective or emotional facet specifically. Finally, there are scales to measure emotion in academic contexts, such as in @pekrun2011 and @pekrunMeasuringEmotionsEpistemic2016, but they aim at knowing the specific emotional experience of learners (e.g. through a list of discrete emotions), whereas in this case it is the meta-evaluation of emotional awareness that is at stake.

Based on these assumptions, the study introduces a tentative scale, the Emotion Awareness Usefulness (EAU), which aims at measuring emotional awareness specifically as a support for learning contexts. At the same time, the scale is intended to be as general as possible, without, for instance, making any reference to specific features of the EAT or the learning task. The aim, once again, is to provide an instrument that can foster comparison between studies. In this regard, the scale identify 7 dimensions that may be relevant to many situations in which emotional awareness is provided through an EAT:

1.  **Frequency**. The frequency of use is a dimension used in different scales pertaining to Human-Computer Interaction and User Experience [@mackenzieHumanComputerInteractionEmpirical2013; @tullisMeasuringUserExperience2013], as it is the case in the System Usability Scale [@brookeSUSQuickDirty1996]. The more frequently a tool is used, the more useful it is perceived, especially when the use is voluntary.

2.  **Affordance**. Affordance in this context broadly refers to the actions available through the EAT and to what extent these actions are evoked by the tool [@normanDesignEverydayThings2013; @suthersTechnologyAffordancesIntersubjective2006; @rizzoOriginDesignIntentional2006]. For instance, the presence of an EAT may prompt users to express/share their emotions, something they would not do without the presence of the tool [e.g., @parkinsonEmotionsDirectRemote2008; @rimeEmotionElicitsSocial2009; @vankleefInterpersonalDynamicsEmotion2018].

3.  **Social Presence**. Social presence is a pivotal dimension in remote learning, providing support for learners isolation and feeling of loneliness [e.g., @kreijnsMeasuringPerceivedSocial2011; @jezegouCreerPresenceDistance2010]. Perceiving the emotions of colleagues can help learners to remember there are others in the same condition as they are.

4.  **Self-Understanding**. Having emotions a strong influence on intra-personal functions [e.g., @broschImpactEmotionPerception2013; @levensonIntrapersonalFunctionsEmotion1999; @schererWhatAreEmotions2005], the presence of an EAT may contribute to a better self-assessment of the situation and its consequences on learners' behavior [@ruizSupportingLearningConsidering2016; @lavoueEmotionAwarenessTools2020].

5.  **Understanding Others**. The presence of the emotions of colleagues through the EAT may inform learners about what others are experiencing during the remote learning periods, providing information to build and update a mental model of the causes of and consequences on their behavior [e.g., @dillenbourgSymmetryPartnerModelling2016; @vankleefEmergingViewEmotion2010; @vankleefEmotionalInfluenceGroups2017; @vankleefInterpersonalDynamicsEmotion2018]

6.  **Self-Other Comparison**. Comparing one's own emotions with that of the colleagues can provide useful information, especially in situation of incertitude [e.g., @eligioEmotionUnderstandingPerformance2012; @molinariEmotionFeedbackComputermediated2013; @vandevenEnvyAdmirationEmotion2017]. The presence of the EAT may facilitate and prompt this comparison.

7.  **Self-Regulation**. Emotion regulation is a pivotal phenomenon that allows learners to modify their emotional experience using different strategies, such as suppression or reappraisal, in order to maintain instrumental emotional states and modify disruptive ones [e.g., @arguedasAnalyzingHowEmotion2016; @grossEmotionRegulationCurrent2015; @grossHandbookEmotionRegulation2014; @jarvenojaRegulationEmotionsSocially2013]. The presence of the EAT may facilitate regulatory processes both in terms of learners own emotions and that of the colleagues.

The items have been derived or adapted, when possible, from existing scales. Every item can be rated on a scale from 1 (strongly disagree) to 10 (strongly agree). The precise wording of each item is depicted in Table \@ref(tab:eau-table).

(ref:eau-table-caption) Dimensions and respective items of the Emotion Awareness Usefulness (EAU) scale

```{r eau-table}
eau_description <- tibble::tribble(
  ~"#",
  ~"Dimension",
  ~"Item",
  "1",
  "Frequency",
  "I used the tool frequently (e.g. every time I worked for the course).",
  "2",
  "Affordance",
  "The use of the tool prompted me to share my emotions.", 
  "3",
  "Social Presence",
  "The use of the tool allowed me to feel less lonely during remote learning periods.",
  "4",
  "Self-Understanding",
  "The use of the tool allowed me to better understand my emotions.",
  "5",
  "Understanding Others",
  "The use of the tool allowed me to better understand the emotions of my colleagues.",
  "6",
  "Self-Other Comparison",
  "The use fo the tool allowed me to compare my emotions with those of my colleagues.",
  "7",
  "Self-Regulation",
  "The use of the tool allowed me to regulate my emotions."
)

eau_description |> 
  kable(
    caption = "(ref:eau-table-caption)\\label{tab:eau-table}",
    caption.short = "EAU scale composition",
    longtable = TRUE,
    booktabs = TRUE,
    linesep = "\\addlinespace"
  ) |> 
  column_spec(1, width = "1em") |> 
  column_spec(2, width = "10em") |> 
  column_spec(3, width = "22em") |> 
  kable_styling(latex_options = "HOLD_position")

```

The scale is very straightforward and with only a few items, specifically a single item per dimension. This is a potential shortcoming from a reliability and validity standpoint [@boatengBestPracticesDeveloping2018], but, especially in a repeated measure design, brevity has been considered an important factor. Furthermore, the convenience sample of the study provides some leverage on the formulation of items. MALTT students are, for instance, familiar with terms such as *regulation*, which may be too technical for other populations and therefore would require a more explicit formulation.

#### System Usability Scale

The System Usability Scale (SUS) is a widely adopted scale that measures the usability of a tool [@brookeSUSQuickDirty1996]. It comprises 10 items, usually on a 5-point scale, but that can also be adapted to a 7-point range, which has been the case for this study. The 10 items of the scale are the following:

1.  I think that I would like to use this system frequently
2.  I found the system unnecessarily complex
3.  I thought the system was easy to use
4.  I think that I would need the support of a technical person to be able to use this system
5.  I found the various functions in this system were well integrated
6.  I thought there was too much inconsistency in this system
7.  I would imagine that most people would learn to use this system very quickly
8.  I found the system very cumbersome to use
9.  I felt very confident using the system
10. I needed to learn a lot of things before I could get going with this system

The even items of the scale are reversed, so that a lower evaluation on the item corresponds to a greater perceived usability. The scale uses a system of coefficients that add up to obtain a score between 0 and 100. A more thorough discussion of the scale is available in the next chapter, where the usability score of the SUS will be compared between the usability test (Fritz, 2015) and the score obtained in the present study.

#### Geneva Emotional Competence Test

The Geneva Emotional Competence (GECo) test [@schlegelGenevaEmotionalCompetence2018] is a performance-based test that measures emotional competence as an ability, rather than a trait [@chernissEmotionalIntelligenceClarification2010; @saloveyEmotionalIntelligence1990; @schererComponentialEmotionTheory2007]. The test is primarily aimed at emotions in a workplace, but it may be considered that a working environment and a learning environment share many similarities in terms of intra-personal and inter-personal dynamics. The test is divided in 4 sub-competences parts, namely emotion recognition, emotion understanding, emotion regulation, and emotion management.

Emotion recognition determines the ability to infer the corresponding emotional state of a person using video clips of actors. Participants look and hear a professional actor expressing a pre-defined emotion using facial expression and pronouncing pseudo-words with a corresponding vocal prosody. Participants must identify the episode among several lexicalized emotions.

Emotion understanding determines the ability to infer the corresponding emotional state of a person based on a description of a situation. Participants read the details of an event that occurs to another person and must infer which emotion, among a list of discrete options, has been elicited by that event.

Emotion regulation determines the ability in engaging in adaptive (vs. disruptive) strategies to modify one's own emotional state. Participants read the description of a situation they must imagine has happened to them, which is meant to trigger disruptive emotional episodes. Respondents must then identify among four choices the two appropriate strategies, which allows the person to switch to a more adaptive emotional experience.

Emotion management determines the ability to adopt the better strategy to handle situations eliciting disruptive emotions in others. Participants read a vignette depicting a situation in which they interact with another person. The situation is meant to elicit in that other person a disruptive emotional response such as anger, irritation or misplaced happiness (*i.e.* the test considers that also *positively valenced* emotions may be disruptive). The participant can then choose between 5 different strategies to manage the emotional response of the other person, among which one is considered to be the more appropriate.

Each sub-test yields a score of accuracy. The 4 scores can then be combined to obtain an overall emotional competence score.

#### Individual and Class Perceived Frequency of Feelings

Considering the fact that the word clouds adopted in the perceiving-monitoring part of the EAT clearly define which feelings have been experienced more frequently than others, the study comprises a survey that asks participants, at the end of the semester, to rate the frequency by which (1) they recall having felt each of the 20 subjective feelings of the EATMINT circumplex ; and (2) they recall their colleagues having felt each of the same 20 subjective feelings. In the survey, each subjective feeling is presented with a 5-point scale comprising *never*, *seldom*, *sometimes*, *often* and *very often*. Participants were also allowed to skip each particular feeling without rating the frequency both in the individual and the class surveys.

### Procedure

All courses of the Master are organized in three periods per semester, which will defined by P1, P2 and P3. Each period is composed by a week of on-site courses, and 4-5 weeks of remote learning. In order to let students get familiar with distance learning, the use of the tool was integrated only from P2. In this way, students had P1 to get acquainted with the difficulties of distance learning, and could therefore better assess the usefulness of an awareness tool in general, and of an EAT in the specific case of this contribution.

During the on-site course of P2, students were informed that they would be asked to use the EAT as a corollary activity in the course. They were also informed that, beside the pedagogical interest of the activity, the use of the EAT was linked with a research topic and that data could therefore be used under specific conditions. The distinction between the participation to the *compulsory* pedagogical activity and the voluntary participation to the research was clearly explained, and students were asked to read a consent form that was linked into the private work-space of the course. They then drew an ID from a urn, which they would use for any interaction with the EAT or with the surveys. With the ID, which was unique for each student, they also received a common code for each class.

#### Expectancy Survey

At this point, each student was asked to fill the *Expectancy* survey in order to collect their perception of the use of an EAT before actually using it. The survey was simply introduced by this description:

> An emotion awareness tool is a tool that allows to share one's own emotions with other people in a computer-mediated context. The tool has two main function: (1) it allows the user to express her own emotions and make them visible to the other users who are using the tool; and (2) it allows the user to perceive the emotions of the other users who have access to the same tool. You will have access to an emotion awareness tool for the two remote periods of the course, so that you can use it while you are working on STIC I: while you are reading the pedagogical material, you are coding the devices for your exercises, or you are contributing to the Wiki.

The questions of the EAU were the same as described in the material above, except that they were transformed in a prospective tense. For instance, *I think I will use this tool frequently* or *I think the tool will prompt me to share my emotions*.

#### Demo Survey

Once filled the *Expectancy* survey, students were introduced to the EAT through a demo. They discovered the interface they will be using throughout distance periods of the course, and they could directly test the functioning of the tool by expressing emotions, knowing those will not be recorded. The general functioning of the tool (*i.e.,* the use of the appraisal dimensions and the choice of the subjective feeling) was explained. After 5 minutes of practicing with the tool, students took the *Demo* survey, which is exactly the same survey as the *Expectancy*, comprising the dimensions of the EAU in the prospective tense.

#### Set-Up of the EAT for Distance Periods

Towards the end of the on-site session in which the tool was presented, the set-up of the EAT for the actual use was organized. Since it was not possible to combine the EAT on the same interface with the various tools students use as part of the course, a generic web page was therefore the only flexible solution. Students saw how the window could be adapted and put beside another window (*e.g.,* of a software or of another web page) in order to have the EAT close to the task at hand. To ease the access to the EAT, students created a bookmark in their browser that would automatically log them in with their unique ID and the code of the class.

Practically, then, students were supposed to open their browser, click on the bookmark pointing to the EAT, resize the window and place it beside the activity they were performing for the course. Or, alternatively, keep it minimized on their operating system task area and maximize it on recall. In both cases, the use of the EAT required a deliberate action outside the *normal* work-flow of the course.

#### Halfway Survey

During the on-site course of P3, students filled in the *Halfway* survey, after a whole period (i.e. 5 weeks) of use of the tool during remote learning. The survey comprised the EAU dimensions in retrospective tense (*e.g.*, *I have used the tool frequently* or *The tool has prompted me to share my emotions*), as well as an open-ended question in which students could provide additional information about their experience with the EAT.

#### Final Survey

Students filled the *final* survey during the first on-site course of a follow-up course (STIC II) in the next semester, that is after 9 weeks from the *halfway* survey. The long period is the result of 5 weeks of *normal* remote learning, interrupted by 2 weeks of Christmas' leave in December (in which students often works, though), and 2 weeks of end-of-semester leave. The EAT was available until the formal end of semester. It has been decided to ask students to fill in the *final* survey on-site, even with two weeks delay compared to the end of the semester, in order to maximize data collection. The *final* survey comprised:

-   The EAU survey in retrospective tense (same as *halfway* survey);
-   The System Usability Scale [@brookeSUSQuickDirty1996], but with a 7-point scale rather than the usual 5-point scale;
-   A survey asking participants to rate the frequency with which they have experienced the 20 subjective feelings belonging to the underlying affective space of the DEW;
-   A survey asking participants to rate the same feelings, but with respect to the frequency with which their colleagues have felt them during the remote periods;
-   An open-ended question in which students could provide additional information about their experience with the tool.

#### Reminders

Reminders to use the EAT during remote learning periods were dispatched twice per periods (P2 and P3) within messages in the private space of the course. The reminders were integrated into wider communications, for instance the feedback of an exercise.

#### Geneva Emotional Competence Online Survey

In the private work-space of the course, students could find a link to the Geneva Emotional Competence (GECo, @schlegelGenevaEmotionalCompetence2018) test. The presence of the link was reminded at each on-site course, but students were clearly informed that the test was exclusively part of the research, so they were not forced to take it. Students could therefore take the test anytime during the P2 or P3 periods. Considering that there is no evidence yet that the use of an EAT in this context could improve the emotional competence of a person, especially in a performance-based test, this option left more time for students to take a long test during a very active period of learning. Students deciding to take the test had only to provide their anonymous ID.

### Exclusion Criteria

Having no previous reference for data collection, *a priori* exclusion criteria were difficult to formalize. Since there was the possibility of students dropping out either from the Master or from the research activity (e.g. refusing to fill-in the surveys), participants not having filled both the *halfway* and the *final* survey will be considered as if they dropped out and will thus be excluded from data analysis.

## Results

Results are based on $N = `r s2.participants_aggregated |> nrow()`$ participants. `r (s2.participants_aggregated_all |> nrow()) - (s2.participants_aggregated |> nrow())` students did not fill neither the *halfway* nor the *final* survey and were therefore excluded from the analysis. As mentioned above, it was considered that they have dropped off either from the course or the research. Table \@ref(tab:s2-descriptive-table) depicts the number of participants retained for each class across the 4 longitudinal surveys *expectancy*, *demo*, *halfway* and *final*, for which the two classes have very similar -- if not equal -- sample sizes.

(ref:s2-descriptive-table-caption) Number of participants retained for each class in total, and with respect to the 4 longitudinal surveys.

```{r s2-descriptive-table}
s2.valid_results_description |> 
  kable(
    col.names = c(NULL, "Class 1", "Class 2"),
    booktabs = TRUE,
    digits = 2,
    caption = "(ref:s2-descriptive-table-caption)\\label{tab:s2-descriptive-table}",
    caption.short = "Study 2: Descriptive statistics",
    longtable = FALSE,
  ) |>
  kable_styling(latex_options = "HOLD_position")
```

### Measures About the Use of the EAT

Data about the adoption and use of the tool are limited here to the number of emotions expressed. This is clearly a shortcoming, since, potentially, participants could have perused the emotional information available on the interface without expressing any emotion (ever, or only during a specific session). As illustrated in the presentation of the toolbox, it would have been possible to use the accesses of participants to provide a more accurate estimation of the adoption and use. Nevertheless, the feature was developed too late, once the design of the study was already finalized, and in the information to participants, as well as in the consent form, there was no mention of recording participants accesses. For this reason, data related to accesses have been erased.

Overall, participants expressed `r s2.participants_aggregated$num_emotions |> sum()` emotions through the EAT, that is a mean of `r maf.print_m_sd(s2.participants_aggregated$num_emotions, TRUE, TRUE)`. One student in Class 1 and three students in Class 2 did not express any emotions at all. As mentioned above, this does not rule out the possibility that they nevertheless have accessed the tool. They are therefore kept into the analysis.

In comparing the two classes, the number of emotions expressed is similar with respect to the central tendency ($M_{class1} = 11.47$ against $M_{class2} = 13.47$), but differs greatly in variation ($SD_{class1} = 21.69$ against $SD_{class2} = 11.79$). The greater SD of Class 1 results in particular by a single participant that expressed 86 emotions. In Class 2, the greatest number of emotions expressed is 34. Taking the median as a more robust reference of comparison, the difference between Class 1 ($Mdn = 3$) and Class 2 ($Mdn = 12$) is much more evident. Figure \@ref(fig:s2-graph-emotions-expressed-boxplot) compares the expression of emotions between the two classes.

(ref:s2-graph-emotions-expressed-boxplot-caption) Boxplot comparing the expression of emotions between the two classes.

```{r s2-graph-emotions-expressed-boxplot, fig.align="center", fig.width=4, fig.height=2.5, fig.cap="(ref:s2-graph-emotions-expressed-boxplot-caption)"}
s2.graph_expressed_emotions_boxplot
```

The use of the tool with respect to the longitudinal duration of the course is depicted in Figure \@ref(fig:s2-graph-expressed-emotions-over-time). The classes have similar profiles in the cumulative number of emotions expressed over time, alternating phases in which they express emotions with periods of pause.

(ref:s2-graph-expressed-emotions-over-time-caption) Cumulative number of emotions expressed through the EAT

```{r s2-graph-expressed-emotions-over-time, fig.align='center', out.width="80%", fig.cap="(ref:s2-graph-expressed-emotions-over-time-caption)"}
s2.graph_expressed_emotions_over_time
```

Overall, it is safe to assume that Class 2 made a more thorough and homogeneous use of the EAT in expressing emotions compared to Class 1, even though the use in expressing emotions remains, overall, limited to a few participants that expressed most of the emotions.

### Emotion Awareness Usefulness

Being the first adoption of the Emotion Awareness Usefulness (EAU) scale, it is useful to start by evaluating the sensibility of the scale in terms of overall dispersion for each of the 7 underlying dimensions, namely *Frequency*, *Affordance*, *Social Presence*, *Self-Understanding*, *Understanding Others*, *Self-Other Comparison*, and *Self-Regulation*. In Figure \@ref(fig:s2-eda-dimensions-dispersion-graph) every circle represents one of the $N=`r s2.ea_usefulness |> nrow()`$ ratings, which was made on a scale from 1 to 10, for each dimension across surveys and participants. The dispersion for each of the 7 dimensions spans the entire range of the rating, suggesting that each dimension has a good sensibility.

(ref:s2-eda-dimensions-dispersion-graph-caption) Overall ratings of each of the 7 EAU dimensions, $N=`r s2.ea_usefulness |> nrow()`$ ratings. Bars represent 95% confidence intervals around the overall mean.

```{r s2-eda-dimensions-dispersion-graph, fig.cap="(ref:s2-eda-dimensions-dispersion-graph-caption)", out.width="80%", fig.align='center'}
s2.eda.dimensions_dispersion
```

This preliminary assessment therefore corroborates the interest to investigate more specific patterns in the rating of each of the 7 dimensions with respect to the change over time and differences between classes. Table \@ref(tab:s2-description-EAU-stratified) depicts means and standard deviations of the 7 dimensions stratified for the two classes across the 4 longitudinal surveys.

(ref:s2-description-EAU-stratified-caption) Means and (standard deviations) of the EAU ratings across longitudinal surveys.

```{r s2-description-EAU-stratified}
s2.ea_usefulness.descriptive_stratified |>
  select(-dimension) |> 
kable(
    booktabs = TRUE,
    digits = 2,
    caption = "(ref:s2-description-EAU-stratified-caption)\\label{tab:s2-description-EAU-stratified}",
    caption.short = "Study 2: EAU means and standard deviations",
    longtable = FALSE,
    linesep = c("", "", "\\addlinespace")
  ) |> 
  kable_styling(
    latex_options = c("repeat_header")
  ) |> 
  row_spec(c(3, 6, 9, 12, 15, 18, 21), bold = T) |> 
  pack_rows(
    index = c(
      "Frequency" = 3, 
      "Affordance" = 3, 
      "Social Presence" = 3,
      "Self-Understanding" = 3,
      "Understanding Others" = 3,
      "Self-Other Comparison" = 3,
      "Self-Regulation" = 3
    )
  ) |>
  kable_styling(latex_options = "HOLD_position")

```

In order to assess the presence of effects in the above ratings, a linear mixed-model, also known as multilevel linear models [@finchMultilevelModelingUsing2019; @westLinearMixedModels2015], was fitted to the data with the following parameters. The dependent variable is the singular value, from 1 to 10, expressed on each dimension of the EAU in the 4 surveys. The fixed covariates are (1) the longitudinal survey with 4 levels (*Expectancy*, *Demo*, *Halfway*, and *Final*); (2) the specific dimension of the EAU with 7 levels (*Frequency*, *Affordance*, *Social Presence*, *Self-Understanding*, *Understanding Others*, *Self-Other Comparison*, and *Self-Regulation*); and (3) the group each student belongs to with 2 conditions (*Class 1* or *Class 2*). All the two-way interactions between pairwise covariates, as well as the three-way interaction, were also fitted in the model. The random covariates account for the nested structure of the observations: the repeated measure of the participant is nested inside the class to which the participant belongs.

The use of a linear-mixed model is warranted by a better flexibility compared to repeated-measure ANOVA, especially in case of missing data. Furthermore, linear-mixed models allow to account both for the repeated measures per participant and the nested, hierarchical structure of residuals, with participants potentially influenced by the use of the tool made by the colleagues in their class, which would violate the non-independence of residuals in ordinary least square regression. Finally, it allows to keep each dimension separate rather than averaging over a single score, which will loose an interesting source of variance with respect to the 7 dimensions of the EAU (see @finchMultilevelModelingUsing2019; @mcelreathStatisticalRethinkingBayesian2020; @singmannIntroductionMixedModels2020; @westLinearMixedModels2015; @brownIntroductionLinearMixedEffects2021 for a more comprehensive overview of linear mixed models compared to ordinary least square regression).

The linear mixed model analyzing the score on the EAU scale was fitted using the mixed function of the Afex [@singmannAfexAnalysisFactorial2020; @singmannIntroductionMixedModels2020] R package version `r packageVersion("afex")`. A Type III analysis of variance of the multilevel linear model detected effects for the longitudinal survey and the dimension of the EAU scale, but not for the group. Two-way interactions were detected between the group and the EAU dimension as well as between the EAU dimension and the longitudinal survey, but not between the group and the longitudinal survey. Finally, the three-way interaction between group, longitudinal survey and EAU dimension was not detected. Results are depicted in Table \@ref(tab:s2-mlm-eau-table) using Kenward-Roger approximation for computing the *p*-value [@lukeEvaluatingSignificanceLinear2017].

(ref:s2-mlm-eau-caption) Results of a Type III ANOVA on the fitted multilevel linear model using Kenward-Roger approximation for computing the *p*-value

```{r s2-mlm-eau-table}
s2.mlm.ea_usefulness.anova_table |>
  kable(
    booktabs = TRUE,
    longtable = FALSE,
    digits = 3,
    caption = "(ref:s2-mlm-eau-caption)\\label{tab:s2-mlm-eau-table}",
    caption.short = "Study 2: Emotion Awareness Multilevel Linear Model",
    linesep = c("", "",  "\\addlinespace")
  ) |>
  kable_styling(latex_options = "HOLD_position")
```

Results are graphically depicted in Figure \@ref(fig:s2-graph-dimensions-and-survey), in which the EAU evaluation is stratified by the 7 dimensions of the scale and the 4 longitudinal surveys, as well as divided between the 2 classes. Data show high *expectancy* ratings for the *Frequency*, *Affordance*, *Social Presence*, *Understanding Others*, and *Self-Other Comparison* dimensions, but not for *Self-Understanding* and *Self-Regulation*. The ratings are generally maintained even after the *demo* surveys and tend to decrease with the actual use of the tool in the *halfway* survey, to remain then more or less stable even in the *final* survey. Data also show that the two classes basically overlap on all dimensions and across longitudinal surveys. The group per dimension interaction is probably yielded by the *Frequency* and *Affordance* dimensions, for which the two classes differ the most, but it does not seem to play an important role in differentiating EAU ratings. As a consequence, the factor related to the class is dropped in post-hoc contrasts, which will focus only on the difference between the *Final* and the *Expectancy* surveys.

(ref:s2-graph-dimensions-and-survey-caption) EAU rating over longitudinal surveys stratified by dimensions and grouped by class. Bars represents 95% confidence interval and the dashed gray line the median point of the scale.

```{r s2-graph-dimensions-and-survey, fig.align="center", fig.cap="(ref:s2-graph-dimensions-and-survey-caption)"}
s2.ea_usefulness.graph
```

Results of the post-hoc contrasts averaged over group and stratified across EAU dimensions are illustrated in Table \@ref(tab:s2-eau-contrasts-table). Contrasts detect differences between the *Final* and the *Expectancy* surveys in every dimension except the *Self-Understanding* one. All detectable differences highlight a decrease in perceived EAU, with the greatest decrease for *Self-Other Comparison* and *Social Presence* (almost 3 rating points), followed by *Understanding Others* and *Affordance* (more than 2 rating points), and finishing with *Frequency* and *Self-Regulation* (more than 1 rating point).

(ref:s2-eau-contrasts-caption) Contrasts between the Final and the Expectancy surveys for each of the 7 dimensions of the EAU scale averaged over the two classes.

```{r s2-eau-contrasts-table}
s2.mlm.ea_usefulness.comparison |> 
  as_tibble() |>
  mutate(
    p.value = round_ps_apa(p.value)
  ) |> 
  kable(
    digits = 3,
    caption = "(ref:s2-eau-contrasts-caption)\\label{tab:s2-eau-contrasts-table}",
    caption.short = "Study 2: Contrasts between Final and Expectancy surveys per EAU dimension",
    longtable = FALSE,
    booktabs = TRUE
  ) |> 
  kable_styling(
    latex_options = c("repeat_header")
  ) |>
  kable_styling(latex_options = "HOLD_position")
```

### Structure and Reliability of the Emotion Usefulness Scale

Even though the use of multilevel linear model is more adequate for a fine grained assessment of the tentative scale, it is worth exploring whether the Emotion Awareness Usefulness scale (EAU) proposes structural features that may be of interest for future use. In this regard, the way the scale has been administered is somehow atypical. On the one hand, participants rated the scale on multiple occasion, which is consistent with the test/re-test paradigm. On the other hand, the conditions in which the scale has been administered where obviously not the same, since the aim of the contribution was to measure the change of perception over time rather then the consistency of the scale. For an exploratory purpose, it could be informative to relax some of the habitual boundaries in reliability measures and *pretend* that each administration of the survey was unique, even when the rater was the same. This choice is warranted by two elements. First, it increases the sample size of measures compared to taking just one of the four survey in which the scale has been administered. Second, if the repeated measure of the administration is taken into consideration, there will be essential overlapping with the multilevel analysis performed above. For these reasons, all $N = `r s2.ea_usefulness_scale.all |> nrow()`$ administrations of the scale will be considered in the analysis.

Two types of analyses will be conducted to explore the structure and reliability of the EAU. First, it is worth assessing to what extent the scale can be considered as uni-dimensional, that is, measuring a single underlying latent variable, represented in this case by the perceived usefulness of disposing of emotional awareness. Second, it is also worth exploring whether there is an underlying structure of more than one factor.

#### Uni-Dimensionality

For determining the existence of a single, common factor, there is a growing consensus in considering that Cronbach's $\alpha$ is not the most adequate choice [see for exemple @hayesUseOmegaRather2020; @revelleReliabilityTutorial2019; @sijtsmaUseMisuseVery2009]. In this regard, @revelleReliabilityTutorial2019 suggest that more than one indicator of the psychometric properties of the scale should be reported. The table below illustrates indicators of reliability computed using the psych R package [@revellePsychProceduresPsychological2021], used here in version `r packageVersion("psych")`.

| $\omega_h$ | $\alpha$ | $\omega_{tot}$ | Uni  | r.fit | fa.fit | max.split | min.split | mean.r | med.r |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| 0.6        | 0.86     | 0.9            | 0.86 | 0.92  | 0.93   | 0.88      | 0.71      | 0.46   | 0.35  |

: Reliability measures of the EAU scale

All indicators seem to converge on moderate to high values, which corroborates the reliability of the scale. For the purpose of this study, particular attention is focused on the *Uni* indicator, which is computed through the *unidim* function of the psych package (*ibid*.). The function is described as follows:

> There are a variety of ways of assessing whether a set of items measures one latent trait. unidim is just one more way. If a one factor model holds in the data, then the factor analytic decomposition F implies that FF' should reproduce the correlations with communalities along the diagonal. In this case, the fit FF' should be identical to the correlation matrix minus the uniquenesses. unidim is just the ratio of these two estimates. The higher it is, the more the evidence for unidimensionality.

Results of fitting the *unidim* approach to the EAU yields a unidimensionality index of `r s2.eau.unidim$uni[1] |> printnum()`, with a fit of the average correlation to the matrix of `r s2.eau.unidim$uni[2] |> printnum()`. This may suggest that the scale can, in principle, be reduced to a unidimensional latent factor.

#### Exploratory Factor Analysis

Even though the scale provides a good approximation for a single factor, it is still worth examining if more than one factor better fit the structure. The exploratory factor analysis will be conducted in two steps using again the psych R package [@revellePsychProceduresPsychological2021] version `r packageVersion("psych")`. First, a scree test is conducted to determine the number of factors that account for the greatest variance. Then, this number of factors is used in an exploratory factor analysis to retrieve the loading of the seven dimensions of the EAU on the suggested number of factors.

The scree test pictured in Figure \@ref(fig:s2-scree-plot-graph) suggests that three factors account for a fair amount of variance, with small gain achieved by adding a fourth or a fifth dimension.

(ref:s2-scree-plot-caption) Scree plot based on all the EAU surveys administered. $N = `r s2.ea_usefulness_scale.all |> nrow()`$

```{r s2-scree-plot-graph, fig.align="center", fig.cap="(ref:s2-scree-plot-caption)"}
scree(s2.ea_usefulness_scale.all, pc = FALSE)
```

An exploratory factor analysis with three factors, using the *minimum residuals* method of extraction with the *oblimin* rotation, results in the following loading of dimensions:

1.  The first factor comprises *Social Presence*, *Understanding Others*, and *Self-Other Comparison* dimensions, that is the more *partner(s)-oriented* dimensions.
2.  The second factor includes *Self-Understanding* and *Self-Regulation* dimensions, that is the more *self-centered* dimensions of emotional awareness. The second factor also relates to *Social Presence*, which also loads on the first factor, and *Frequency*, shared with the third factor, but both with a lower coefficient;
3.  The third factor represents *Frequency* and *Affordance* dimensions, that is the more *usability related* dimensions.

The diagram in Figure \@ref(fig:s2-factor-analysis-graph) reports the coefficients of loading. The overall reliability scores are Cronbach's $\alpha =$ `r s2.eau.fa$alpha |> printnum()`, $\omega_{h}$ = `r s2.eau.fa$omega_h |> printnum()`, and $\omega_{t}$ = `r s2.eau.fa$omega.tot |> printnum()`, which suggest good reliability of the scale. Incomplete and tentative, the EAU seems nevertheless a rather promising scale that can be expanded in further research.

(ref:s2-factor-analysis-caption) Graphical representation of the exploratory factor analysis

```{r s2-factor-analysis-graph, fig.align="left", fig.cap="(ref:s2-factor-analysis-caption)"}
omega.diagram(s2.eau.fa, main = "", marg = c(5,0,0,0))
```

### Emotion Awareness Usefulness and Emotional Competence

The study also included the possibility to take the Geneva Emotion Competence (GECo) test [@schlegelGenevaEmotionalCompetence2018] anytime before the end of the semester. As a reminder, the GECo is a performance-based test measuring participants' emotional competence on four sub-competences: emotion recognition, emotion understanding, emotion regulation, and emotion management. Given the test was a corollary activity related only to the research -- and that the test is demanding in terms of time and effort due to its accuracy -- only $N = `r s2.geco_score_to_eau.wider |> nrow()`$ participants took it. This limits the possibility of exploring relationship between emotional competence and other indicators collected throughout the study beyond a descriptive perspective. In the meantime, participants that did take the test used their precious time during an intense phase of their education, which deserves gratitude and consideration.

Given the overall limited use that has been done of the EAT, the more interesting measure at hand to be related to emotional competence is the prospected usefulness measured in the *Expectancy* survey using the EAU scale. The unidimensionality coefficients exposed above suggest that the average score of the EAU can be, at least in the exploratory context, retained as an indicator of perceived usefulness of emotional awareness and therefore represent the measure of interest. With these premises, the most informative test retained in this case is the use of a Bayesian linear model using informed priors [@mcelreathStatisticalRethinkingBayesian2020; @wagenmakersBayesianInferencePsychology2018a; @dienesHowBayesFactors2016; @etzIntroductionBayesianInference2018; @makowskiIndicesEffectExistence2019]. Bayesian analysis is gaining interest in the social sciences (*ibid.*) and in this specific case, where the analysis is exploratory, it may represent a good attempt to obtain the most information from the small sample at hand.

In the model, thus, the outcome variable is represented by the unidimensional average of the EAU score and the predictors are the four sub-competences of the GECo test. The aim of the test is to explore whether specific sub-competences seem to be more related to the overall expectation of the perceived potential of emotional awareness. As informed priors, the model uses the means and standard deviations observed in Study 1 in @schlegelGenevaEmotionalCompetence2018, where the GECo is validated. The measures are reported in Table 1 of the original article on page 9. Among the 5 studies on which the GECo has been validated, the first is the one whose population is closer to the participants in this study. Participants to the GECo validation's Study 1 were in fact 149 students from different faculties at the University of Geneva, and the test was administered in French as it was the case for this study. In Study 1 of the GECo validation, the score of the sub-competences were the following: $M_{Recognition} =$ 0.66 ($SD =$ 0.13); $M_{Understanding} =$ 0.70 ($SD =$ 0.16); $M_{Regulation} =$ 1.12 ($SD =$ 0.22); $M_{Management} =$ 0.45 ($SD =$ 0.18). For the $N$ = 11 participants in this study, the scores to the same sub-competences were: $M_{Recognition} =$ 0.73 ($SD =$ 0.11); $M_{Understanding} =$ 0.78 ($SD =$ 0.17); $M_{Regulation} =$ 0.57 ($SD =$ 0.10); $M_{Management} =$ 0.55 ($SD =$ 0.15). The regulation sub-competence is therefore the only one that seems to deviate considerably from the validation's sample, with an observed mean that is half the score observed in @schlegelGenevaEmotionalCompetence2018. Notwithstanding this huge difference -- for which, honestly, an explication is difficult to provide -- the priors seem adequate to normalize the parameters and provide an informed framework for a Bayesian linear model [@mcelreathStatisticalRethinkingBayesian2020].

The analysis was performed using the rstanarm version 2.21.3 R package [@goodrichRstanarmBayesianApplied2022]. The model was estimated using the Markov Chain Monte-Carlo sampling, with 4 chains of 10'000 iterations and a warm-up of 5'000. The prior were scaled internally by the model to provide some leverage considering the small sample size at hand. Otherwise, the poster distribution would have basically confirmed the strong priors [@goodrichRstanarmBayesianApplied2022]. The adjusted standard deviation for the prior was respectively of $SD_{Recognition}$ = 1.47, $SD_{Understanding}$ = 1.16, $SD_{Regulation}$ = 2.76, and $SD_{Management}$ = 1.48. Table \@ref(tab:s2-eau-ec-bayes-model) reports the summary of the posterior distribution. For each parameter, the Probability of Direction (pd), the Region of Practical Equivalence (ROPE), and the Bayes Factor (BF) are reported [@makowskiIndicesEffectExistence2019]. Contrary to frequentist's statistics where significance is commonly determined with the p-value, in Bayesian analysis there are more options and, for the time being, not established conventions to interpret results with specified benchmarks [@makowskiIndicesEffectExistence2019].

(ref:s2-eau-ec-bayes-model-caption) Results of a Bayesian linear model analysis with the standardized average of the EAU scale as outcome variable, and the four GECo sub-competences as parameters.

```{r s2-eau-ec-bayes-model}
s2.bayesian.result.expectancy |> as_tibble() |>  
  mutate(
    Parameter = if_else(Parameter == "(Intercept)", "Intercept", Parameter),
    CI = paste0("[", printnum(CI_low), ", ", printnum(CI_high), "]"),
    BF = exp(log_BF),
    ROPE = paste0(printnum(ROPE_Percentage), "%")
  ) |>
  select(
    Parameter, Median, CI, pd, ROPE, BF, Rhat, ESS
  ) |>
  kable(
    caption = "(ref:s2-eau-ec-bayes-model-caption)\\label{tab:s2-eau-ec-bayes-model}",
    caption.short = "EAU scale composition",
    longtable = TRUE,
    booktabs = TRUE,
    digits = 2
  ) |> 
  kable_styling(latex_options = "HOLD_position") |>
  kable_styling(latex_options = "HOLD_position")
```

Even without pre-defined benchmarks, though, as one may expect from the small sample size at hand, all the parameters remain uncertain and the test provide inconclusive results about the possibility that the perceived emotional awareness usefulness can be related to emotional sub-competences. It is nevertheless interesting to note that, assuming the parameters would hold in a larger sample, emotion recognition has virtually no effect, whereas regulation and management have effects that are respectively almost twofold, and over twofold that of understanding. As a reminder, emotion recognition was performed through efferent manifestations that would normally be available in face-to-face interactions, and its lack of effect could be considered as supporting the need for an EAT to represent emotion with a structure rather than efferent cues. The importance of regulatory processes would also be corroborated, with an interesting perspective coming from the greater effect of inter-personal emotion regulation compared to intra-personal emotion regulation. These are nevertheless only wild speculations for the time being. The only relevant element to retain may therefore be that the GECo test and its sub-competences are viable measures to further investigate this kind of effects.

### Perceived Usability of the EAT

$N = `r s2.sus_total |> nrow()`$ participants filled the System Usability Scale (SUS) survey [@brookeSUSQuickDirty1996] at the end of the semester. The observed score has been of `r maf.print_m_sd(s2.sus_total$sus_score, TRUE, TRUE)`, which is considered *Good* according to the stratification proposed by Bangor, Kortum and Miller [-@bangorDeterminingWhatIndividual2009].

Figure \@ref(fig:s2-sus-items-graph) illustrates the score obtained on each of the 10 items of the SUS for the two classes. The score takes into account the reverse order for even items and is pondered on the 7-point scale used in the present study. As in the case of the EAU, ratings on the SUS are also consistent between classes. More specifically, data clearly show that the first item, inherent to the frequency of use, is far below the other items, which have received overall a high rating. Items 5 (integration of different functions of the system) and 9 (confidence in using the system) also have received lower ratings, even if not as low as the first item.

(ref:s2-sus-items-graph-caption) Rating of the individual items of the System Usability Scale (SUS) for N = 26 participants.

```{r s2-sus-items-graph, fig.align="center", fig.cap="(ref:s2-sus-items-graph-caption)"}
s2.sus_by_item.graph
```

A more detailed analysis on perceived usability is presented in the next chapter, which will compare the score with the usability test (Fritz, 2015). More accurate benchmarks will also be adopted to assess the individual items of the scale [@lewisItemBenchmarksSystem2018].

### Recollection of Individual and Collective Emotions

In the *final* survey, that is approximately two weeks after the end of the semester -- the day the instance of the toolbox was closed -- participants were asked to recall the frequency with which (1) they have experienced the 20 subjective feelings of the underlying EATMINT affective space, and (2) their class as a whole has experienced the same 20 subjective feelings. The sparse use in expressing emotions limits the interest in assessing whether there is a recollection of the individual and collective emotions shared with the EAT and is therefore reported here primarily to comply with the disclosure of all the measure collected. Figure \@ref(fig:s2-recollection-feelings-graph) compares the frequency with which the participant herself thinks she has experienced each emotion (Self) with the frequency that she attributes to the whole group (Class). The gray line available on each comparison represents the *observed* frequency with which the subjective feelings has been expressed through the EAT. This frequency is computed by mapping the expressed feelings that have been chosen the most (e.g. *Attentive* and *Interested*) as the *Very often* frequency, whereas the least expressed feelings (e.g. *Surprised* and *Disgusted*) represent the lower bound, and correspond to the *Never* frequency. *Envious* and *Bored* do not have a horizontal line because there were not even a single expressed emotion with these subjective feelings.

(ref:s2-recollection-feelings-graph) Comparison between the frequency with which each subjective feeling has been recollected as being perceived by the learner herself (Self) or attributed to the whole group (Class). The gray line represents the *observed* frequency mapped on the number of expressions through the EAT.

```{r s2-recollection-feelings-graph, fig.align='center', fig.cap="(ref:s2-recollection-feelings-graph)"}
s2.perceived_emotions_frequency.graph
```

Data basically show that participants tended to rate a similar frequency for their colleagues based on their own frequency, a phenomenon already encountered in other contributions [@eligioEmotionUnderstandingPerformance2012; @kruegerTrulyFalseConsensus1994; @tomaAnticipatedCooperationVs2010]. When participants lack the knowledge of their partners emotions, they use themselves as the *measuring stick*. The frequency is also mostly independent from the *observed* frequency, except for *Frustrated*, *Bored*, and *Satisfied*, for which the *observed* and the *class* estimation overlap. The estimation for the group and the *observed* frequency may, in principle at least, coincide, since the graphical representation of the whole class -- the word cloud -- was overtly aimed at the relative occurrence of subjective feelings. So, if the word cloud about the class as a whole was retained in memory, at least this measure could potentially be precise. The fact that this is mostly not the case seems to suggest that, simply, there has been no recollection of the emotional experience from the EAT, and estimation are based on individual background knowledge or some form of retrospective theory of mind [@wellmanTheoryMindState2018; @hallSocialPsychologyPerceiving2018].

### Open-Ended Question

In the *halfway* and *final* surveys, participants had the possibilities to add general commentaries to the overall questionnaire, with a free text field corresponding to the overarching question *Would you like to add any remark or comment on the study as a whole?* The open-ended question received 21 answers in the *halfway* survey, and only 10 in the *final* survey. Even though the overall approach to the study is nomothetic rather than idiographic, the fact that the tool's adoption has been sparse overall suggests that these questions could provide some useful reasons.

In this regard, most of the answers both in the *halfway* and *final* surveys point out that students forgot to use the tool, primarily because they were already overwhelmed by the learning task. A few students, though, precised that the lack of use was also influenced by the presence of alternative communication channels used by the class, as it is clearly stated in this answer:

> At first, I forgot to use it and realized it late in the period. Afterwards, I didn't do it, because I use [the group's messaging platform] Slack to exchange and this tool is sufficient for me to manage my emotions. Using another tool would have generated an additional mobilization of resources and [would] therefore [have been] counterproductive for me.\
> --- Verbatim of the answer, translated from original French.

Other students highlighted the fact that the moment-to-moment use of the tool interfered with their learning activity, diverting their attention. Even if they did manifest their emotion, those were rather prospective or retrospective [@pekrunControlValueTheoryAchievement2014; @pekrunControlValueTheoryAchievement2006]. Furthermore, the sparse use of the tool even produced the very opposite effect it was intended to obtain, that is, increase social presence. As stated by a student:

> I used the tool and I like the concept but I only found myself online once with my other colleagues which actually made me feel quite alone in my sharing moments. This is the opposite of what I expected because I thought I would feel more connected to my colleagues and my emotions in the moment.\
> --- Verbatim of the answer, translated from original French.

A few students nevertheless provide positive feedbacks about the presence of the tool, even if they regret the sparse use made of it by themselves or their colleagues. The feedback that more closely adheres to the tool overall purpose, though, provide an attentive analysis of its use in terms of the role the appraisal criteria played in its adoption:

> It was a great tool to use. I particularly appreciated to have this tool in order to force myself to analyze my emotions while working on [the course] topics. I particularly appreciated the question about the capability to change the situation, which was a good opportunity to take a step back and understand what factors led to the situation and how I could influence them. It was also particularly interesting to be able to see the last emotional states and the most used. I would be happy to continue the survey in the future period.\
> --- Verbatim of the answer, which was provided in English by the student

## Discussion

The aim of this exploratory study was to assess several facets of the interaction with an EAT over a longer period of time, namely two thirds of a semester. In this regard, two classes of a blended university Master about education technology were provided with the possibility to spontaneously use the EAT at any time they wished during periods of distance learning in an entry-level course about programming and computational thinking. The tool was meant to foster learners' self-reflection about their own emotional experience in a course that is known to put students on an emotional roller coaster: students often alternate success in having their intentions translated into code with failures in reaching a final product that meet their overstated expectations [@fritzPenseeComputationnelleAvec2019]. In the meantime, the EAT was also allegedly adopted to allow students to project themselves socially and affectively in a course whose instructional design does not impose collaboration between peers. The asynchronous and non-collaborative settings of the course, combined with the overall dexterity of the students with web applications, was therefore considered an interesting scenario to assess the longitudinal use of an EAT with the characteristics advocated in the thesis.

The overall use of the EAT has nevertheless been scant, which has caused a chain effect on all the other indicators linked to the research questions set forth. The discussion will therefore start from this consideration, assessing the first research question, and progressively unravels the other questions successively.

### Scarce Use of the EAT

The number of expressed emotions, used here as the sole indicator of concrete use of the EAT, showed that only one student expressed over 80 emotions, with a dozen of other students expressing between 34 and 10 emotions, and the reminder 10 emotions or less, with 3 students not expressing any emotion at all. Even without an accurate benchmark at disposal, these measures refer of a scarce overall adoption of the EAT. The possibility of having students only monitoring the emotional experience of others, without entering any emotions themselves, seems unlikely and did not transpire from any comment.

Standing on indicators of *pure* use of the EAT, it may therefore be assumed that the effort to recall its existence, open, produce and peruse emotional information outweighs the benefits that could be derived from a stable and persistent adoption of the tool [@dillenbourgSymmetryPartnerModelling2016]. The course as a whole, though, is very demanding in terms of different environments, tools, requirements for the projects to be handed-in, documentation to be consulted, and so on [@fritzPenseeComputationnelleAvec2019]. As a consequence, there may not even have been a deliberate assessment of the trade-off between costs and benefits, since the overwhelming tension of articulating all the different parts of the course could have simply taken the upper hand.

Another possibility is that, despite some learners having wished to dispose of the emotion of others as in @molinariEMORELOutilReporting2016, others can be reluctant to the very idea of emotional awareness altogether, as encountered by @ruizSupportingLearningConsidering2016. A closer look at the perception of usefulness can therefore provide a more accurate representation of students attitude towards the EAT.

### Perceived Usefulness Is Promising at First, but Drops with Concrete Use

The upfront expectations of students towards the EAT seem to relate a genuine need for a richer experience during remote periods, which is consistent with theoretical and practical efforts to improve socio-affective support in distance learning [@brackettRULERTheoryDrivenSystemic2019; @jarvenojaRegulationEmotionsSocially2013; @kreijnsSocialAspectsCSCL2013; @lavoueEmotionAwarenessTools2020]. More specifically, learners manifested the highest expectations about the usefulness of an EAT for the *Understanding Others* ($M_{total}=6.93$), and *Self-Other Comparison* ($M_{total}=7.70$), that is, the two more socially-oriented dimensions. In particular, it is worth pointing out that the *Self-Other Comparison* dimension did not even receive any low score in the *expectancy* survey, and the *Understanding Others* only two very low scores (see \@ref(fig:s2-graph-dimensions-and-survey)). This seems to rule out the possibility that there are students *a priori* reluctant to the whole business of emotional awareness.

Conversely, for the two more self-oriented dimensions, *Self-Understanding* and *Self-Regulation*, expectations were only moderate to low ($M_{total}=4.57$ and $M_{total}=4.23$ respectively). In other words, the intra-personal function of an awareness tool is perceived as potentially less intriguing compared to the inter-personal stance [@eligioEmotionUnderstandingPerformance2012; @rimeEmotionElicitsSocial2009; @fischerSocialFunctionsEmotion2016; @vankleefInterpersonalDynamicsEmotion2018]. It would be interesting to investigate whether this is a shortcoming that is overtly attributed to the concept of an EAT, or it also (or rather) subsumes an intrinsic difficulty of students to engage in emotion self-reflection and self-regulation [@molinariEMORELOutilReporting2016; @lavoueEmotionAwarenessTools2020; @seagerEmotionalIntrospection2002].

The *Affordance* dimension was rated high ($M_{total}=6.57$), suggesting that the tool is expected to serve its function of prompting learners to share their emotions. This seems to corroborate the need for a dedicated tool targeting specifically emotions [@brackettRULERTheoryDrivenSystemic2019; @brackettEnhancingAcademicPerformance2012a; @brackettPermissionFeelUnlocking2019], but does not implicate the benefit of implementing an emotional structure into it, since ratings with the *Demo* survey did not increase the expectations.

Finally, the *Frequency* and *Social Presence* dimensions are more difficult to assess, since they are the two dimensions on which the two classes have a lesser convergence. Frequency of use is notoriously a user-experience dimension that is often overestimated by potential users, for whom telling *yes, I will use it* has no concrete consequences [@tullisMeasuringUserExperience2013; @sauroQuantifyingUserExperience2016]. The moderate expectations for *Social Presence* ($M_{total}=5.83$), compared with higher expectations for the more socially-oriented dimensions, may suggest that learners consider the EAT as a potential source of social reference rather than a way to perceive the presence of others. This is consistent with theoretical evidence suggesting that emotions in others can be a valuable source of information, especially in challenging situations [@jarvenojaRegulationEmotionsSocially2013; @vankleefHowEmotionsRegulate2009; @vankleefInterpersonalDynamicsEmotion2018].

Inter-dimensional comparison should nevertheless take into account the tentative nature of the EAU scale. Direct comparison between different dimensions, in fact, presupposes that all the seven constructs can be mapped into a similar space [@williamsLevelsMeasurementStatistical2021], which is an assumption that cannot be sustained without a thorough validation of the scale. Intra-individual change over time on the same dimension, though, is less concerned by the *absolute* measurement space of a construct, for it is determined by the relative shift in perception as the situation evolves [@fitzmauriceAppliedLongitudinalAnalysis2011].

In this regard, all the expectations were basically confirmed in the *Demo* survey, once participants had tested the concrete use of the EAT, suggesting that the specific features of the tool neither increased, nor decreased the expectations about its usefulness. This is both good and bad news. On the bright side, learners seem to trust the tool's ability to sustain their expectations. On the other hand, though, the tool failed to change participants' mind on the dimensions rated moderate to low. This seems to indicate that they did not see in the tool additional interest, especially for interpreting, reflecting on, and experiencing their own emotional episodes [@boehnerHowEmotionMade2007; @ruizSupportingLearningConsidering2016; @lavoueEmotionAwarenessTools2020].

The perception of usefulness then drops immediately. Already at the *halfway* survey, the rating on all dimensions of the EAU have plummeted. Almost none of them even slightly recover at the *final* rating. All ratings tended to stabilize on the bottom end of the scale, so that the dimensions that suffered from the greatest decrease are the ones that benefited from greater expectations upfront, namely *Understanding Others* and *Self-Other Comparison*, who dropped of more than 2.5 rating points.

A similar drop was observed for the *Social Presence* dimension, which started though from only a moderate expectation. This means that the tool was eventually perceived as not conveying the presence of others at all. This may be due, in large part, to the fact that students almost never crossed each others online at the same time. An attempt to reconstruct asynchronously the presence of others through non-contextualized emotional traces left in the tool seems therefore rather hopeless. Some students overtly reported in the open-ended questions that they disposed of other tools to interact with colleagues, such as instant messaging, which provided a more holistic form of interaction, providing cognitive, social and affective support at the same time [@cheshinAngerHappinessVirtual2011; @blundenEmoticonAreThere2020; @parkinsonEmotionsDirectRemote2008]. This directly questions the interest of disposing of a dedicated tool, even when it implements an emotion structure that would be difficult to obtain in general purpose environment as an instant messaging application.

Finally, the assessment of the perception cannot ignore that many students reported that they wished they could have used the tool more often, but did not manage to do that because of the overall pressure in meeting deadlines with a functioning project, which is a primary concern for novices in programming [@fritzPenseeComputationnelleAvec2019; @leeExploringRelationshipNovice2011]. The *true* perception of the usefulness of an EAT may therefore not be as bleak as the one depicted by the EAU ratings after the concrete (non-)use of the tool. In this regard, the scale in itself showed promising sensibility and reliability indicators, suggesting also the presence of a three-dimensional structure with dimensions related to the user experience (*Frequency* and *Affordance*), to the intra-personal function of emotional awareness (*Self-Regulation* and *Self-Understaning*), and to the inter-personal function (*Self-Other Comparison*, *Understanding Others*, and *Social Presence*).

### Inconclusive, But Promising Settings to Introduce Emotional Competence in the Picture

The use of an appraisal-driven EAT is closely linked to the concept of emotional competence from a componential perspective [@schererComponentialEmotionTheory2007], as illustrated in Section \@ref(ec-cycle-dew). The introduction of the Geneva Emotion Competence (GECo) test was therefore a promising measure upon which explore the potential role of this construct as an intervening factor in determining the use and perception of the EAT. Given its accuracy in determining four sub-competences (recognition, understanding, regulation and management of emotion), the length of the test discourage most of participants from taking it, especially during an intensive period as the first semester of the Master. As a consequence, only $N =$ 11 students completed the test, which limited the information what could be retrieved from this valuable source.

As already mentioned, the test is targeting more specifically working settings, but the item could be reworded relatively easily to match academic settings, both at the intra-personal and inter-personal level. The accuracy of the test may also be relaxed depending on the specific aims of the study, so that it may therefore be possible to envisage a shorter version. For instance, the recognition part based on efferent manifestations could be skipped in computer-mediated learning environments who do not aim at reproducing face-to-face interactions [@buderGroupAwarenessTools2011; @janssenCoordinatedComputerSupportedCollaborative2013].

All things considering, a performance-based test about the construct of emotional competence may be a very useful instrument in investigating emotional awareness more broadly. Under the assumption that emotional competence may also be trained, the longitudinal use of an EAT under more pro-active conditions can even contribute to test potential effect on the overall competence [@brackettEnhancingAcademicPerformance2012; @hoffmannTeachingEmotionRegulation2020].

### Questionable Procedure for Testing Emotional Experience From the EAT

Under the assumption that emotional stimuli have a privileged access to memory [@broschImpactEmotionPerception2013; @kensingerRetrievalEmotionalEvents2020; @montagrinGoalConducivenessKey2013; @poolAttentionalBiasPositive2015; @rimePartageSocialEmotions2005], it has been tested whether students had an accurate recalling of the emotional experience as it was depicted by the EAT at the end of the semester. Even though the practice of recalling self-emotional experience and projecting emotional experience of others have been adopted in other contributions [@eligioEmotionUnderstandingPerformance2012; @molinariEmotionFeedbackComputermediated2013; @avryAchievementAppraisalsEmotions2020], in the present study the assessment was prompted more from enthusiasm than careful planning. Even in the case of a more consequential use of the EAT, though, doubts may persist about the validity of the procedure. As a consequence, this research question will not be discussed any further, being only slightly related to the overall aims of the thesis.

### Consistency Between Classes Suggests Limited Interacting Effects

Finally, a last research question spanned across the previous four and concerned difference between two classes observed during two different academic years, but under very similar settings. It was assumed that in such conditions, at least from an exploratory perspective, the two classes could be retained as a form of pseudo-random assignment, since the composition of classes in the Master MALTT are not usually subject to any systematic factor at play in determining age, background, or perspectives of students [@pearl2018; @pearl2018book; @rohrerThinkingClearlyCorrelations2018]. It was posited that, if *wide* differences in the use and perception of the EAT between classes could be observed, that would probably be accountable, in part at least, to interacting effects between students of each cohort [@dillenbourgSymmetryPartnerModelling2016].

Most of the observed measures in this study, though, are very consistent across the two classes. In both classes, only a handful of students adopted the tool over the longitudinal period, with similar patterns in periods where emotions were expressed and periods were students were most likely working on other courses. In Class 1, though, there was a single student that expressed most of the emotions, whereas in Class 2 the encoding of emotional information was less skewed, even though far from being homogeneous. Notwithstanding this difference, the rating on the EAU scale over the four surveys was almost symmetrical between the two classes. The dimensions that have been rated somehow differently were limited to the *Expectancy* and *Demo* surveys and consisted in *Frequency*, where Class 1 was more optimistic; *Affordance,* once again with Class 1 having a more favorable outlook; and *Social Presence*, where Class 2 reported greater expectations. The fact that these differences concern ratings before the concrete use of the EAT, though, rule out the possibility that they may be determined by interacting factors, at least not implicating the use of the tool. As a reminder, classes spent the first of the three periods during the semester without using the EAT. So, different social interactions may have occurred across classes that could, in principle, have influenced students in having different attitudes toward the use of an EAT with their colleagues. The use of the tool could be implemented from the very onset of the semester to limit this possibility.

Inter-individual attitudes towards the EAT were nevertheless present, with some students having adopted it, or having at least a favorable outlook towards its usefulness, as indicated by the open-ended questions. Those students have nevertheless not *pushed* others in following through, and were most probably even set back from the lack of use from the colleagues. In this sense, there may have been an interacting effect, with potentially interested students being dissuaded by their isolated use of the EAT. As already mentioned, this would in fact be a reverse effect, with the present of the EAT increasing isolation rather than allowing students to project themselves socially and affectively in the computer-mediated environment.

On the bright side, the consistency between the two classes at least conveys support for the intrinsic quality of the EAU scale and also of the EAT in itself. The EAU scale seems to have allowed both classes to consistently express their expectations and progressive disillusion with the usefulness of the tool. Furthermore, notwithstanding the limited use, the rating on the SUS [@brookeSUSQuickDirty1996] was consistent between the two classes, yielding an overall results of almost 73 points. This last rating may suggest that there has not been a favorable interacting process between the intrinsic quality of the tool and the conditions for taking advantage from it.

## Conclusion

The present observational and longitudinal study aimed at investigating the use and perception of usefulness of an EAT during asynchronous and non-collaborative learning settings, under the assumption that the presence of the EAT may provide instrumental information on various dimensions that are considered as pivotal in remote computer-mediated learning environments. Furthermore, by implementing the EAT in two cohorts of the same course, the study also aimed at investigating whether differences between the two classes could be observed. If that would have been the case, the use and perception of the EAT may depend also on interacting dynamics between learners, rather than on individual characteristics alone. Finally, as a corollary objective, the study also attempted at determining whether emotional competence may emerge as an intervening factor in the use or perception of the EAT.

Overall, the study presents several drawbacks that limited its informative potential. At the same time, it also provided some promising elements, particularly in the material and type of analysis which may help future investigations about the subject at hand. The concluding remarks of this chapters first assess the main limitations of the study, and then resume the main contributions that may be considered for future studies.

### Limitations

The study suffered from an unresolved ambiguity between a field study and a pedagogical intervention into an ongoing course. On the one hand, the field study objectives presupposed minimal intervention, consistently with a *pure* awareness tool perspective, letting learners free to adopt and use the tool in the way they saw fit. At the same time, from a pedagogical standpoint, one of the established shortcoming in the implementation of auxiliary technologies in the learning activity is that their presence alone does not guarantee neither the use, nor their effectiveness [@kreijnsIdentifyingPitfallsSocial2003; @kreijnsIdentifyingPitfallsSocial2003; @janssenGroupAwarenessTools2011]. The overall sparse use of the EAT, consistent between classes, has therefore diminished the informative potential of the whole study, which proved to be exceedingly ambitious in its *group-awareness* perspective. In fact, learners were bestowed with the whole process of reminding to use the tool, open it alongside the different learning activities necessary to comply with the course requirements, and extrapolate meaningful information from displaying their own emotions, as well as monitoring their emotions and that of their colleagues. As many learners have revealed in the free commentary, this was an excessive demand in a course where they already had to face new and complex learning environments or tools [@fritzPenseeComputationnelleAvec2019].

A certain amount of *scripting* -- that is, pedagogical scaffolding of the learning activities [@millerScriptingAwarenessTools2015] -- seems therefore necessary. Learners should be more adequately supported in the use of the EAT, for instance with occasional reminder of its presence. Discussions about its use and the available information could also been integrated, for example in the form of focus-groups [@lallemandMethodesDesignUX2017]. This sort of support may be very consistent with an interacting approach. The use of the EAT would be assessed and reassessed by the group as a whole, with guidance resulting as a direct effect of the input from students. With hindsight, the neutral comparison between cohorts was therefore overly ambitious, for it requires a *laissez-faire* attitude in contrast with learners needs of a more guided scenario and support. This is even more relevant considering the convenience sample of the study: learners that by vocation and training are exposed to various learning technologies. The fact that even learners allegedly open to adopting new technologies made a sparse use of the EAT suggests that this design is unlikely to provide interesting evidence on the subject at hand, beyond confirming that an awareness tool must be integrated in an environment carefully planned to maximize its adoption and efficiency [@kreijnsIdentifyingPitfallsSocial2003; @kreijnsIdentifyingPitfallsSocial2003; @janssenGroupAwarenessTools2011; @buderGroupAwarenessTools2011].

Beside the context in which the EAT has been deployed, also the tool in itself presented major limitations from a longitudinal perspective. Even though the overall perception of the tool on the *Demo* survey and the System Usability Scale [@brookeSUSQuickDirty1996] do not highlight that students perceived limitations, they were also not in the full condition to assess its potential. The use of three word clouds to peruse emotional information is a very limited representation of the complexity and quality of emotion as an information unit, a central tenet of the overall contribution. The conceptual work done on implementing an emotional structure into the tool was therefore limited to the expressing-displaying part of the EAT, but was not then reflected in the perceiving-monitoring part. This certainly calls for intervention in conceiving and deploying better graphical representations of emotions, which may walk students along a rich and meaningful representation of their own as well as their colleagues emotions [@ruizSupportingLearningConsidering2016; @leonyProvisionAwarenessLearners2013; @bersetVisualisationDonneesRecherche2018; @fritzRealTimeEmotionalAwareness2016].

### Study's Overall Contribution

Despite all the limitations, the study also provides some elements of interest that may be adopted in future studies about emotional awareness in computer-mediated learning environments more generally.

First, the EAT did not encounter any technical problem. Even though it hasn't been put really under pressure from participants, it has nevertheless been up and running for the two longitudinal studies, apparently collecting all the relevant data provided by students. The intrinsic quality of the tool in itself has not been diminished by the lack of its use, corroborating the idea that the sparse use could be, at least partially, due to the design of the study. The perceived usability is in fact consistent across classes and similar to a previous usability test conducted in synchronous and collaborative settings (Fritz, 2015). The EAT's usability will be more thoroughly assessed in the next chapter, but it is worth mentioning here that it appears the tool can be implemented also in an asynchronous and individual use, without modifying the perception of its usability.

Second, the tentative Emotional Awareness Usefulness (EAU) scale showed promising results with respect to its sensitivity and reliability. The scale nevertheless needs further development, since even the formulation of items considered the vantage point of participant's knowledge. Furthermore, there are at least a few dimensions that are missing and some of the current ones could be decoupled to avoid some ambiguity. For instance, the *Social Presence* item does not take into account the full complexity of the construct as illustrated by the extant literature on the subject [@jezegouCreerPresenceDistance2010; @lowenthalSearchBetterUnderstanding2017; @rourkeLearningCommunitiesInquiry2009; @kirschnerAwarenessCognitiveSocial2015], see also Section \@ref(social-presence-distance-learning). Social isolation is in fact only a facet of social presence. For example, the scale does not include anything about a sense of belonging or authenticity, which are characteristics advocated by several scholars. The *Affordance* dimension suffers from the very same ambiguity that the thesis as a whole tries to dissipate, since it only consider the *self-affordance* in expressing one's own emotions, but does not consider the *social-affordance* in considering others' emotions. The *Understanding Others* and *Self-Other Comparison*, in fact, go a step further and implicitly assume that others' emotions are taken into consideration, whereas this dimension should be indexed in its own term. One can in fact be interested in others' emotions without necessarily acting on their understanding, or do not use the emotions' in others as a comparison, but for other purposes. Furthermore, the scale could also be deplyoed in collaborative settings, in which case *Self-Regulation* should also be supplemented by an item on inter-personal emotion regulation [@reeckSocialRegulationEmotion2016; @zakiInterpersonalEmotionRegulation2013]. In other words, the scale itself should be better tailored on the abstract model of emotional awareness presented in Section \@ref(abstract-model-of-ea). Finally, the scale should seek a better integration with existing scales in the field [@rieffeEmotionAwarenessInternalising2008; @laneLevelsEmotionalAwareness1990; @tuRelationshipSocialPresence2002; @kreijnsMeasuringPerceivedSocial2011; @pekrun2011; @pekrunMeasuringEmotionsEpistemic2016], especially in the perspective of having multiple items about the same dimension. Considering the growing interest towards the instrumentality of emotional awareness in computer-mediated learning environments, it would be worth investing in the development of a scale that maintains the general outlook, but that better reflects good practices and standards in the development of quality measures [@flakeMeasurementSchmeasurementQuestionable2020; @boatengBestPracticesDeveloping2018].

Finally, speaking of valid instrument, the Geneva Emotional Competence (GECo) test [@schlegelGenevaEmotionalCompetence2018] provides a viable option for researchers interested in in an ability measure of this socio-affective construct. Even if the test is quite long, it provides measurement for emotion recognition, emotion understanding, emotion regulation, and emotion management, which can be related each to different facets of the use and perception of an EAT. Furthermore, the items used outside emotion recognition are situated in working conditions that have a bearing with learning in higher education. It therefore presents also some ecological potential, maintaining though the rigor of a scientific instrument.

All things considering, thus, also this second empirical contribution is consistent with the thesis's general objective of focusing primarily on construct validity and internal consistency. The generalization potential and practical evidence yielded by the study are very limited, but the promising quality of the individual instruments adopted may be of interest for future studies wishing to take into account the longitudinal effect of emotional awareness.

### Acknowledgments

I would like to thank professor Daniel K. Schneider for allowing the use of the EAT in two occasions during the STIC I course.
