---
bibliography: references.bib
---

# Building a Toolbox Around the Parsimonious Computational Model {#toolbox-chapter}

```{r eat-dashboard-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)

```

The previous chapter illustrated the parsimonious computational model linking appraisal dimensions and subjective feelings, which is the *core* of the proof of concept proposed by the thesis. This chapter introduces a toolbox built around the computational model, which allows the configuration of an Emotion Awareness Tool (EAT) according to researchers and practitioners needs. As stated in the introduction, the implementation of a toolbox is driven by open science tenets, which advocate the need for investing in the development of open material that can foster transparency, sharing, comparison, replicability and reproducibility of research practices, measures and results [@Nosek1422; @chambersSevenDeadlySins2017; @scheelWhyHypothesisTesters2020; @nelsonPsychologyRenaissance2018; @flakeMeasurementSchmeasurementQuestionable2020; @schererWhatAreEmotions2005]. The chapter starts by a general overview of the toolbox, which is divided in an area dedicated to researchers and practitioners, and the *end-user* interface of the tool integrated in a computer-mediated learning environment. The reminder of the Chapter then illustrates the available configuration options of how emotion is expressed-displayed and how emotion is perceived-monitored respectively. Finally, the Chapter describes some features of the toolbox that can be configured from an empirical point of view, as well as the measures that can be retrieved from the toolbox.

## General Presentation of the Toolbox

The toolbox is a web-based application that can also be installed on local machines in relatively few steps. The details are ignored here because this sort of information is likely to change over time, but the choice of a web-based application has been made to maximize ease of access to both researchers and users, with only a modern browser as a requirement. In fact, contrary to *pure* and individual self-report instruments, which may be administered in different settings with minimal adaptations, an EAT presents more challenging technical constraints, especially from a moment-to-moment and inter-personal perspective. Whenever synchronization between two or more *agents* sharing information is concerned, it is necessary to adopt a bi-directional communication technique, such as web socket. Most web applications are in fact based on the client-server architecture: the *agent* (the client) sends a request to the server, which responds back with the appropriate response (e.g., the content of a page). Outside the bounded episode of request/response, though, the server has no way to send information to the client, if the client hasn't initialized a request first. Nowadays the concept of *push* notifications in mobile phones or web sites has become ubiquitous, but still, the technique requires adequate software, which is not readily available. The combination of theoretical/pedagogical and technical requirements, thus, advocate the development of a comprehensive toolbox allowing researcher to customize and carry out directly their instances of the EAT according to their specific aims, minimizing the technical burden to set up a computer-mediated environment. This section provides a general overview of the toolbox, which comprises a *front-end* part dedicated to users, and a *back-end* part dedicated to researchers and practitioners. The section starts with the overview of the *back-end* part, since it is the one where the *front-end* part is defined.

### The Toolbox Back-End

The toolbox back-end is similar to a reserved admin area, where researchers must provide their credentials to access their instances of the tool. Figure \@ref(fig:toolbox-dashboard-page) shows the dashboard of the admin area available once the researcher has logged-in. At the time of writing, the back-end is available only in English.

(ref:toolbox-dashboard-page-caption) The dashboard page of the admin area shows a list of active instances/studies and gives access to the different features of the back-end.

```{r toolbox-dashboard-page, fig.align="center", fig.cap="(ref:toolbox-dashboard-page-caption)", out.width="100%"}
knitr::include_graphics(here::here("./figure/dew/dew-toolbox-admin-area.png"))
```

From the back-end part of the toolbox, researchers and practitioners can perform mainly four actions that have scientific and/or pedagogical relevance :

1.  Access instances -- that is, specific configurations of the tool -- which are identified as *studies* in the interface[^1]. The dashboard only lists the active instances, but in the *studies* tab researchers can also find past or inactive instances.
2.  Manage instances by creating, duplicating, modifying, or removing *studies*.
3.  Manage affective spaces that can be used in *studies*. Affective spaces can be either private, available thus only to the logged-in researcher, or shared with other researchers subscribed to the same server*.*
4.  Import configurations of *studies* or affective spaces from external sources, for instance -- ideally -- supplementary material from a contribution that has used the toolbox.

A *study* is the element of the toolbox that glues all parts together. It is determined by the different configurations options and is made available to users through the toolbox front-end illustrated in the next subsection. Figure @ref(fig:dew-toolbox-study-detail) shows a cropped detail page of a *study*, which happens to be an archived instance of the usability test illustrated in Chapter @ref(dew-chapter).

(ref:dew-toolbox-study-detail-caption) Example of a *study*'s detail page. The screen capture has been cropped to save space.

```{r dew-toolbox-study-detail, fig.align="center", fig.cap="(ref:dew-toolbox-study-detail-caption)", out.width="100%"}
knitr::include_graphics(here::here("./figure/dew/dew-toolbox-study-details.png"))
```

Through the detail page, it is possible to perform a series of actions connected to the *study*. Only the most salient actions are listed hereafter.

First, the study can be started, which means that the front-end of the instance is launched in a new tab of the window. Each study disposes of its own web address, which can be limited to the local machine or local network, or publicly available over the web depending on where the server is installed. This is thus just one way to start-up an instance, which can nevertheless be accessed directly by users through the URL, without the need to pass from the admin area. The study can also be accessed in a preview mode, which shows how the final instance will look like to user, but without gathering any data.

Second, the *study* can be configured. The configuration is equivalent when creating a new instance or modifying an existing one. Instancescan also be duplicated, which may be useful in case of conditions within the same *study*. The configuration details are illustrated in the following sections of the chapter.

Third, the status of the study can be easily updated, switching from *open* to *closed* or vice-versa. It is in fact possible to decide whether an instance is available or not at any given time. When not available, the URL of the front-end will show a message informing the user that the instance is not active.

Fourth, it is possible to export different elements of the study, as depicted in Figure \@ref(fig:toolbox-export-modal-caption). The first and more obvious element to export are the data collected. In this regard, the detail page also provides a data summary frame on the right-side of the screen, right under the main actions buttons. The data summary report the number of participants who have been used the instance, the number of observations/emotions expressed, as well as an average for every dimension rated. The recorded observations are also illustrated in a wordcloud, which provides a perceptive representation of the most frequent subjective feelings used by participants. A second element that can be exported are the participants accesses to the instance. Since it is possible that a participant access the instance without expressing any emotion, this form of data can still be used as a separate dataset. A third element concerns the overall configuration of the *study*, which can be shared with other interested people, for instance as supplementary material in an article. Finally, the whole *study* (data, affective space, and overall configuration combined) can be exported as a form of backup.

(ref:toolbox-export-modal-caption) Screen capture of the export procedure, which can be executed on different elements of the *study* and, if possible, with different file types.

```{r toolbox-export-modal, fig.align="center", fig.cap="(ref:toolbox-export-modal-caption)", out.width="70%"}
knitr::include_graphics(here::here("./figure/dew/dew-toolbox-export-options.png"))
```

From the admin area it is also possible to access the list of available affective spaces, as well as create new ones. As stated above, affective spaces can be either private or shared. Only the researcher/practitioner that has created or added the affective space to the server can decide to make it public or private. When used in a *study*, the affective space is nevertheless copied into the specific instance, so that actions performed to the affective space do not automatically propagate to *studies*.

Alongside the information necessary to represent the structure of the affective space (*i.e.*, dimensions and disposition of lexicalized emotions), the toolbox also reckons the importance of crediting the original author(s) of the affective spaces. In this regard, it is possible to specify how each affective space should be cited. Figure \@ref(fig:toolbox-affective-space-detail) shows the detail page of the English version of EATMINT circumplex introduced in Section \@ref(eatmint-circumplex). The structure of the affective space can be exported either as data, with the *Export* button on the top-left side of the screen, or a Scalable Vector Graphic (SVG), that is an image that can later be easily modified by a vector editor[^2]. The SVG file can later be included directly, or rasterized before inclusion in a contribution for illustrative purposes.

(ref:toolbox-affective-space-detail-caption) Detail page of the English version of the EATMINT circumplex presented in Section \@ref(eatmint-circumplex) as an example of affective space. Each affective space disposes of a field to indicate how it should be cited in order to credit the author(s).

```{r toolbox-affective-space-detail, fig.align="center", fig.cap="(ref:toolbox-affective-space-detail-caption)", out.width="100%"}
knitr::include_graphics(here::here("./figure/dew/dew-toolbox-affective-space-page.png"))
```

At the time of writing, there are several affective spaces identified in the literature that can be implemented as underlying structures for the DEW. These include the EATMINT circumplex in French and English @fritzProvidingEmotionalAwareness2017, the three versions of the Geneva Emotion Wheel @schererGRIDMeetsWheel2013, the circular scaling coordinates of 28 affect words by @russellCircumplexModelAffect1980, and the mapping of 80 emotion terms on a four-dimensional space by @gilliozMappingEmotionTerms2016. Furthermore, as stated in the description of the computational model in the previous chapter, an higher-order dimensional space can also be used for lower-order rating dimensions. For instance, a three-dimensional affective space can be (1) disjointed in three different one-dimensional affective space, (2) combined in two different bi-dimensional affective space, or (3) used in its whole three-dimensional structure. Bi-dimensional affective spaces can also be represented both as a circumplex or as a Cartesian plane, allowing thus great flexibility on the underlying *reference frame* to be adopted.

Finally, the last relevant feature from a scientific or pedagogical perspective concerns the possibility to import affective spaces and whole *studies*' configurations. As mentioned above, this is meant to increase the transparency and sharing of research and practices involving the use of the tool. External sources can be imported for direct use, for better understanding of the inner functioning of an instance, as well as for checking the accuracy and adherence to protocols.

To sum up, the back-end area of the toolbox is meant to facilitate researchers and practitioners tasks both at the individual and collective levels. At the same time, there is also the possibility to use the tool in isolation, on individual premises, with relatively few technical steps and requirements.

### The Toolbox Front-End

The toolbox front-end is the instance of the tool participants/learners will interact with. It is available through an URL as any other site or web application. At the time of writing, the *fixed* parts of the front-end interface -- which are few considering that most of it can be configured -- are available in English, French, German and Italian.

The front-end part of the screen can count up to four different screens: (1) one for general instructions, (2) one for the log-in/synchronization with two or more users if needed, (3) one for the task itself, and (4) one for a debriefing or end-of-task screen that can for instance provide a link to further steps in the procedure. There are nevertheless ways to modify the URL given to users, for them to skip any step except the task itself. For instance, users can be provided with an URL that includes a specific or random ID and that logs users directly into the task. This mechanism has been used in the empirical contribution of Chapter \@ref(study-2).

When two or more participants have to be synchronized to start a specific task, the toolbox provide a *pseudo* log-in system that can be configured to hold-on until all the required users are ready to start the task. Figure ... illustrates this passage. The same instance can be used for as many groups as needed, with the size of the group that can potentially scale up to thousands. The limit is in fact determined by the machine's ability to deal with concurrent sockets. Users belonging to the same group need only to provide a common Group ID. Once again, the instructions on how to log-in into the system can be customized. Synchronization is also not mandatory. For instance, in a longitudinal use of the EAT as the one that will be made in the second empirical contribution of the tool, participants could log-in at any time, regardless of the number of concurrent colleagues connected on the interface. The system automatically detects if a new (or returning) user has accessed the instance and adapts the interface accordingly.

(ref:dew-toolbox-frontend-login-caption) Example of *log-in* screen when the task has to start at the same time for all involved users. This is nevertheless not a mandatory step.

```{r dew-toolbox-frontend-login, fig.align="center", fig.cap="(ref:dew-toolbox-frontend-login-caption)", out.width="60%"}
knitr::include_graphics(here::here("./figure/dew/dew-toolbox-frontend-login.png"))
```

The core of the front-end is the interface where the EAT is available, which can be coupled (or not) with a task or learning activity on the side. Figure \@ref(fig:toolbox-frontend-interface) shows the front-end interface of an hypothetical study or learning activity based on collaborative writing. The EAT occupies the left-hand side of the screen, whereas the online editor is in a iframe (technically a window inside a window) on the right-hand side. The interface also presents a timer and a button that allows participants to stop the task at any time. This is just an example of how the choice of a web-based application allows the integration with existing tools, but once again, the possibilities are much wider and depends on the specific aims for which the toolbox is adopted. As will be described in the reminder of the Chapter, many aspects of the overall interface and the inner functions can be adapted through the back-end part of the toolbox. The example, for instance, adopts an *Energy* x *Familiarity* dimensions, which are derived from the *Arousal* x *Novelty* dimensions of the four-dimensional structure in @gilliozMappingEmotionTerms2016.

(ref:toolbox-frontend-interface-caption) Example of an instance of the toolbox comprising the EAT on the left-hand side and a collaborative writing task on the right-hand side.

```{r toolbox-frontend-interface, fig.align="top", fig.cap="(ref:toolbox-frontend-interface-caption)", out.width="100%"}
knitr::include_graphics(
  here::here("./figure/dew/dew-toolbox-frontend-task.png")
)
```

It is important to note that the toolbox guarantees only the synchronization between the emotional information shared by the EAT, as well as the beginning and the end of the activity if these parameters are specified. The presence of a coordinate task must be taken into account by the specific tool adopted (*e.g.*, an online text editor). In this regard, the overall toolbox passes to the frame within the task is performed the identity of the participant and the group, as well as the emotion shared through the interface. Researchers and practitioners who intend and dispose of the technical know-how to intercept that information can thus use it.

The synchronization between the interfaces of users is made thorough the bi-directional technology mentioned above, which guarantees the advocated moment-to-moment feature of the EAT. The speed of the bi-directional communication may vary slightly depending on how the clients and the server are connected (e.g. on a local network or over the web), but the latency remains in the order of milliseconds.

To sum-up, the front-end of the toolbox consists in a web-application of the sort that most users should be nowadays familiar with. It guarantees bi-directional communication over very brief periods of time for the emotional information, as well as the onset and end of the activity if needed. The overall interface reflects the choices made by the researcher or practitioner when the instance was set up through the back-end. Some of the most salient choices are briefly outlines in the reminder of the chapter.

## Configuration of the Expressing-Displaying Function {#toolbox-displaying-features}

The options available about how emotion is *encoded* into the system pertains to two intertwined element: the underlying affective space and how the expressing-displaying part of the EAT is configured. The options available for the affective space have already been outlined in the general presentation of the back-end part of the toolbox in Section \@ref(the-toolbox-back-end). It is worth reminding to this purpose that any kind of affective space can be adopted, as long as it meets the requirements of the underlying computational model defined in Section \@ref(model-requirements). Existing and validated affective spaces may be preferable in some circumstances, whereas more exploratory and custom choices could be warranted in others. The fact that affective spaces can be shared within the same server and across servers if needed is precisely meant to leave the maximum freedom, but at the same time foster transparency and comparability of conditions. An affective space is technically determined by the following minimal information:

1.  The number and labels of the dimensions, from a minimum of 1 to potentially no upper limit, even though a large number of dimensions may be unfit for the interface.

2.  The type of algorithm adopted to determine the *k-nearest neighbors*. This depends on the structure of the underlying affective space:

    -   For uni-dimensional spaces, as well as for three-dimensional spaces and beyond, the available algorithms are the vector/Euclidean distance and a random order, which may be interesting for research purposes (see Section below). The random order is based upon the Fisher-Yates algorithm[^3] to shuffle an array of elements.

    -   For two-dimensional spaces, the available algorithms are the ones listed above, plus the radial/arctangent distance.

3.  A non-empty array of lexicalized emotions, each of them with their position relative to the underlying affective space and the specific label. The position can be encoded as a number of coordinates or as an angle for the bi-dimensional circumplex. At the time of writing, the toolbox adopts a system of coordinates ranging from -100 to 100 with a one-step increment, but this may become more flexible in the future, for instance to account for affective spaces derived from theories with a fixed number of values (*e.g.* Pekrun's Control-Value theory).

The expressing-displaying interface of the tool can be modified almost on every aspects. Researchers and practitioners can define:

1.  The specific way by which each the rating of each dimension is prompted (*e.g.*, *Is the situation pleasant?*, *How familiar are you with the situation?*, etc.), as well as the labels of the two opposing poles of the continuum. Those can be general (*e.g.,* *Not at all* $\leftrightarrow$ *Yes, absolutely*) or more specifics to the dimension(*e.g.*, *Very unfamiliar* $\leftrightarrow$ *Totally familiar*).

2.  How the choice of the lexicalized emotion is prompted (*e.g.* *How do you feel?*, *What emotion do you feel?, ...)*.

3.  The number of lexicalized emotions that are proposed as buttons on the interface, with any number less or equal to the number of subjective feelings in the affective space. A greater number of options means that more buttons populate the interface, even though it is worth noting that the interfaces stretches when the buttons are available, but than shrinks again when the choice has been made. As a consequence, a large number of options would not reduce permanently the space available for the perceiving-monitoring function. Conversely, this number may very well be 0, meaning that no suggestion is made at all.

4.  Whether to add the "Other..." text-field to the interface or not. Adding it is generally considered a good practice [@schererWhatAreEmotions2005; @mortillaroEmotionsMethodsAssessment2015], but there may also be situations in which a forced choice can be of interest.

5.  Whether to add or not an alternative button of the kind *No emotion* or *Not sure*. The precise label of this additional button could also be determined.

The customization of how emotion is encoded can be fully appreciated by using *extreme* cases. The simplest case consists in a *pure* dimensional approach. In fact, it is possible to by-pass the computational model by providing an empty affective space, or by setting the number of suggested emotion to 0. In this case, the alternative button can be labelled the like of *Send*, and an emotion thus be represented only by the values on the sliders. From a theoretical perspective, this combination would be closer to dimensional/constructivist theories of emotion [@russellCoreAffectPsychological2003; @russellEmotionCoreAffect2009; @stanleyTwodimensionalAffectiveSpace2009] -- se also Section \@ref(theories-of-emotion) -- especially if the alternative button *Send* is replaced by an open text-field, allowing respondents to construe the appropriate emotional label based on their own cultural background and vocabulary.

Another extreme case consists in setting the number of suggestion at the same value as the total number of subjective feelings in the underlying affective space. That would by-bass the sub-setting, but not the sorting part of the computational model. In fact, all the lexicalized emotion would be available on screen, but their precise order would depend on $\Delta(E,P)$. This would be more aligned with those appraisal theories of emotions that subsume the existence of representative/modal emotion families [@moorsAppraisalTheoriesEmotion2013; @grandjeanConsciousEmotionalExperience2008].

It is also possible to provide the very same coordinates to all the subjective feelings in the affective space, in which case the order of the buttons will be fixed, no matter the ratings on the sliders. This may for instance allow to replicate part of the EMORE-L interface [@molinariEMORELOutilReporting2016], where the three appraisal dimensions and the eight discrete emotions are not linked. One can imagine to contrast a condition in which there is no link between the dimensions and the discrete emotions, and one when the link is done through an appropriate underlying affective space. As a reminder from the related works in Section \@ref(ea-intra-personal), the authors found that discrete emotions that are theoretically distinguished by different appraisal profiles (*i.e.*, different $P$), received by constrat similar ratings on the *Control*, *Value* and *Activation* dimensions (*i.e.*, similar $E$). The different configuration of the EAT could therefore investigate whether the computational model guides learners to have a more *adequate* [@schererComponentialEmotionTheory2007] appraisal evaluation as illustrated in Section \@ref(appraisal-competence).

To sum-up, the available configuration options in the expressing-displaying function can have pedagogical, theoretical, as well as user-experience implications. The flexibility of the configuration bestow researchers and practitioners the choice of which aspect should be privileged.

## Configuration of the Perceiving-Monitoring Function {#toolbox-monitoring-features}

As already mentioned, whereas the way emotion is *encoded* may be kept more or less the same regardless of the context, emotion *decoding* is highly dependent on the purpose of emotional awareness and how data is graphically represented from a visuo-spatial perspective [@hegartyCognitiveScienceVisualspatial2011]. As illustrated in the abstract model in Section \@ref(abstract-model-of-ea) built upon the definition of emotional awareness, a multi-purpose proof of concept shall consider emotional awareness as not only based on inter-personal, or not only limited to dydic interactions. Computer-mediated learning enviroments in particular span from the individual to the thousands of learners of MOOCs. Ideally, a multipurpose EAT should be able to scale congruently to the context. This possibility is inherently linked with the perceiving-monitoring part of the tool. The two representations (emotion timeline and appraisal line charts) proposed by the prototype are clearly limited to a restricted number of users. Adding 20 rows of the timeline and 20 line charts to account for 20 learners would pile up an overwhelming amount of information on screen. Research and practitioners may therefore also be allowed to choose between graphical representations of emotion aligned with the number of learners sharing the same EAT, as well as the kind of emotional meaning-making that the tool is supposed to foster [@leonyProvisionAwarenessLearners2013; @derickEvaluatingEmotionVisualizations2017; @bersetVisualisationDonneesRecherche2018; @fritzRealTimeEmotionalAwareness2016].

This subject, though, has received so far limited attention overall, as mentioned in Section \@ref(ea-in-computer-mediated-environment). The work on the proof of concept has unfortunately not progressed very much on this topic either, in spite of the good intentions [@fritzRealTimeEmotionalAwareness2016; @bersetVisualisationDonneesRecherche2018]. In particular, @bersetVisualisationDonneesRecherche2018, in his Master thesis, attempted to conceptualize graphical representation of emotion directly linked to the Dynamic Emotion Wheel, which were then assessed in a usability test. At that time, the DEW was still a prototype limited to two dimensions, and therefore the author focused on representation that combined two dimensional values with a discrete emotion. In spite of the difficult task, Berset (*ibid.*) proposed interesting representations -- such as timeline that *piles* up discrete emotions by showing also their frequency (see Figure 21 in the original manuscript) -- that have unfortunately not yet been implemented into the tool.

As a consequence, the perceiving-monitoring function of the toolbox is limited in options and scope. This sections nevertheless provides an overview of the available configuration options.

The first option, which has implications regardless of the specific graphical representation adopted, is relative to the persistence of data over time. In this regard, it is possible to decide whether the expressed emotions are maintained between different *sessions* with the instance or not. A session corresponds to a new access to the tool, which is the equivalent to loading the page into the browser and *log-in* into the instance. When data is not persisted, all the graphical representation restart afresh, without any data. If persistence is maintained, the users will find all the available data from the first time the instance has been adopted. This also includes, in case of longitudinal inter-personal/group-awareness, data produced by other users sharing the same group in the instance.

At the time of writing, the toolbox proposes only three kind of graphical representation of emotions, depicted side-by-side in Figure \@ref(fig:dew-monitoring-widgets): (1) the emotion timeline, (2) the dimensional/appraisal line charts, and (3) a word-cloud similar to the one available in the *study*'s detail page in the back-end part illustrated in Figure \@ref(fig:dew-toolbox-study-detail). All the representations will be adopted in the empirical contribution of Part III, so they are presented here only briefly.

(ref:dew-monitoring-widgets-caption) Three graphical representation of the perceiving-monitoring function: the emotion timeline, the appraisal/dimensional line charts, and the subjective feelings word-cloud. Each of them can be configured.

```{r dew-monitoring-widgets, fig.align="center", fig.cap="(ref:dew-monitoring-widgets-caption)", out.width="30%", fig.show="hold"}
knitr::include_graphics(
  c(
    here::here("./figure/dew/dew-emotion-timeline.png"),
    here::here("./figure/dew/dew-appraisal-linechart.png"),
    here::here("./figure/dew/dew-wordcloud.png")
    
  )
)
```

The three graphical representation can all be configured according to the falling parameters. Congruently with the intra-personal and/or intra-personal functon of emotional awareness, each of them can provide information about the user herself and/or the other users in the same group/instance:

1.  For the emotion timeline, this means that the widget can show (1) only the *You* row; (2) only one row for every other user (*e.g.*, the *P987654* and *P555555* rows), whereas it is not possible to single-out exclusively one user if many are sharing the same space; or (3) both the *You* and one row for each other user, as it is the case in the image.
2.  For the line charts, the interface can show (1) only the line chart with the appraisals/dimensions of the user herself (as in the image); (2) only one line chart for every other user in the group; or (3) both the user's own line chart and that/those of the other(s). The legend of each line/dimension can also be configured.
3.  For the word-cloud the situation is slightly different, but the sense is the same. The interface can once again show (1) only the cloud of the user's own feelings; (2) only one cloud where the feelings of all other users (bar the user herself) are combined; (3) only one cloud where all the feelings (user herself plus all other users) are combined; or (4) any combination of the previous three.

The title of the panel in which the graphical representation is contained can also be configured. In the case the line charts of other participants are adopted when there are more than one other user, the users' ID is added to the panel's title. The order of appearance can also be determined thorough the back-end admin area, except within a sequence of line charts belonging to other users, which will be stacked one after the other.

To sum-up, at the time of writing there is a limited set of graphical representation to *decode* emotion for the perceiving-monitoring function of awareness. Those that are available, though, can be articulated from an intra-personal, inter-personal or combined perspective. This possibility will be harnessed in both empirical contributions in Part III.

## Configuration of Research-Related Features {#toolbox-research-features}

Being the toolbox also meant for researchers, there are a few features that are specifically meant for empirical studies or experiments. Most of them belong to standard procedures in studies' interactions, whereas one is very specific to the toolbox. The *standard* features includes:

1.  As mentioned in the presentation of toolbox front-end, a screen can be devoted to instructions. Even though this can be helpful also for practitioners, they may be particularly useful in case of online studies. At the time of writing, the text can be written in Markdown, a widely used, light-weight mark-up language that allows to structure a text with titles, lists, images, etc. So the instruction can be as long and as precise as needed.

2.  It is possible to force participants to use a pre-defined or random IDs for either or both the user and group identifiers. The system can also block the same IDs from being used again once the log-in has been done.

3.  The duration of the task can be set to a specific time, with or without a timer that is available on the top of the interface, as in Figure \@ref(fig:toolbox-frontend-interface). A button that users can click to stop the task can also be made available, and labelled as wished.

4.  The last screen of the front-end interface can contain a custom text, which can also be formatted. It is also possible to provide an *exit URL* and a label for the button that points at it. This may be useful for instance if there is an additional step in the procedure (*e.g.*, an online survey) or for directing participants to the end-of-trial URL commonly adopted by online recruiting platforms.

The specific research-related features consists in the possibility to simulate the emotional experience of one or more fake participants, and inject it in the interface through the graphical representations of the perceiving-monitoring function described above. This possibility has been evoked in the illustration of the DEW's usability test and will also be adopted in the first empirical contribution presented in Chapter \@ref(study-1). To simulate the emotional experience, researchers must provide a list of *observations* that respects the number of dimensions of the underlying affective space, for consistency with what is expressed by *true* participants. The list of simulated emotions is therefore composed by:

1.  A consistent identifier for every emotion belonging to the fake user. For instance, in the emotion timeline in Figure \@ref(fig:dew-monitoring-widgets), the *P555555* is faked. This shows incidentally that a fake participant can be added as the only other participant to a dyadic task, but also in addition to more than one *true* participant. To simulate more than one fake user, it suffices to enter in the list a different number of unique identifiers.

2.  A time when the simulated emotion will be injected into the system. The value refers to the time elapsed since the log-in from every *true* participant accessing the instance, so it is more appropriate to use the simulation with synchronized trials of a fixed duration and not repeatable more than one time.

3.  A value respecting the domain [$V_{min}:V\_{max}$] for every appraisal/dimension in the adopted affective space. If the interface includes the line charts for other participants, those values will serve to populate the graphics.

4.  An emotion term or idiom, such a lexicalized emotion, that represents the subjective feeling. The label does not necessarily have to be part of the adopted underlying affective space. It can be manipulated as desired. For instance, one can test whether a *fake* participant that only uses custom emotion terms influences *true* participants to avoid the pre-defined options. Or the fake participant could provide lexicalized emotions belonging to the affective space, but with inchoerent appraisal/dimensional values (*e.g.*, a negatively valenced emotion terms when the *Valence* dimension is rated positively, or vice-versa).

The simulation of a participant can also be adopted systematically. As a reminder from the related works in Section \@ref(ea-inter-personal) about inter-personal emotional awareness, @avryAchievementAppraisalsEmotions2020 manipulated feedback in an online collaborative game representing the *Control* and *Value* dimensions of Pekrun's theory [@pekrunControlValueTheoryAchievement2014; @pekrunControlValueTheoryAchievement2006]. The toolbox can provide a simulation including also the subjective feeling rather than only appraisal dimensions. For instance, different *emotional profiles* of the *fake* participants can vary according to how it evaluates and categorize/integrate the situation. The consequences of these differences can be tested on a number of cues spanning the quality of interaction, what kind of personality is attributed to the *fake* participant, whether it impacts the emotional experience of the *true* participants, and so on. In this regard, a third experiment harnessing this features was planned for this contribution, but was ultimately not carried out do to the outbreak of the COVID19 pandemic. More details will be provided in the concluding part of the thesis.

To sum up, the toolbox provides researchers with features that can serve *standard* procedures in empirical settings, but also use the tool to create conditions or manipulations that can help to respond to specific research questions. Measurements gathered through the toolbox play in this sense a major role. They are thus illustrated next in the chapter.

## Measures Available Through the Toolbox

## Summary

[^1]: Which is revealing of what is the primary goal of the toolbox, but I hope practitioners can also take advantage from it

[^2]: At the time of writing, examples of widely adopted vector editors are the proprietary Adobe Illustrator and Affinity Designer, or the open-source Inkscape.

[^3]: <https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle>
