# Building a Toolbox Around the Parsimonious Computational Model {#toolbox-chapter}

```{r eat-dashboard-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)

```

In the previous chapter illustrated the parsimonious computational model linking appraisal dimensions and subjective feelings as a representation of an emotion structure that can be *injected* into a graphical user interface to self-report emotions. The model represents the *core* of the proof of concept proposed by the thesis, but is clearly not sufficient to provide emotional awareness in computer-mediated learning environments. In this regard, this chapter introduces a toolbox built around the computational model that allows the configuration of the expressing-displaying as well as the perceiving-monitoring functions of an Emotion Awareness Tool (EAT) according to researchers and practitioners needs. The implementation of a toolbox is driven by open science tenets, which advocate the need for investing in the development of open material that can foster transparency, sharing, replicability and reproducibility of research practices and results. In this intent, the toolbox pays particular attention in incorporating these tenets.

PLACE IT SOMEWHERE

Contrary to *pure* and individual self-report instruments, which may be administered in different settings with minimal adaptations, an EAT presents more challenging technical constraints, especially from a moment-to-moment and inter-personal perspective. Whenever synchronization between two or more *agents* sharing information is concerned, it is necessary to adopt a bi-directional communication technique, such as web sockets. Most web applications are in fact based on the client-server architecture, through which the *agent* (the client) sends a request to the server, which responds back with the appropriate response (e.g., the content of a page). Outside the bounded episode of request/response, though, the server has no way to send information to the client, if the client hasn't initialized a request first. Nowadays the concept of *push* notifications in mobile phones or web sites has become ubiquitous, but still, the technique requires adequate hardware and software, which is not readily available.

As a consequence, the technical extension relates more generally to making the tool available to a wider audience of interested researchers and practitioners, minimizing the technical burden to set up a computer-mediated environment with the appropriate requirements. The combination of the theoretical and technical extensions, thus, suggests the interest for the development of a comprehensive toolbox allowing researcher to customize and carry out directly their instances of the EAT according to their specific aims.

Third, as illustrated in the abstract model in Section \@ref(abstract-model-of-ea) built upon the definition of emotional awareness, a multi-purpose proof of concept shall also consider computer-mediated learning environments not based on inter-personal, or not limited to dydic interactions. Computer-mediated learning enviroments span from the individual to the thousands of learners of MOOC. Ideally, a multipurpose EAT should be able to scale congruently to the context. This possibility is inherently linked with the perceiving-monitoring part of the tool. The two representations (emotion timeline and appraisal line charts) proposed by the prototype are clearly limited to a restricted number of users. Adding 20 rows of the timeline and 20 line charts to account for 20 learners would pile up an overwhelming amount of information on screen. Research and practitioners may therefore also be allowed to choose between graphical representations of emotion aligned with the number of learners sharing the same EAT, as well as the kind of emotional meaning-making that the tool is supposed to foster [@leonyProvisionAwarenessLearners2013; @derickEvaluatingEmotionVisualizations2017; @bersetVisualisationDonneesRecherche2018; @fritzRealTimeEmotionalAwareness2016].
