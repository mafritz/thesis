# Emotion Awareness in Asynchronous and Individual Settings

```{r s2-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)

Sys.setenv(LANG = "en")

# Load the relevant data and graphs from the study-1 folder
source(here("data", "study-2", "s2-export.R"))
```

The study illustrated in the previous chapter suggests the presence of a genuine interest in the use of an Emotion Awareness Tool (EAT) in a real-time, computer-mediated collaborative task. Nevertheless, this does not exclude the possibility that emotional awareness may be beneficial above and beyond these conditions, for instance in asynchronous and individual conditions. It is in fact widely accepted that one of the main drawbacks in remote learning is the lack of social presence: learners often feel alone, without any contact with their colleagues [*e.g.*, @jacquinotApprivoiserDistanceSupprimer1993; @paquelinDistanceQuestionsProximites2011; @parkinsonEmotionsDirectRemote2008; @sungFiveFacetsSocial2012]. An interest towards an EAT may therefore be motivated by the fact that emotions are used as a *proxy*, a strong reminder that there is someone else *out there*, even without the need to integrate the emotional information as instrumental to task at hand [@buderGroupAwarenessTools2011; @dourishAwarenessCoordinationShared1992]. In this regard, the use of an EAT may contribute to provide learners with a shared understanding of the affective implications of the distance learning conditions. For instance, sharing emotions with their colleagues may, one the one hand, provide useful information as social reference, on the basis of which learners can regulate their own emotions in facing the challenges of remote learning conditions [@fischerSocialFunctionsEmotion2016; @grossEmotionRegulationCurrent2015; @grossHandbookEmotionRegulation2014; @winneWhatStateArt2015]. On the other hand, the affective dimensions created through the EAT may contribute to foster a sense of belonging and cohesion to the group, even in the absence of face-to-face and/or synchronous exchanges [@barsadeGroupAffect2015; @barsadeRippleEffectsEmotional2002; @rimeEmotionElicitsSocial2009; @rimePartageSocialEmotions2005; @salasMeasuringTeamCohesion2015; @parkinsonInterpersonalEmotionTransfer2011; @parkinsonEmotionsDirectRemote2008; @vankleefEmotionalCollectivesHow2015; @vankleefEmotionalInfluenceGroups2017].

This second empirical study will investigate whether real-time collaboration represent a necessary condition for the usefulness of an EAT in distance learning, or whether the social and relational information it conveys can be useful even in an asynchronous and individual condition. In this regard, students of two classes following the same course in a blended Master in Learning and Teaching Technologies will be provided with the possibility to use an EAT during the periods of remote learning, through which they can share their emotional states with all the other members of the class. Their use of the tool and their attitude towards the usefulness of it will be monitored at different time during the semester in order to assess the usefulness of the EAT. In this intent, the chapter also introduces the Emotion Awareness Usefulness (EAU) survey, which is derived from dimensions described in the literature, and aims at investigating to what extent the presence of an EAT is instrumental in understanding, interpreting, and experiencing emotion [@boehnerHowEmotionMade2007].

The end of the chapter provides corollary analyses as a preliminary attempt in investigating whether the adoption, use and perception of the EAT are related to learners' emotional competence [@brackettEnhancingAcademicPerformance2012; @brackettRULERTheoryDrivenSystemic2019; @schererComponentialEmotionTheory2007; @schlegelGenevaEmotionalCompetence2018]. A link between three sub-competences -- namely the appraisal, the communication, and the regulation competences [@schererComponentialEmotionTheory2007] -- and the use of an EAT is also proposed.

By implementing the use of an EAT in longitudinal, collective, and ecological settings, the present chapter aims at investigating the adoption, use and perception of an EAT by learners in remote learning environment. The present chapter may therefore be of interest to the broader field of distance learning and, more specifically, to the investigation of the relationship between affective states and technology enhanced learning [@arguedasOntologyEmotionAwareness2015; @bakerBetterBeFrustrated2010; @dmelloDynamicsAffectiveStates2012; @dmelloSelectiveMetaanalysisRelative2013; @lehmanConfusionComplexLearning2012; @reisAffectiveStatesComputersupported2018; @reisAffectiveStatesCSCL2015]. The chapter also investigates emotions at the group level [*e.g.*, @barsadeRippleEffectsEmotional2002; @cheshinAngerHappinessVirtual2011; @keltnerSocialFunctionsEmotions1999; @parkinsonEmotionSocialRelations2005; @smithCanEmotionsBe2007; @vankleefEmotionalCollectivesHow2015; @vankleefEmotionalInfluenceGroups2017] and may therefore be of interest in studies using groups as unit of observation.

## Study Overview

At the origin, awareness in Computer-Supported Cooperative Working (CSCW) was limited to cues about the presence of other co-workers: whether they were online and on what they were working on [@grudinComputerSupportedCooperativeWork1994; @gutwinDescriptiveFrameworkWorkspace2002; @gutwinWorkspaceAwarenessRealtime1996]. Progressively, awareness has assumed a broader perspective and, especially in computer-mediated collaboration and Computer-Supported Collaborative Learning (CSCL), there is nowadays a consensus about the need to provide -- through awareness tools -- information about others, which is inherently linked to social and relational phenomena [@arguedasOntologyEmotionAwareness2015; @buderGroupAwarenessTools2011; @janssenCoordinatedComputerSupportedCollaborative2013; @janssenGroupAwarenessTools2011]. An Emotion Awareness Tool (EAT) is deeply rooted in this perspective, since the information shared is not directly part of the collaborative task. In other words, using Janssen and Bodemer [-@janssenCoordinatedComputerSupportedCollaborative2013] division between the *content* and the *relation* spaces already mentioned also in the previous chapter, an EAT may be limited to the *relational* space if learners do not make the effort to integrate that information also in the *content* space. This fact may therefore limit the usefulness of Emotional Awareness to enhancing the social presence. That is, emotions shared through the EAT are used as a *proxy*, a strong reminder of the presence of other learners, but without integrating the emotional information into the task at hand. This phenomenon would not be inherently bad, since it is widely accepted that one of the main drawbacks in distance learning is the sentiment of loneliness and isolation [*e.g.*, @carswellDistanceEducationInternet2000; @conradEngagementExcitementAnxiety2002; @jacquinotApprivoiserDistanceSupprimer1993], but it would question whether the result is worth the effort: social presence may be sustained with cues that are closer to the *content space* compared to the dual-task [@pashlerDualtaskInterferenceSimple1994] imposed by the use of an EAT while performing the learning activities. Performance-based indicators of interest in emotional information sharing, seeking and processing -- obtained in the randomized trial with three different interfaces illustrated in the previous chapter -- seem to corroborate a genuine interest in emotional awareness as instrumental to the task at hand. That does not exclude the possibility, though, of an interest in using the EAT exclusively as a form of social presence. Therefore, it is worth investigating the usefulness of an EAT in an asynchronous and individual situation: can it still be useful?

In order to investigate the matter, the adoption of an experimental approach as the one used in the previous study is nevertheless inadequate for at least the following reasons. First, using a task of a relatively short time may fail to produce a sense of belonging to a group, especially in a computer-mediated settings. It is therefore more reliable to measure the usefulness of the EAT in an extended period of time, ideally in order to assess whether the perception of usefulness evolves in time. Second, if collaboration is removed, participants would be sharing emotions with, and seeing emotional episodes of an estranged person, without any connection in time, space or purpose. Thus, the social presence should rather be elicited in a group that has already a *raison d'Ãªtre*, and whose members share as many elements as possible, even though they are not directly collaborating. Third, in an asynchronous and non collaborative situation, emotions may be elicited by a wide range of elements which are more difficult to pinpoint to something that has happened synchronously. It is thus important that the context in which emotional episodes emerge is as ecological as possible, for them to be representative as a *proxy* of the person.

For these reasons, the present study adopts a longitudinal plan [@fitzmauriceAppliedLongitudinalAnalysis2011] in which the use of the EAT is implemented in an ecological context of distance learning. The Master of Science in Learning and Teaching Technologies (MALTT) at Geneva University provides a blended learning program since more than 20 years. The planning divides each semester in three periods, in which a week of on-site classes is followed by 4-5 weeks of remote learning, during which students are often assigned a small project to submit before the following period begins. The use of the EAT will be implemented in one of the courses of the Master, named *Sciences et Technologies de l'Information et de la Communication I* (STIC I), which covers introductory web programming and computational thinking [@fritzPenseeComputationnelleAvec2019]. Students will use the EAT to express their emotions at any moment while they are working for the STIC I course, a mechanism comparable to the Experience Sample Method [ESM; @csikszentmihalyiValidityReliabilityExperienceSampling2014] or the Ecological Moment Assessment [EMA; @shiffmanEcologicalMomentaryAssessment2008] already used in distance learning situations (*e.g.*, @molinariEMORELOutilReporting2016, but see for instance @scollonExperienceSamplingPromises2003 for a critical assessment of the method). Contrary to some implementation of ESM or EMA, in which there is an external prompt that reminds participants of the recording activity, the use of the EAT is left to the spontaneous initiative of students, who can decide whether and when to use it based on the eliciting events during remote learning [@wheelerSelfRecordingEverydayLife1991].

Compared to the previous study, the emotional information of more than two students will be shown on the perceiving-monitoring part of the interface [@buderGroupAwarenessTools2011; @schmidtProblemAwareness2002]. As a consequence, the way emotional awareness is graphically represented on screen must also be adapted in order to convey a *grouped* representation of a whole class [@bersetVisualisationDonneesRecherche2018; @fritzRealTimeEmotionalAwareness2016]. This technical modification has consequences on a more abstract and theoretical level, since *individual* or *dyadic* emotions are replaced by *group* emotions [*e.g.*, @barsadeRippleEffectsEmotional2002; @keltnerSocialFunctionsEmotions1999; @parkinsonEmotionSocialRelations2005; @smithCanEmotionsBe2007; @vankleefEmotionalCollectivesHow2015; @vankleefEmotionalInfluenceGroups2017]. The use of the EAT may therefore be influenced by collective dynamics. For instance, Cheshin, Rafaeli and Bos [-@cheshinAngerHappinessVirtual2011] found supporting evidence that emotional contagion [@barsadeRippleEffectsEmotional2002; @hatfieldEmotionalContagion1993] can also happen in virtual teams, where computer-mediated communication is exclusively text-based.

In this regard, comparing two classes of the same course in different years may therefore also contribute to investigate to what extent the adoption, use and perception of the usefulness of an EAT is determined *mainly* by individual characteristics or is also influenced by *interactions* between the individual and the group [@boehnerHowEmotionMade2007; @dillenbourgSymmetryPartnerModelling2016]. Even though students would not be randomly assigned to the classes, it is difficult to figure out systematic factors at play, which would determine why particular students would apply in a specific year rather than another, especially in a Master that has always been very heterogeneous in the students' profile.

Finally, whereas the number of emotions expressed can be maintained as an indicator of the use of the EAT, the eye-tracking measures used to detect emotional information seeking and processing cannot be replicated in a longitudinal plan. For this reason, the study also implements a tentative survey aiming at measuring the perceived Emotion Awareness Usefulness (EAU). The survey -- thoroughly depicted in the material section -- combines 7 dimensions retrieved from the literature:

1.  *Frequency*. The frequency of use is a dimension used in different scales pertaining to Human-Computer Interaction and User Experience [@mackenzieHumanComputerInteractionEmpirical2013; @tullisMeasuringUserExperience2013], as it is the case in the System Usability Scale [@brookeSUSQuickDirty1996]. The more frequently a tool is used, the more useful it is perceived, especially when the use is voluntary.
2.  *Affordance*. Affordance in this context broadly refers to the actions available through the EAT and where they take place [@normanDesignEverydayThings2013]. The presence of an EAT may prompt users to share their emotions, something they would not do without the presence of the tool [*e.g.*, @parkinsonEmotionsDirectRemote2008; @rimeEmotionElicitsSocial2009; @vankleefInterpersonalDynamicsEmotion2018].
3.  *Social Presence*. Social presence is a pivotal dimension in remote learning, providing support for learners isolation and feeling of loneliness [*e.g.*, @gunawardenaSocialPresencePredictor1997; @tuRelationshipSocialPresence2002]. Perceiving the emotions of colleagues can help learners to remember there are others in the same condition as they are.
4.  *Self-Understanding*. Having emotions a strong influence on intra-personal functions [*e.g.*, @broschImpactEmotionPerception2013; @levensonIntrapersonalFunctionsEmotion1999; @schererWhatAreEmotions2005], the presence of an EAT may contribute to a better self-assessment of the situation and its consequences on learners' behavior.
5.  *Understanding Others*. The presence of the emotions of colleagues through the EAT may inform learners about what others are experiencing during the remote learning periods, providing information to build and update a mental model of the causes and consequences on their behavior [*e.g.*, @dillenbourgSymmetryPartnerModelling2016; @vankleefEmergingViewEmotion2010; @vankleefEmotionalInfluenceGroups2017; @vankleefInterpersonalDynamicsEmotion2018]
6.  *Self-Other Comparison*. Comparing one's own emotions with that of the colleagues can provide useful information, especially in situation of incertitude [*e.g.*, @eligioEmotionUnderstandingPerformance2012; @molinariEmotionFeedbackComputermediated2013; @vandevenEnvyAdmirationEmotion2017]. The presence of the EAT may facilitate and prompt this comparison.
7.  *Self-Regulation*. Emotion regulation is a pivotal phenomenon that allows learners to modify their emotional experience using different strategies, such as suppression or reappraisal, in order to maintain instrumental emotional states and modify disruptive ones [*e.g.*, @arguedasAnalyzingHowEmotion2016; @grossEmotionRegulationCurrent2015; @grossHandbookEmotionRegulation2014; @jarvenojaRegulationEmotionsSocially2013]. The presence of the EAT, both in terms of learners own emotions and that of the colleagues, may facilitate regulatory processes.

## Research Questions

The present study aims at investigating four main topics. The first consists in the assessment of whether synchronous collaboration is a *necessary* condition for emotional awareness to be perceived as an integrated information into the task. If an EAT is perceived useful even when participants are not directly collaborating, it will rather suggest that emotional awareness is a *sufficient* condition for enacting social presence of others, regardless of the collaborative or individual nature of the task [@mackieCausesConditions1965]. In other words, emotional awareness could act as a *proxy* for students not to feel alone during distance learning and provide social reference as to how colleagues are feelings [@barsadeGroupAffect2015; @hareliEmotionsSignalsNormative2013; @vankleefEmotionalInfluenceGroups2017], as well as enhancing group belonging and cohesion during remote learning [@andersonEmotionalConvergencePeople2003; @keltnerSocialFunctionsEmotions1999; @salasMeasuringTeamCohesion2015; @vankleefEmotionalCollectivesHow2015]. The first research questions (*Q1*) thus investigates what is the use and the perception about the usefulness of emotional awareness in asynchronous and individual learning settings, and whether the use or the perception of usefulness change over time.

The second purpose of the study is to contribute to assess whether the use of an EAT depends *mainly* on the individual characteristics of the students or is *also* determined by the interaction between students using the tool at the same time [@dillenbourgSymmetryPartnerModelling2016]. Taking advantage of the fact that two classes will use the EAT under *more or less* equivalent conditions (same course, same program, same learning environment, ...) -- and assuming no systematic factor at play determining particular type of students in one class compared to the other -- differences in the use or perception of the tool between one class and the other should corroborate the effect of interaction rather than individual characteristics alone. The second research question (*Q2*) therefore investigates whether differences in the use or the perception of usefulness of the EAT can be detected between one class and the other.

The third aim of the study is to assess the perceived usability [@tullisMeasuringUserExperience2013] of an EAT in a longitudinal and asynchronous context. The previous assessment of the tool was conducted in a usability test, with the same fixed time and simulated collaborative task as in the previous chapter (Fritz, 2015). It is therefore worth investigating what is the perceived usability of the EAT in an ecological context.

The forth and last purpose of the study is to assess to what extent the moment-to-moment emotions expressed by learners are then recollected correctly after a period of time, both with respect to their own expressed emotions and that of their colleagues. There is in fact evidence in the literature suggesting that emotional episodes have a privileged access to memory [@broschImpactEmotionPerception2013; @kensingerRetrievalEmotionalEvents2020; @montagrinGoalConducivenessKey2013; @poolAttentionalBiasPositive2015; @rimePartageSocialEmotions2005], and it is therefore worth exploring whether the presence of an EAT contributes in *anchoring* the individual and collective affective experience during distance learning.

No hypothesis is nevertheless posited for any research question, because the setting is too unpredictable. The EAT has never been used before in longitudinal studies, which are by nature more prone to unforeseen events. For instance, it is not even warranted that the EAT will be used in the first place. Furthermore, the measure of emotion awareness usefulness is tentative and non-validated. Consequently, positing hypothesis without pre-registering them would expose any finding to well-founded doubts of questionable research practices [@johnMeasuringPrevalenceQuestionable2012; @makelQuestionableOpenResearch2019], especially Hypothesizing After the Results are Known (HARKing; @kerrHARKingHypothesizingResults1998). All research questions should therefore be interpreted as non-confirmatory [@scheelWhyHypothesisTesters2020].

## Methods

I report how I determined the sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

`r s2.participants_aggregated_all %>% nrow()` students (`r (s2.participants_gender_age$gender == "F") %>% sum()` women, `r (s2.participants_gender_age$gender == "M") %>% sum()` men, and 5 missing values) of the course *Sciences et Technologies de l'Information et de la Communication I* [@fritzPenseeComputationnelleAvec2019] in the Master of Science in Learning and Teaching Technologies at Geneva University took part in the study ($M_{age} = `r s2.participants_gender_age$age %>% mean(na.rm = TRUE) %>% printnum()`$, $SD_{age} =`r s2.participants_gender_age$age %>% sd(na.rm = TRUE) %>% printnum()`$ with 7 missing values). Students belonged to two classes that took the one-semester course in two successive years during the period of the thesis (2015-2020): `r table(s2.participants_aggregated_all$group)[1]` students in the first class, and `r table(s2.participants_aggregated_all$group)[2]` students in the second, without overlapping. It is worth noting that a third cohort was originally planned to increase the sample size, but the study has not been implemented because this third cohort had to undergo an abrupt switch to an exclusive distance learning format due to the pandemic. Even though a completely online format would have been even more interesting for the purpose of the present study, the use of the EAT would have added up to an already complicated situation. Furthermore, the cohort would also differ with the other in the way social links could have been created, not disposing of the same weeks with on-site courses.

The use of the EAT was warranted as a pedagogical activity, since the use of technological tools in learning situations is an integral part of the Master's program. Given no participant can be forced to take part to a study, though, students had the choice, at the end of the course, either to sign a consent form allowing data to be used for research purposes, or to write on the same form only the ID they were given at the beginning of the study (without connection to their identity, see procedure below) so that all data associated with that ID could be erased. The overall sample size of the study is therefore determined by the number of students whose ID appears in at least one of the different sources of measure (see below) and has not been retracted via the *non-consent* form.

The population is clearly a convenience sample, but the choice has nevertheless both an explanation and a potential interest over and above the limitations. The explanation is preeminently of a technical nature. The EAT has never been adopted in a longitudinal study, where it must be seamlessly available even in the absence of the experimenter. Since the study implies comparison between two cohorts, it is therefore mandatory that technical problems should be signaled and repaired as soon as possible. In this regard, MALTT students possess the technical know-how to identify and accurately describe malfunctioning in a web application, as well as a quick access to the technical team.

The interest of the convenience sample is, ironically, its potential inconvenience. In fact, if the tool is adopted and considered as useful, results may be biased by the convenience sample, and therefore be taken with more than a grain of salt. On the other hand, if the tool is not adopted and considered of scarce usefulness, then the shortcomings are amplified, since even learners with an interest, habit, and technical know-how would not adopt it.

### Material

#### Configuration of the Emotion Awareness Tool

The Dynamic Emotion Wheel Research Toolbox (DEW-RT) was adopted for both cohorts. The configuration of the Dynamic Emotion Wheel (DEW), depicted in Figure \@ref(fig:s2-dew-interface-figure), is implemented as follows.

For the expressing-displaying function of awareness, the same EATMINT circumplex used in the study depicted in the previous chapter and also in Fritz (2015) was adopted. As a reminder, this affective space comprises 20 emotions organized over the two appraisal dimensions *Valence*, prompted with the question *is the situation pleasant?*, and *Control/Power*, prompted with the question *is the situation under your control?*. Both dimensions were characterized by two opposite poles, labeled *not at all* and *yes absolutely*. The choice and disposition of the subjective feelings is thoroughly depicted in the chapter about the DEW-RT, within the section dedicated to the EATMINT affective space.

For the perceiving-monitoring function of awareness, three *word clouds* were implemented. In a *word cloud*, words are depicted in a font whose size is proportional to the number of occurrences of that world in a specific context, such a text document or a categorization, so that the more frequently used words appear bigger than the less frequently used ones. The perceiving-monitoring interface of the EAT comprised the following elements:

1.  A *Self-Centered* word cloud, depicting the last 50 feelings expressed by the participant herself;
2.  A *Partners-Oriented* word cloud, depicting the last 100 feelings expressed by the other members of the class, that is all the feelings bar that of the participant herself;
3.  A *Collective-Oriented* word cloud, depicting all the emotions expressed by the whole class since the first use of the EAT, that is, the emotions of the participant herself, plus that of the other members.

(ref:s2-dew-interface-caption) Interface of the EAT for a participant, depicting the expressing-displaying and perceiving-monitoring parts of the tool. For the perceiving-monitoring parts, the word clouds refer to the social functions of emotions identified by Fischer and Mastead [-@fischerSocialFunctionsEmotion2016]: affiliation and distancing (details in the text).

```{r s2-dew-interface-figure, fig.cap="(ref:s2-dew-interface-caption)", fig.align="center", out.width="50%"}
include_graphics(here("figure/s2/dew-interface.png"))
```

The combination of the three word clouds sustain the two main social functions of emotions identified by Fischer and Mastead [-@fischerSocialFunctionsEmotion2016]: the affiliation and the distancing function. The top and center word clouds allow participant to compare her own emotions (top) with that of the class (center). In this way, she can position herself with respect to the group (distancing). The bottom word cloud groups all the emotions of the class and is therefore more related to the affiliation function of emotions.

The number of emotions proposed by each word cloud is arbitrary, since there is no previous benchmark about frequency of use in general, and expression in particular. The word cloud also present *a priori* shortcomings with respect to subjective feelings typed directly by participants, since for them to be grouped, they should be written in exactly the same way (*e.g.*, a small typo would isolate that expression). All things considering, though, word clouds are relatively known graphical representation, and convey an immediate and straightforward method of aggregation.

Compared with the interface used in the study illustrated in the previous chapter, thus, the differences concern only the perceiving-monitoring part of the EAT. First, all the emotional information was conveyed through the subjective feelings, with no trace of the cognitive evaluation. This choice is technically justified by the lack, at the time being, of a grouped representation of the appraisal dimensions, since the line charts used in the previous study are limited to individuals. It is also warranted by the fact that, in the usability test conducted on the prototype of the DEW (Fritz, 2015) adopting the very same interface as in the previous study, eye-tracking measures clearly showed that the subjective feelings in the emotion time line were sought more often than the line charts with the appraisal dimensions. Second, no temporal reference appeared at all, since the subjective feelings were categorized based on the frequency alone. This choice is justified by the fact that, in an asynchronous context, the temporal reference conveys limited information, especially considering that there is no manifest link between the time and a specific task or situation involved. Third, except for the participant's own emotions, it was not possible to discern what specific colleague has expressed a particular feeling or cluster of feelings. Once again, this choice is technically imposed by the lack, at the time being, of a grouped representation of feelings, which is able to maintain agency without overcrowding the interface. The choice is nevertheless also a theoretical influence, since in such a setting, the emotions of the colleagues are *truly* at a group level [@barsadeGroupAffect2015; @smithCanEmotionsBe2007; @vankleefEmotionalCollectivesHow2015]. More generally, without a previous benchmark about the number and frequency of emotions expressed in an asynchronous, individual situation, it was also difficult to establish grouping criterion (e.g. group by hour, by day, or by week). The grouped representation of emotions is an open issue that has just started to be investigate [see for instance @bersetVisualisationDonneesRecherche2018].

#### Emotion Awareness Usefulness Rating

According to Boehner and colleagues [-@boehnerHowEmotionMade2007, p. 207], "success of [an affect-aware] system is measured by whether users find the system's responses useful for interpreting, reflecting on, and experiencing their emotions". Based upon this perspective, the study introduces a tentative scale that aims at measuring Emotion Awareness Usefulness (EAU) with respect to 7 dimensions identified in the literature (see also the study overview). The scale comprises 7 items expressing one of the 7 dimensions, for which participants expressed their accord on a scale from 1 (strongly disagree) to 10 (strongly agree) according to the item alone (*i.e.*, with no reference to the dimension):

1.  *Frequency*. I used the tool frequently (e.g. every time I worked for the course).
2.  *Affordance*. The use of the tool prompted me to share my emotions.
3.  *Social Presence*. The use of the tool allowed me to feel less lonely during remote learning periods.
4.  *Self-Understanding*. The use of the tool allowed me to better understand my emotions.
5.  *Understanding Others*. The use of the tool allowed me to better understand the emotions of my colleagues.
6.  *Self-Other Comparison*. The use fo the tool allowed me to compare my emotions with those of my colleagues.
7.  *Self-Regulation*. The use of the tool allowed me to regulate my emotions.

The scale is very straightforward and with only a few items, specifically only one per dimension. This is a potential shortcoming from a reliability and validity standpoint, but, especially in a repeated measure design, brevity is of essence. Once again, the convenience sample of the study provides some leverage on the formulation of items, since MALTT students are, for instance, familiar with terms such as *regulation*, which may be too technical for other populations and therefore would require a more explicit formulation.

#### System Usability Scale

The System Usability Scale (SUS) is a widely adopted scale that measures the usability of a tool [@brookeSUSQuickDirty1996]. It comprises 10 items, usually on a 5-point scale, but that can also be adapted to a 7-point range, which has been the case for this study. The 10 items are as follows:

1.  I think that I would like to use this system frequently
2.  I found the system unnecessarily complex
3.  I thought the system was easy to use
4.  I think that I would need the support of a technical person to be able to use this system
5.  I found the various functions in this system were well integrated
6.  I thought there was too much inconsistency in this system
7.  I would imagine that most people would learn to use this system very quickly
8.  I found the system very cumbersome to use
9.  I felt very confident using the system
10. I needed to learn a lot of things before I could get going with this system

The even items of the scale are reversed, so that a lower evaluation on the item corresponds to a greater perceived usability. The scale uses a system of coefficients that add up to obtain a score between 0 and 100. A more thorough discussion of the scale is available in the next chapter, where the usability score of the SUS will be compared between the usability test (Fritz, 2015) and the score obtained in the present study.

#### Geneva Emotional Competence Test

The Geneva Emotional Competence (GECo) test [@schlegelGenevaEmotionalCompetence2018] is a performance-based test that measures emotional competence as an ability, rather than a trait [@chernissEmotionalIntelligenceClarification2010; @saloveyEmotionalIntelligence1990; @schererComponentialEmotionTheory2007]. The test is primarily concerned with emotions in a workplace, which has relevant congruence with inter-personal dynamics in remote learning. The test is divided in 4 sub-competences tests, namely *emotion recognition*, *emotion understanding*, *emotion regulation*, and *emotion management*.

Emotion recognition determines the ability to infer the corresponding emotional state of a person using video clips of actors. Participants look and hear a professional actor expressing a pre-defined emotion using facial expression and pronouncing pseudo-words with a corresponding vocal prosody. Participants must then choose among different natural language words the one that best describe the displayed emotion.

Emotion understanding determines the ability to infer the corresponding emotional state of a person based on a description of a situation. Participants read the details of an event that occurs to another person and must infer which emotion, among a list of discrete options, has been elicited by that event.

Emotion regulation determines the ability in engaging in adaptive (vs. disruptive) strategies to modify one's own emotional state. Participants read the description of a situation they must imagine has happened to them, which is meant to trigger disruptive emotional episodes and must identify the two appropriate strategies vs. the two inappropriate ones.

Emotion management determines the ability to adopt the better strategy to handle situations eliciting disruptive emotions in others. Participants read a vignette depicting a situation in which they interact with another person. The situation is meant to elicit in that other person a disruptive emotional response such as anger, irritation or misplaced happiness. The participant can then choose between 5 different strategies to manage the emotional response of the other person, among which one is considered to be the more appropriate.

Each sub-test yields a score of accuracy ranging from 0 (low competence) to 1 (high competence). The 4 scores can be combined to obtain an overall emotional competence score.

#### Individual and Class Perceived Frequency of Feelings

Considering the fact that the *word clouds* adopted in the perceiving-monitoring part of the EAT clearly define which feelings have been experienced more frequently than others, the study comprises a survey that asks participants, at the end of the semester, to rate the frequency by which (1) they have felt each of the 20 subjective feelings of the EATMINT circumplex ; and (2) their colleagues have felt each of the same 20 subjective feelings. In the survey, each subjective feeling is presented with a 5-point scale comprising *never*, *seldom*, *sometimes*, *often* and *very often*. Participants were also allowed to skip each particular feeling without rating the frequency both in the individual and the class surveys.

### Procedure

All courses of the Master are organized in three periods per semester, which will defined by P1, P2 and P3. Each period is composed by a week of on-site courses, and 4-5 weeks of remote learning. In order to let students get familiar with distance learning, the use of the tool was integrated only from P2. In this way, students had P1 to get acquainted with the difficulties of distance learning, and could therefore better assess the usefulness of an awareness tool in general, and of an EAT in the specific case of this contribution.

During the on-site course of P2, students were informed that they would be asked to use the EAT as a corollary activity in the course. They were also informed that, beside the pedagogical interest of the activity, the use of the EAT was linked with my thesis and that data could be used for research. The distinction between the participation to the *compulsory* pedagogical activity and the voluntary participation to the research was clearly explained, and students were asked to read a consent form that was linked into the private work-space of the course. They then drew an ID from a urn, which they would use for any interaction with the EAT or with the surveys. With the ID, which was unique for each student, they also received a common code for each class.

#### Expectancy Survey

At this point, each student was asked to fill the *Expectancy* survey in order to collect their perception of the use of an EAT before actually using it. The survey was simply introduced by this description:

> An emotion awareness tool is a tool that allows to share one's own emotions with other people in a computer-mediated context. The tool has two main function: (1) it allows the user to express her own emotions and make them visible to the other users who are using the tool; and (2) it allows the user to perceive the emotions of the other users who have access to the same tool. You will have access to an emotion awareness tool for the two remote periods of the course, so that you can use it while you are working on STIC I: while you are reading the pedagogical material, you are coding the devices for your exercises, or you are contributing to the Wiki.

The questions of the EAU were the same as described in the material above, except that they were transformed in a prospective tense. For instance, *I think I will use this tool frequently* or *I think the tool will prompt me to share my emotions*. A scale from 1 to 10 allowed students to express their agreement which each dimension of the survey.

#### Demo Survey

Once filled the *Expectancy* survey, students were introduced to the EAT through a demo. They discovered the interface of the tool they will use throughout distance periods of the course, and they could directly test the functioning of the tool by expressing emotions, knowing those will not be recorded. The general functioning of the tool (i.e. the use of the appraisal dimensions and the choice of the subjective feeling) was explained. After 5 minutes of practicing with the tool, students took the *Demo* survey, which is exactly the same survey as the *Expectancy*, comprising the dimensions of the EAU in the prospective tense.

#### Set-Up the EAT for Distance Periods

Towards the end of the course, the set-up of the EAT for the actual use was organized. Since it was not possible to combine the EAT on the same interface with the various tools students use as part of the course, a generic web page was therefore the only flexible solution. Students saw how the window could be adapted and put beside another window (e.g. of a software or of another web page) in order to have the EAT close to the task at hand. To ease the access to the EAT, students created a bookmark in their browser that would automatically log them in with their unique ID and the code of the class.

Practically, then, students were supposed to open their browser, click on the bookmark pointing to the EAT, resize the window and place it beside the activity they were performing for the course. Or, alternatively, keep it minimized on their operating system task area and maximize it on recall. In both cases, the use of the EAT required a deliberate action outside the *normal* work-flow of the course.

#### Halfway Survey

During the on-site course of P3, students filled in the *Halfway* survey, after a whole period (i.e. 5 weeks) of use of the tool during remote learning. The survey comprised the EAU dimensions in retrospective tense (*e.g.*, *I have used the tool frequently* or *The tool has prompted me to share my emotions*), as well as an open-ended question in which students could provide additional information about their experience with the tool.

#### Final Survey

Students filled the *final* survey during the first on-site course of a follow-up course (STIC II) in the next semester, that is after 9 weeks from the *halfway* survey. The long period is the result of 5 weeks of *normal* remote learning, interrupted by 2 weeks of Christmas' leave in December (in which students often works, though), and 2 weeks of end-of-semester leave. The EAT was available until the formal end of semester. It has been decided to ask students to fill in the *Final* survey on-site, even with two weeks delay compared to the end of the semester, in order to maximize data collection. The *Final* survey comprised:

-   The EAU survey in retrospective tense (same as *Halfway* survey);
-   The System Usability Scale [@brookeSUSQuickDirty1996], but with a 7-point scale rather than the usual 5-point scale;
-   A survey asking participants to rate the frequency with which they have experienced the 20 subjective feelings belonging to the underlying affective space of the DEW;
-   A survey asking participants to rate the same feelings, but with respect to the frequency with which their colleagues have felt them during the remote periods;
-   An open-ended question in which students could provide additional information about their experience with the tool.

#### Reminders

Reminders to use the EAT during remote learning periods were dispatched twice per periods (P2 and P3) within messages in the private space of the course. The reminders were integrated into wider communications, for instance the feedback of an exercice.

#### Geneva Emotional Competence Questionnaire

In the private workspace of the course, students could find a link to the Geneva Emotional Competence (GECo, @schlegelGenevaEmotionalCompetence2018) test. The presence of the link was reminded at each on-site course, but students were clearly informed that the test was exclusively part of the research, so they were not forced to take it. Students could therefore take the test anytime during the P2 or P3 periods. Considering that there is no evidence yet that the use of an EAT in this context could improve the emotional competence of a person, especially in a performance-based test, this option left more time for students to take a long test during a very active period of learning. Students deciding to take the test had only to provide their anonymous ID in addition to the questions of the test.

### Exclusion Criteria

Having no previous reference for data collection, *a priori* exclusion criteria were difficult to formalize. Since there was the possibility of students dropping out either from the Master or from the research activity (e.g. refusing to fill-in the surveys), participants not having filled both the *Halfway* and the *Final* survey will be considered as if they dropped out and will thus be excluded from data analysis.

## Results

Results are based on $N = `r s2.participants_aggregated %>% nrow()`$ participants, having `r (s2.participants_aggregated_all %>% nrow()) - (s2.participants_aggregated %>% nrow())` students not filled both the *Halfway* and the *Final* survey, and were therefore excluded from the analysis considering they have dropped of the either from the course or the research. Table \@ref(tab:s2-descriptive-table) depicts the number of participants retained for each class across the 4 longitudinal surveys *Expectancy*, *Demo*, *Halfway* and *Final*, for which the two classes have very similar -- if not equal -- sample sizes.

(ref:s2-descriptive-table-caption) Number of participants retained for each class in total, and with respect to the 4 longitudinal surveys.

```{r s2-descriptive-table}
s2.valid_results_description %>% 
  kable(
    col.names = c(NULL, "Class 1", "Class 2"),
    booktabs = TRUE,
    digits = 2,
    caption = "(ref:s2-descriptive-table-caption)\\label{tab:s2-descriptive-table}",
    caption.short = "Study 2: Descriptive statistics",
    longtable = FALSE,
  )
```

### Expressing Emotions

Overall, participants expressed `r s2.participants_aggregated$num_emotions %>% sum()` emotions through the EAT, that is a mean of `r maf.print_m_sd(s2.participants_aggregated$num_emotions, TRUE, TRUE)`. One student in Class 1 and three students in Class 2 did not express any emotions at all. The fact that those students had not expressed emotions, though, does not systematically rule out the fact that they have not used the tool at all: potentially, they could have logged in just to see the emotions of others. Technically, the DEW-RT registers the log for every access, but students were not informed beforehand of this possibility. Thus, data about accesses has not been extracted -- and therefore not used -- and the 4 students are kept in the analysis.

In comparing the two classes, the number of emotions expressed is similar with respect to the central tendency ($M_{class1} = 11.47$ against $M_{class2} = 13.47$), but differs greatly in variation ($SD_{class1} = 21.69$ against $SD_{class2} = 11.79$). The greater SD of Class 1 results in particular by a single participant that expressed 86 emotions. In Class 2, the greatest number of emotions expressed is 34. Taking the median as a more robust reference of comparison, the difference between Class 1 ($Mdn = 3$) and Class 2 ($Mdn = 12$) is much more evident. Figure \@ref(fig:s2-graph-emotions-expressed-boxplot) compares the expression of emotions between the two classes.

(ref:s2-graph-emotions-expressed-boxplot-caption) Boxplot comparing the expression of emotions between the two classes.

```{r s2-graph-emotions-expressed-boxplot, fig.align="center", fig.width=4, fig.height=2.5, fig.cap="(ref:s2-graph-emotions-expressed-boxplot-caption)"}
s2.graph_expressed_emotions_boxplot
```

The use of the tool with respect to the longitudinal duration of the course is depicted in Figure \@ref(fig:s2-graph-expressed-emotions-over-time) The classes have similar profiles in the cumulative number of emotions expressed over time, alternating phases in which they express emotions with periods of pauses.

(ref:s2-graph-expressed-emotions-over-time-caption) Cumulative number of emotions expressed through the EAT

```{r s2-graph-expressed-emotions-over-time, fig.align='center', out.width="80%", fig.cap="(ref:s2-graph-expressed-emotions-over-time-caption)"}
s2.graph_expressed_emotions_over_time
```

Overall, it is safe to assume that Class 2 made a more thorough and homogeneous use of the EAT in expressing emotions compared to Class 1, even though the use in expressing emotions seems to be limited. It is nevertheless worth exploring whether the difference in expressing is also corroborated by differences in the perception of usefulness.

### Emotion Awareness Usefulness

Being the first adoption of the Emotion Awareness Usefulness (EAU) scale, it is worth beginning with some exploratory data analysis aiming at determining to what extent the self-reported rating over the 7 dimensions can contribute to assess (1) whether there is a change over time of the perceived EAU, and (2) whether the two classes differ in the perception of the EAU. In this regard, it is useful to start by evaluating the sensibility of the scale in terms of overall dispersion for each of the 7 underlying dimensions, namely *Frequency*, *Affordance*, *Social Presence*, *Self-Understanding*, *Understanding Others*, *Self-Other Comparison*, and *Self-Regulation*. In Figure \@ref(fig:s2-eda-dimensions-dispersion-graph) every circle represents one of the $N=`r s2.ea_usefulness %>% nrow()`$ ratings, which was made on a scale from 1 to 10, for each dimension across surveys and participants. The dispersion for each of the 7 dimensions spans over the entire range of the rating, suggesting that each dimension has a good sensibility.

(ref:s2-eda-dimensions-dispersion-graph-caption) Overall ratings of each of the 7 EAU dimensions, $N=`r s2.ea_usefulness %>% nrow()`$ ratings. Bars represent 95% confidence intervals around the overall mean.

```{r s2-eda-dimensions-dispersion-graph, fig.cap="(ref:s2-eda-dimensions-dispersion-graph-caption)", out.width="80%", fig.align='center'}
s2.eda.dimensions_dispersion
```

This preliminary assessment therefore corroborates the interest to investigate more specific patterns in the rating of each of the 7 dimensions with respect to the change over time and differences between classes. Table \@ref(tab:s2-description-EAU-stratified) depicts means and standard deviations of the 7 dimensions stratified for both classes across the 4 longitudinal surveys.

(ref:s2-description-EAU-stratified-caption) Means and (standard deviations) of the EAU ratings across longitudinal surveys.

```{r s2-description-EAU-stratified}
s2.ea_usefulness.descriptive_stratified %>%
  select(-dimension) %>% 
kable(
    booktabs = TRUE,
    digits = 2,
    caption = "(ref:s2-description-EAU-stratified-caption)\\label{tab:s2-description-EAU-stratified}",
    caption.short = "Study 2: EAU means and standard deviations",
    longtable = FALSE,
    linesep = c("", "", "\\addlinespace")
  ) %>% 
  kable_styling(
    latex_options = c("repeat_header")
  ) %>% 
  row_spec(c(3, 6, 9, 12, 15, 18, 21), bold = T) %>% 
  pack_rows(
    index = c(
      "Frequency" = 3, 
      "Affordance" = 3, 
      "Social Presence" = 3,
      "Self-Understanding" = 3,
      "Understanding Others" = 3,
      "Self-Other Comparison" = 3,
      "Self-Regulation" = 3
    )
  )

```

In order to assess the presence of effects in the above ratings, a linear mixed-model, also known as multilevel linear models [@finchMultilevelModelingUsing2019; @westLinearMixedModels2015] is fitted with the following components. The dependent variable is the singular value, from 1 to 10, expressed on each dimension of the EAU in the 4 surveys. The fixed covariates are (1) the longitudinal survey with 4 levels (*Expectancy*, *Demo*, *Halfway*, and *Final*); (2) the specific dimension of the EAU with 7 levels (*Frequency*, *Affordance*, *Social Presence*, *Self-Understanding*, *Understanding Others*, *Self-Other Comparison*, and *Self-Regulation*); and (3) the group each student belongs to with 2 conditions (*Class 1* or *Class 2*). All two-way interactions between pairwise covariates, as well as the three-way interaction, are also fitted in the model. The random covariates account for the nested structure of the observations: the repeated measure of the participant is nested inside the class to which the participant belongs.

The use of a linear-mixed model is warranted by a better flexibility compared to repeated-measure ANOVA, especially in case of missing data. Furthermore, linear-mixed models allow to account both for the repeated measures per participant and the nested structure of residuals, with participants potentially influenced by the use of the tool made by the colleagues in their class, which would violate the non-independence of residuals in ordinary least square regression. Finally, it allows to keep each dimension separate rather than averaging over a single score, which will loose an interesting source of variance with respect to the 7 dimensions of the EAU (see @finchMultilevelModelingUsing2019; @mcelreathStatisticalRethinkingBayesian2020; @singmannIntroductionMixedModels2020; @westLinearMixedModels2015 for a more comprehensive overview of linear mixed models compared to ordinary least square regression).

The linear mixed model analyzing the score on the EAU scale was fitted using the mixed function of the Afex [@singmannAfexAnalysisFactorial2020; @singmannIntroductionMixedModels2020] R package version `r packageVersion("afex")`. A Type III analysis of variance of the multilevel linear model detects effects for the longitudinal survey and the dimension of the EAU scale, but not for the group. Two-way interactions were detected between the group and the EAU dimension as well as between the EAU dimension and the longitudinal survey, but not between the group and the longitudinal survey. Finally, a the three-way interaction between group, longitudinal survey and EAU dimension was not detected. Results are depicted in Table \@ref(tab:s2-mlm-eau-table) using Kenward-Roger approximation for computing the *p*-value [@lukeEvaluatingSignificanceLinear2017].

(ref:s2-mlm-eau-caption) Results of a Type III ANOVA on the fitted multilevel linear model using Kenward-Roger approximation for computing the *p*-value

```{r s2-mlm-eau-table}
s2.mlm.ea_usefulness.anova_table %>%
  kable(
    booktabs = TRUE,
    longtable = FALSE,
    digits = 3,
    caption = "(ref:s2-mlm-eau-caption)\\label{tab:s2-mlm-eau-table}",
    caption.short = "Study 2: Emotion Awareness Multilevel Linear Model",
    linesep = c("", "",  "\\addlinespace")
  )
```

Results are graphically depicted in Figure \@ref(fig:s2-graph-dimensions-and-survey), in which the EAU evaluation is stratified by the 7 dimensions of the scale and the 4 longitudinal surveys, as well as grouped by the 2 classes. Data show high *Expectancy* ratings for the *Frequency*. *Affordance*, *Social Presence*, *Understanding Others*, and *Self-Other Comparison* dimensions, but not for *Self-Understanding* and *Self-Regulation*. The ratings are generally maintained even after the *Demo* surveys and tend to decrease with the actual use of the tool in the *Halfway* survey, to remain then more or less stable even in the *Final* survey. Data also show that the two classes basically overlap on all dimensions and across longitudinal surveys. The group per dimension interaction is probably yielded by the *Frequency* and *Affordance* dimensions, for which the two classes differ the most, but it does not seem to play an important role in differentiating EAU ratings. As a consequence, the factor related to the class is dropped in post-hoc contrasts, which will focus only on the difference between the *Final* and the *Expectancy* surveys.

(ref:s2-graph-dimensions-and-survey-caption) EAU rating over longitudinal surveys stratified by dimensions and grouped by class. Bars represents 95% confidence interval and the dashed gray line the median point of the scale.

```{r s2-graph-dimensions-and-survey, fig.align="center", fig.cap="(ref:s2-graph-dimensions-and-survey-caption)"}
s2.ea_usefulness.graph
```

Results of the post-hoc contrasts averaged over group and stratified across EAU dimensions are illustrated in Table \@ref(tab:s2-eau-contrasts-table). Contrasts detect differences between the *Final* and the *Expectancy* surveys in every dimension except the *Self-Understanding* one. All detectable differences highlight a decrease in perceived EAU, with the greatest decrease for *Self-Other Comparison* and *Social Presence* (almost 3 rating points decrease), followed by *Understanding Others* and *Affordance* (more than 2 rating points decrease), and finishing with *Frequency* and *Self-Regulation* (more than 1 rating point decrease).

(ref:s2-eau-contrasts-caption) Contrasts between the Final and the Expectancy surveys for each of the 7 dimensions of the EAU scale averaged over the two classes.

```{r s2-eau-contrasts-table}
s2.mlm.ea_usefulness.comparison %>% 
  as_tibble() %>%
  mutate(
    p.value = round_ps_apa(p.value)
  ) %>% 
  kable(
    digits = 3,
    caption = "(ref:s2-eau-contrasts-caption)\\label{tab:s2-eau-contrasts-table}",
    caption.short = "Study 2: Contrasts between Final and Expectancy surveys per EAU dimension",
    longtable = FALSE,
    booktabs = TRUE
  ) %>% 
  kable_styling(
    latex_options = c("repeat_header")
  )
```

### Perceived Usability of the EAT

$N = `r s2.sus_total %>% nrow()`$ participants filled the System Usability Scale (SUS) survey [@brookeSUSQuickDirty1996] at the end of the semester. The observed score has been of `r maf.print_m_sd(s2.sus_total$sus_score, TRUE, TRUE)`, which is considered *Good* according to the stratification proposed by Bangor, Kortum and Miller [-@bangorDeterminingWhatIndividual2009].

Figure \@ref(fig:s2-sus-items-graph) illustrates the score obtained on each of the 10 items of the SUS for the two classes. The score takes into account the reverse order for even items and is pondered on the 7-point scale used in the present study. As in the case of the EAU, ratings on the SUS are also consistent between classes. More specifically, data clearly show that the first item, inherent to the frequency of use, is far below the other items, which have received overall a high rating. Items 5 (integration of different functions of the system) and 9 (confidence in using the system) also have received lower ratings compared to the other items, even if not as low as the first item about frequency.

(ref:s2-sus-items-graph-caption) Rating of the individual items of the System Usability Scale (SUS) for N = 26 participants.

```{r s2-sus-items-graph, fig.align="center", fig.cap="(ref:s2-sus-items-graph-caption)"}
s2.sus_by_item.graph
```

A more detailed analysis on perceived usability is presented in the next chapter, which will compare the score with the usability test (Fritz, 2015). More accurate benchmarks will also be adopted to assess the individual items of the scale [@lewisItemBenchmarksSystem2018].

### Recollection of Individual and Collective Emotions

In the *Final* survey, that is approximately two weeks after the end of the semester -- and therefore the last day in which the EAT could be used by students during the STIC I course - participants were asked to recall the frequency with which (1) they have experienced the 20 subjective feelings of the underlying affective space as individuals, and (2) their class as a whole has experienced the same 20 subjective feelings. The sparse use in expressing emotions limits the interest in assessing whether there is a recollection of the individual and collective emotions shared with the EAT and is therefore reported here primarily to comply with the disclosure of all the measure collected. Figure \@ref(fig:s2-recollection-feelings-graph) compares three relative frequencies of the 20 subjective feelings of the underlying affective space adopted by the EAT. The first frequency is empirically retrieved using the relative frequency of expression of each subjective feelings compared to all the expressed feelings. The frequencies are mapped so that the most expressed feelings (e.g. *Attentive* and *Interested*) represent the upper bound, and correspond to the *Very often* frequency, whereas the least expressed feelings (e.g. *Surprised* and *Disgusted*) represent the lower bound, and correspond to the *Never* frequency. The second depicted frequency consists in how often participants recalled their colleagues have experienced the specific feelings. It is worth reminding at this purpose that from the interface of the EAT it was not possible to infer which specific colleague expressed a particular emotion, and therefore it was potentially possible to retrieve the frequency from the *word clouds* of the interface. Finally, the third frequency is the self-reported frequency by which participants experienced each subjective feeling themselves. The class and the self frequencies were collected by asking participants to rate the frequency on the same 5-point scale used in the graph (*i.e.*, from never to very often).

(ref:s2-recollection-feelings-graph) Comparison between the observed relative frequency of expressed feelings and the reported frequency recollected for the participants themselves, as well as the frequency attributed to the class as a whole.

```{r s2-recollection-feelings-graph, fig.align='center', fig.cap="(ref:s2-recollection-feelings-graph)"}
s2.perceived_emotions_frequency.graph
```

### Open-Ended Question

In the *Halfway* and *Final* surveys, participants had the possibilities to add general commentaries to the overall questionnaire, with a free text field corresponding to the overarching question *Would you like to add any remark or comment on the study as a whole?*. The open-ended question received 21 answers in the *Halfway* survey, and only 10 in the *Final* survey. Even though the overall approach to the study is nomothetic rather than idiographic, the fact that the tool's adoption has been sparse overall suggests that these questions could provide some useful reasons.

In this regard, most of the answers both in the *Halfway* and *Final* surveys point out that students forgot to use the tool, primarily because they were already overcome by the learning task. A few students, though, precised that the lack of use was also influenced by the presence of alternative communication channels used by the class, as it is clearly stated in this answer:

>At first, I forgot to use it and realized it late in the period. Afterwards, I didn't do it, because I use [the group's messaging platform] Slack to exchange and this tool is sufficient for me to manage my emotions. Using another tool would have generated an additional mobilization of resources and [would] therefore [have been] counterproductive for me. --- Verbatim of the answer, translated from original French.

Other students highlighted the fact that the moment-to-moment use of the tool interfered with their learning activity, diverting their attention. Even if they did manifest their emotion, those were rather prospective or retrospective. Furthermore, the sparse use of the tool even produced the very opposite effect it was intended to obtain, that is, increase social presence. As stated by a student:

>I used the tool and I like the concept but I only found myself online once with my other colleagues which actually made me feel quite alone in my sharing moments. This is the opposite of what I expected because I thought I would feel more connected to my colleagues and my emotions in the moment. --- Verbatim of the answer, translated from original French.

A few students nevertheless provide positive feedbacks about the presence of the tool, even if they regret the sparse use made of it by themselves or their colleagues. The feedback that more closely adheres to the tool overall purpose, though, provide an attentive analysis of its use in terms of the role the appraisal criteria played in its adoption:

>It was a great tool to use. I particularly appreciated to have this tool in order to force myself to analysis [sic] my emotions while working on [the course] topics. [I] [p]articularly appreciated the question about [the] capability to change the situation, which was a good opportunity to take a step back and understand what factors led to the situation and how I could influence them. It was also particularly interesting to be able to see the last emotional states and the most used. [I] [w]ould be happy to continue the survey in the future period. --- Verbatim of the answer, which was provided in English by the student

## Discussion



### (Not So) *Great Expectations*

Learners expectations towards the usefulness of the EAT may be considered the only result of the study, which is not influenced by the sparse use of the tool. As a reminder, in fact, participants were enrolled in a blended course organized over three periods of time. During the first period, students could experience asynchronous and individual learning settings without any particular support. When they filled the *Expectancy* survey, thus, they had a fresh, first-hand experience of the difficulties they faced during the remote period, from which they could project the perceived usefulness of emotional awareness.

In this regard, the overall expectations of both cohorts suggest a genuine need for a richer experience during remote learning, which is consistent with theoretical and practical efforts in the literature to improve socio-emotional support in distance learning [@brackettRULERTheoryDrivenSystemic2019; @jarvenojaRegulationEmotionsSocially2013; @kreijnsSocialAspectsCSCL2013; @lavoueEmotionAwarenessTools2020]. More specifically, learners manifested the highest expectations about the usefulness of an EAT for the *Understanding Others* ($M_{total}=6.93$), and *Self-Other Comparison* ($M_{total}=7.70$), that is, the two more socially-oriented dimensions. Conversely, for the two more self-oriented dimensions, *Self-Understanding* and *Self-Regulation*, expectations were only moderate to low ($M_{total}=4.57$ and $M_{total}=4.23$ respectively). The *Affordance* dimension was rated high ($M_{total}=6.57$), suggesting that the tool is expected to serve its function of prompting learners to share their emotions. Finally, the *Frequency* and *Social Presence* dimensions are more difficult to assess, since they are the two dimensions on which the two classes have a lesser convergence. Frequency of use is notoriously a user-experience dimension that is difficult to foresee: oftentimes it is overestimated, as it is the case here ($M_{total}=5.57$). Finally, the moderate expectations for *Social Presence* ($M_{total}=5.83$), compared with higher expectations for the more socially-oriented dimensions, may suggest that learners consider the EAT as a potential source of social reference rather than a way to perceive the presence of others. This is consistent with theoretical evidence suggesting that emotions in others can be a valuable source of information, especially in challenging situations [@jarvenojaRegulationEmotionsSocially2013; @vankleefHowEmotionsRegulate2009; @vankleefInterpersonalDynamicsEmotion2018].

Inter-dimensional comparison should nevertheless take into account the tentative nature of the EAU scale. Direct comparison between different dimensions, in fact, presupposes that all the seven constructs can be mapped into a similar space [@williamsLevelsMeasurementStatistical2021], which is an assumption that cannot be sustained without previous validation of the scale. Intra-individual change over time on the same dimension, though, is less concerned by the *absolute* measurement space of a construct, for it is determined by the relative shift in perception as the situation evolves [@fitzmauriceAppliedLongitudinalAnalysis2011]. 

In this regard, all the expectations were basically confirmed in the *Demo* survey, once participants had tested the concrete use of the EAT, suggesting that the specific features of the tool neither increased, nor decreased the expectations about its usefulness. This is both good and bad news. On the bright side, learners seem to trust the tool's ability to sustain their expectations. On the other hand, though, the tool failed to change participants' mind on the dimensions rated moderate to low, suggesting that they did not see in the tool additional interest, especially for interpreting, reflecting on, and experiencing their own emotional episodes [@boehnerHowEmotionMade2007]. 

### Limited Impact of Emotion Awareness

Even good expectations, though, did not stand the (longitudinal) test of time. Overall, the EAT has been adopted only by a handful of users throughout the course, with a mean of expressed emotions below 13. This mean is also inflated by a few participants expressing most of the emotions. The limited use of the EAT is corroborated by the Emotion Awareness Usefulness (EAU) ratings, for all dimensions decreased between the *Expectancy* and the *Final* survey, except for the *Self-Understanding* dimension, which was already quite low from the beginning. Participants seem particularly *deceived* by the EAT inability to foster comparison between their own emotions and that of their colleagues, as well as the inability to sustain a social presence, with both dimensions having a decrease of almost 3 rating points on the EAU scale. The incapacity to foster understanding of other emotion also attests a decrease of around two and a half rating points. The three dimensions happen to be the ones more socially-oriented. The accrued *deception*, though, may result simply by an overall floor effect of ratings at the end of the semester. In other words, participants were overall dissatisfied by the holistic experience, and, as a consequence, the dimensions who had the higher expectation ratings suffered more of the overall setback. 

The emotional information did not make any lasting impression on participants either, since self-reported recollection of subjective feelings' frequency of expression both on the individual and collective level was rated in a similar way, that is neutral on the scale from *Never* to *Very often*.

The answers to the open-ended questions proposed halfway and at the end of the semester mainly highlight that students forgot to use the tool, even when they have found it useful. On a superficial analysis, one may infer that the tool is not interesting enough, for it to be remembered. That is, the effort to recall its existence, open, and adopt it outweighs the benefit derived from using it. The course as a whole, though, is very demanding in terms of different environments, tools, and documentation to be consulted [@fritzPenseeComputationnelleAvec2019]. A few students did actually persist in using the tool throughout the remote learning periods, showing at least that the use was possible. 

### Consistency Between *Convenience* Classes

## Corollary Analysis

The chapter proposes two corollary type of analysis that may be of interest for future contributions. The first concerns the assessment of the Emotion Awareness Usefulness (EAU) scale in terms of its structure and reliability. The second explores a provisional link between emotional competence, using the scores obtained through the Geneva Emotional Competence (GECO) test.

### Structure and Reliability of the Emotion Usefulness Scale

Even though the use of multilevel linear model is more adequate for a fine grained assessment of the tentative scale, it is worth exploring whether the Emotion Usefulness scale (EAU) proposes structural features that may be of interest for future use. In this regard, the way the scale has been administered is somehow atypical. On the one hand, participants rated the scale on multiple occasion, which is consistent with the test/re-test paradigm. On the other hand, the conditions in which the scale has been administered where obviously not the same, since the aim of the contribution was to measure the change of perception over time rather then the consistency of the scale. For an exploratory purpose, it could be informative to relax some of the habitual boundaries in reliability measures and *pretend* that each administration of the survey was unique, even when the rater was the same. This choice is warranted by two elements. First, it increases the sample size of measures compared to taking just one of the four survey in which the scale has been administered. Second, if the repeated measure of the administration is taken into consideration, there will be essential overlapping with the multilevel analysis performed above. For these reasons, all $N = `r s2.ea_usefulness_scale.all %>% nrow()`$ administrations of the scale will be considered in the analysis.

Two types of analysis will be conducted to explore the structure and reliability of the EAU. First, it is worth assessing to what extent the scale can be considered as uni-dimensional, that is, measuring a single underlying latent variable, represented in this case by the perceived usefulness of disposing of emotional awareness. Second, it is also worth exploring whether there is an underlying structure of more than one factor.

#### Uni-Dimensionality

For determining the existence of a single, common factor, there is a growing consensus in considering -- despite its extensive use -- that Cronbach's $\alpha$ is not the most adequate choice [see for exemple @hayesUseOmegaRather2020; @revelleReliabilityTutorial2019; @sijtsmaUseMisuseVery2009]. In the R package psych [@revellePsychProceduresPsychological2021], used here in version `r packageVersion("psych")`, Revelle proposes an exploratory index of unidimensionality through the *unidim* function, described in the documentation of the package as follows:

> There are a variety of ways of assessing whether a set of items measures one latent trait. unidim is just one more way. If a one factor model holds in the data, then the factor analytic decomposition F implies that FF' should reproduce the correlations with communalities along the diagonal. In this case, the fit FF' should be identical to the correlation matrix minus the uniquenesses. unidim is just the ratio of these two estimates. The higher it is, the more the evidence for unidimensionality.

Results of fitting the *unidim* approach to the EAU yields a unidimensionality index of `r s2.eau.unidim$uni[1] %>% printnum()`, with a fit of the average correlation to the matrix of `r s2.eau.unidim$uni[2] %>% printnum()`, suggesting the presence of a unidimensional factor. As a comparison, the more traditional Cronbach's coefficient is also promising, with a raw $\alpha$ of `r s2.eau.unidim.alpha$total$raw_alpha %>% printnum()`.

#### Exploratory Factor Analysis

The exploratory factor analysis will be conducted in two steps using the psych R package [@revellePsychProceduresPsychological2021] version `r packageVersion("psych")`. First, a scree test is conducted to determine the number of factors that account for the greatest variance. Then, this number of factors is used in an exploratory factor analysis to retrieve the loading of the seven dimensions of the EAU on the suggested number of factors.

The scree test pictured in Figure \@ref(fig:sc-scree-plot-graph) suggests that three factors account for a fair amount of variance, with small gain achieved by adding a fourth or fifth one.

(ref:sc-scree-plot-caption) Scree plot based on all the EAU surveys administered. $N = `r s2.ea_usefulness_scale.all %>% nrow()`$

```{r sc-scree-plot-graph, fig.align="center", fig.cap="(ref:sc-scree-plot-caption)"}
scree(s2.ea_usefulness_scale.all, pc = FALSE)
```

An exploratory factor analysis with three factors, using the *minimum residuals* method of extraction with the *oblimin* rotation, result in the following loading of dimensions:

1.  The first factor comprises *Social Presence*, *Understanding Others*, and *Self-Other Comparison* dimensions, that is the more *partner(s)-oriented* dimensions.
2.  The second factor includes *Self-Understanding* and *Self-Regulation* dimensions, that is the more *self-centered* dimensions of emotional awareness. The second factor also relates to *Social Presence*, which also loads on the first factor, and *Frequency*, shared with the third factor, but both with a lower coefficient;
3.  The third factor represents *Frequency* and *Affordance* dimensions, that is the more *usability related* dimensions.

The diagram in Figure \@ref(fig:s2-factor-analysis-graph) reports the coefficients of loading. The overall reliability scores are Cronbach's $\alpha =$ `r s2.eau.fa$alpha %>% printnum()`, $\omega_{h}$ = `r s2.eau.fa$omega_h %>% printnum()`, and $\omega_{t}$ = `r s2.eau.fa$omega.tot %>% printnum()`, which suggest good reliability of the scale. Incomplete and tentative, the EAU seems nevertheless a rather promising scale that can be expanded in further research.

(ref:s2-factor-analysis-caption) Graphical representation of the exploratory factor analysis

```{r s2-factor-analysis-graph, fig.align="left", fig.cap="(ref:s2-factor-analysis-caption)"}
omega.diagram(s2.eau.fa, main = "", ,marg=c(5,0,0,0))
```

### Emotion Awareness Usefulness and Emotional Competence

The study also included the possibility to take the Geneva Emotion Competence (GECo) test [@schlegelGenevaEmotionalCompetence2018] anytime before the end of the semester. As a reminder, the GECo is a performance-based test measuring participants' emotional competence on four sub-competences: emotion recognition, emotion understanding, emotion regulation, and emotion management. Given the test was a corollary activity related only to the research -- and that the test is demanding in terms of time and effort due to its accuracy -- only $N = `r s2.geco_score_to_eau.wider %>% nrow()`$ participants performed it. This limits the possibility of exploring relationship between emotional competence and other indicators collected throughout the study beyond a descriptive perspective. In the meantime, participants that did take the test used their precious time during an intense phase of their education, which deserves gratitude and consideration.

Given the overall limited use that has been done of the EAT, the more interesting measure at hand to be related to emotional competence is the prospected usefulness measured in the *Expectancy* survey using the EAU scale. The unidimensionality coefficients exposed above suggest that the average score of the EAU can be, at least in the exploratory context, retained as an indicator of perceived usefulness of emotional awareness and therefore represent the measure of interest.

These are the premises to a multiple regression that has been fit using the average score to the EAU on the *Expectancy* survey as dependent variable, and the score to the four sub-competences of the GECo test as predictors. The aim is to explore to what extent the sub-competences are related to the expected usefulness of an EAT as support to distance learning. The parameters of the multiple regression are depicted in Table \@ref(tab:s2-ec-eau-lm-table), whereas the full model yielded the following results `r apa_print(s2.sub_competences_to_expectancy.lm)$full_result$modelfit`.

(ref:s2-ec-eau-lm-caption) Parameters of the multiple linear regression predicting expected EAU from the GECo emotional sub-comptences. $N = 11$.

```{r s2-ec-eau-lm-table}
apa_print(s2.sub_competences_to_expectancy.lm)$table %>% 
  kable(
    digits = 3,
    caption = "(ref:s2-eau-contrasts-caption)\\label{tab:s2-ec-eau-lm-table}",
    caption.short = "Study 2: Multiple Linear Regression: EC subcomptences predicting EAU",
    longtable = FALSE,
    booktabs = TRUE,
    escape = FALSE
  )
```

As one may expect from the small sample size at hand, there are no detectable effects in the model, with wide confidence intervals around all predictors. Emotion recognition, understanding and regulation have negative estimates, whereas emotion management has a positive estimate, with a lower bound of the confidence interval that is very close to the 0 threshold. These results must obviously be taken with much more than a grain of salt, but if they were to be extended in a similar way, the fact that emotion management is the sub-competence more related to the overall expectation of the usefulness of an EAT would be an interesting result. Emotion management is in fact the subcompetence more oriented towards interpersonal regulation of emotion, that is, modifying the emotional state of others [@reeckSocialRegulationEmotion2016; @zakiInterpersonalEmotionRegulation2013]. This phenomenon would therefore be more relevant in a synchronous and collaborative condition, in which there is more leverage in acting upon the emotional episodes of one's partner(s).

## Conclusion

The present observational and longitudinal study aimed at investigating the use and perception of usefulness of an EAT during the distance learning periods, starting from the assumption that the presence of the EAT may provide instrumental information on various dimensions that are considered as pivotal in remote computer-mediated learning environments. Furthermore, by implementing the EAT in two cohorts of the same course, the study also aimed at investigating whether differences between the two classes could be observed, in which case the use and perception of the EAT may depend by interacting dynamics between learners, rather than individual characteristics alone. Finally, as a corollary objective, the study also attempted at determining whether the adoption, use and perception of usefulness of the EAT may be linked to emotional competence as a performance-based construct. 

Overall, the study presents several drawbacks that limited its informative potential. At the same time, it also provided some promising elements, particularly in the material and type of analysis which may help future investigations about the subject at hand. The concluding remarks of this chapters first assess the main limitations of the study, and then resume the elements that may be deployed in future studies.


### Limitations

The study suffered from an unresolved ambiguity between a field study and a pedagogical intervention into an ongoing course. On the one hand, the field study objectives presupposed minimal intervention, letting learners free to adopt and use the tool in the way the saw fit. At the same time, from a pedagogical standpoint, one of the established shortcoming in the implementation of auxiliary technologies in the learning activity is that their presence alone does not guarantee neither the use, nor the effectiveness [@kreijnsIdentifyingPitfallsSocial2003]. The overall sparse use of the EAT, consistent between classes, has therefore diminished the informative potential of the whole study, which proved to be too ambitious in its *group-awareness* perspective. In fact, learners were bestowed with the whole process of reminding to use the tool, open it alongside the different learning activities necessary to comply with the course requirements, and extrapolate meaningful information from displaying their own emotions, as well as monitoring their emotions and that of their colleagues. As many learners have revealed in the free commentary, this was an excessive demand in a course where they already had to face new and complex learning environments or tools. 

A certain amount of *scripting* -- that is, pedagogical scaffolding of the learning activities [@millerScriptingAwarenessTools2015] -- seems therefore necessary. Learners should be more adequately supported in the use of the EAT, for instance with occasional reminder of its presence. Discussions about its use and the available information could also been integrated, for example in the form of focus-groups or experience sharing. These useful elements, though, would have been potential confounders in the comparison between the two classes, since they need external guidance, which is difficult to balance without any previous knowledge about what to expect. Maintaining an equal amount of intervention between the two classes would have been impossible in these conditions. With hindsight, the comparison between cohorts was therefore overly ambitious, for it requires a *laissez-faire* attitude, which is in contrast with learners needs of a more guided scenario and support. This is even more relevant considering the convenience sample of the study, that is, learners that by vocation and training are exposed to various learning technologies. The fact that even learners allegedly open to adopting new technologies made a sparse use of the EAT suggest that there is something flawed in the overall construction of the study.

### Elements to Retain For Future Studies



### Acknowledgments

I would like to thank professor Daniel K. Schneider for allowing the use of the EAT in two occasions during the STIC I course.
