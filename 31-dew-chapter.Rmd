---
bibliography: references.bib
---

# Previous Work on a Prototype: the Dynamic Emotion Wheel {#dew-chapter}

```{r dew-chapter-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)
source(here::here("./data/fritz2015/fritz2015_reanalysis.R"), local = knitr::knit_global(), encoding = "UTF-8")

```

This chapter resumes previous work on the subject of Emotion Awareness Tools that I have conducted in my Master thesis [@fritzReinventingWheelEmotional2015][^1]. The Master thesis was a *spin-off* of the Emotion Awareness Tool for Computer-Mediated Interactions (EATMINT) project and was first mainly focused on a user experience perspective, lacking therefore most of the theoretical background set forth in Part I. The Master thesis nevertheless lead to a conceptual prototype, which I named Dynamic Emotion Wheel (DEW), that was first presented at the International Society for Research on Emotion (ISRE) conference [@fritzDynamicEmotionWheel2015], and later in education technology conferences [@fritzDynamicEmotionWheel2016; @fritzRealTimeEmotionalAwareness2016]. The interest elicited in both affective sciences and education technology communities corroborated further conceptual and technical work on the prototype. The chapter starts by briefly outlining the aim and scope of the EATMINT project as the context through which a series of initial requirements for an EAT were set forth. Second, it illustrates the Geneva Emotion Wheel [@schererGRIDMeetsWheel2013; @schererWhatAreEmotions2005], a self-report tool based on the Component Process Model depicted in Section \@ref(cpm-section). The Geneva Emotion Wheel served as inspiration to produce the core principle of the Dynamic Emotion Wheel, illustrated in the third section of the chapter. Fourth, the chapter introduces an affective space adapted from previous work in the EATMINT project, which will also be adopted in the empirical contributions of Part III. Fifth, the results of a usability test conducted on the Dynamic Emotion Wheel in experimental settings are outlined as a preliminary assessment of the tool. Finally, the theoretical and technical extensions to pass from a prototype to a proof of concept are outlined.

## The EATMINT Project {#eatmint-project}

The Emotion Awareness Tool for Computer-Mediated Interactions (EATMINT) project was conducted as part of the National Center of Competence in Research (NCCR) *Affective Sciences* by a group of scholars integrating affective computing and affective sciences, computer science, education technology, education and learning sciences [@cereghettiSharingEmotionsComputermediated2015; @Chanel2013; @chanelGrandChallengeProblem2016; @molinariEmotionFeedbackComputermediated2013; @molinariFeedbackEmotionnelCollaboration2013]. When the project started in mid 2011, the topic of emotional awareness in computer-mediated collaboration was almost uncharted [@feidakisEndowingElearningSystems2011; @eligioEmotionUnderstandingPerformance2012]. The team therefore initiated the project to explore two intertwined objectives:

1.  Designing Emotion Awareness Tools, which allow either the explicit or the autonomic sharing of emotions in computer-mediated interaction;
2.  Studying the impact of emotional awareness on collaboration both at intra- and inter-personal levels, with respect to the emergence of strategies that improve collaboration such as monitoring, regulating and reflecting on emotions.

A first step in the project consisted in the set up of exploratory experiment, from which different types of data could be collected according to complementary research perspectives. First, to what extent emotional awareness influences perceived emotions after collaboration and the perceived quality of interaction [@molinariEmotionFeedbackComputermediated2013]. This part of the study has been thoroughly illustrated in the related works of Section \@ref(ea-inter-personal) about the inter-personal function of emotional awareness. Second, to what extent the perceived interaction during a collaborative task is linked to users' emotional traits, and how an emotional awareness tool can influence this relationship [@molinariFeedbackEmotionnelCollaboration2013]. Third, to what extent physiological and eye-movement coupling predict situations that may benefit from emotional awareness information during the collaborative process [@Chanel2013].

The experimental setup was the same already described in Section \@ref(ea-in-computer-mediated-environment) about emotion in computer-mediated learning environments. In this regard, the EATMINT project members reckoned that the EAT used in pilot experiments -- already depicted in Figure \@ref(fig:tf-eatmint-eat) and repeated hereafter in Figure \@ref(fig:tf-eatmint-eat-repeated) -- showed some limitations, and therefore planned to implement a second version of the tool to be used in future studies. I was involved in this process first as an internship in the project, and later as the subject of my Master thesis [@fritzReinventingWheelEmotional2015]. This section starts with a more comprhensive description of the tool. Then, it illustrates a series of requirements for the next version of the EAT, which were discussed with the EATMINT project's team. Finally, it gives a brief overview of the interaction design method which was applied to find a solution meeting these requirements.

### Description of the EATMINT's First Version of an EAT

The tool in the pilot studies of the EATMINT project was persistenly located at the right edge of the screen, occupying the whole height and about a fifth of the width. The tool was vertically divided in two areas of almost the same size.

(ref:tf-eatmint-eat-repeated-caption) The argument graphic tool and the EAT adopted in @molinariEmotionFeedbackComputermediated2013, from Figure 1 in the original article (repeated from Figure \@ref(fig:tf-eatmint-eat)).

```{r tf-eatmint-eat-repeated, fig.align="center", fig.cap="(ref:tf-eatmint-eat-repeated-caption)", out.width="80%"}
knitr::include_graphics(here("figure/theory/eatmint-eat-and-task.png"))
```

The lower part of the tool was dedicated to the expressing-displaying function of an awareness tool. Users could encode their emotional experience by pressing one of 20 buttons, each labelled with a lexicalized emotion in the form of an adjective (e.g. *attentive*, *irritated*, *relaxed*, etc.). The list of discrete emotions was defined by combining a previous study about affective dynamics during complex learning [@dmelloDynamicsAffectiveStates2012] and two pilot studies that aimed at identifying the most frequent and intense emotions felt during a situation of collaboration, real or imagined. The 20 discrete emotions were equally divided in *positive* and *negative* labelled groups, available side by side, but did not follow any particular order within each list (see Table \@ref(tab:eatmint-original-emotions-table)). At the bottom-end of the screen, a "no-emotion" button spanning across the two columns was also available.

(ref:original-list-eatmint-emotions-caption) List of the 20 emotion adjectives used as buttons in the EAT. Our translation from the original French word in parentheses is based on a document by the @genevaemotionresearchgroupAppendixLabelsDescribing1988. The order in the table reflects the order of the buttons in the interface.

```{r eatmint-original-emotions-table}
eatmint_original_emotion_list <- tribble(
  ~"",   ~"Positive emotions",    ~"Negative emotions",
  1,        "Delighted (Ravi)",      "Stressed (Stréssé)",
  2,        "Attentive (Concentré)",  "Annoyed (Enervé)",
  3,        "Interested (Intéressé)", "Surprised (Surpris)",
  4,        "Satisfied (Satisfait)",  "Irritated (Irrité)",
  5,        "Empathetic (Empathique)", "Envious (Envieux)",
  6,        "Confident (Confiant)",    "Anxious (Anxieux)",
  7,        "Amused (Amusé)",          "Disappointed (Insatisfait)",
  8,        "Relaxed (Détendu)",      "Confused (Confus)",
  9,        "Grateful (Reconnaissant)", "Frustrated (Frustré)",
  10,       "Relieved (Soulagé)",     "Bored (Lassé)"
)

eatmint_original_emotion_list |> 
  kable(
    caption = "(ref:original-list-eatmint-emotions-caption)\\label{tab:eatmint-original-emotions-table}",
    caption.short = "Original list of EATMINT emotions",
    longtable = FALSE,
    booktabs = TRUE
  )

```

The upper side of the tool was primarily concerned with the perceiving-monitoring function of an awareness tool. Participants could in fact see the last three emotions they had expressed and the last three emotions manifested by the partner. Their own emotions appeared in the upper side as a vertical list of text-centered cases with a green background. The very last emotion had a lighter background and resulted on top of the list. This case also served as a text input where participants could type an emotion not in the list, having thus also an expressing-displaying function. Their partner's emotions appeared just below, in exactly the same way, except for a blue background and the first light-blue case that was not editable.

As a result, each participant could voluntarily express their emotional experience in one of three ways: (1) by clicking one of the 20 emotion labelled buttons; (2) by typing an emotion not in the list directly in the first light-green case; or (3) by clicking the "no-emotion" button at the bottom-end of the screen. The expressed emotion would then appear in the upper light-green case of the participant's own screen, and, respectively, in the upper light-blue case of the partner's screen.

### Requirements for a Second Version of an EAT {#eatmint-requirements}

Following the analysis of the experiment from the team and the feedback provided by participants -- who found, for instance, the custom disposition of the discrete emotions labels not helping -- a requirement analysis was conducted with the members of the EATMINT project. At first, the requirements were set forth from a general, brainstorming perspective and it was the aim of the internship to try to put them together in a coherent interface. The requirements analysis identified five main characteristics of the tool.

First, it should keep the voluntary self-report approach. Even though the project's aim contemplated both autonomic and voluntary tools, this specific EAT was intended to follow-up on the voluntary disclosure of the emotional experience.

Second, the tool should be inspired by an emotion theory. One potential theory that was considered in this regard was Pekrun's Control-Value theory of achievement emotions [@pekrunControlValueTheoryAchievement2006; @pekrunControlValueTheoryAchievement2014], already cited in Sections \@ref(learning-on-affect) and \@ref(appraisal-theories). Given that the theory is deeply rooted in the appraisal family, it was also suggested that the tool should integrate a dimensional approach representing the Control and Value appraisals rather than relying exclusively on discrete emotions.

Third, an additional reason to switch to a dimensional approach concerned the reduction of the number of discrete emotions on screen, which was perceived as a source of cognitive overload from participants. The sheer number of discrete labels available, combined with the lack of a specific order, forced participants to perform a seek-and-evaluate task [@rouetRechercheInformationsDans1995] every time they had to click on a proposed label.

Fourth, the presence of 20 buttons on the interface also reduced the space available for the perceiving-monitoring function of an awareness tool. Only the last three emotions for each participant appeared on the interface without any further information such as the time when they occurred or in which order they appeared considering the dyad as a whole. In other words, it was possible to establish in which order each participant had expressed their last emotions, but not if the very last emotion of the dyad belonged to the first or second participant. It was also impossible to tell, from the interface alone, if the order of the emotion followed a one-each turn, or a participant expressed three emotions in a row. Consequently, for the new version of the tool, the EATMINT project members wanted to enhance the possibility for participants to (1) dispose of the evolution of their own emotional state during time, and (2) compare this evolution with their partner's one.

A last requirement, of a more general scope, concerned the flexibility of the tool with respect both to theoretical and technical features. On the theoretical level, the new version of the tool should provide experiments with as much leverage as possible about the underlying theoretical framework, for example the number and labels of the emotions. On the technical level, the interface of the tool could also be considered as a potential factor in the experimental settings. For example, a group of participants could dispose of an interface that particularly highlights inter-personal comparison, whereas the other group an interface that provides more insight on the intra-personal evolution over time. Finally, the tool should also provide a way to set up emotional awareness in experimental settings without specific technical knowledge, and dispose in the meantime of collected data in a practical form for exportation and subsequent analysis.

### Interaction Design Process

The establishment of requirements was the first step in the interaction design method [@cooperFaceEssentialInteraction2007; @rogersInterctionDesignHumanComputer2011], which is driven by the underlying assumption to take the end-user perspective from the very onset of the process. The other steps advocated by this iterative method are: the design of alternatives, often based on an analysis of existing and concurrent products; building prototypes at various levels of fidelity; and finally evaluating to what extent the prototype meets users' functional needs and perceptual preferences. The full process that eventually lead to the Dynamic Emotion Wheel is thoroughly depicted in my Master thesis [@fritzReinventingWheelEmotional2015]. Hereafter, only the most important steps in the process are illustrated, starting from the identification of the closest existing product that presented some of the features aimed by the new version of the EAT.

## The Geneva Emotion Wheel {#gew}

The Geneva Emotion Wheel (GEW) is an emotion self-report tool based upon the Component Process Model (CPM) theoretical framework illustrated in Section \@ref(cpm-section). At the time of writing, the tool is in its third version, having received modifications over the years [@schererWhatAreEmotions2005; @schererGRIDMeetsWheel2013; @shumanConceptsStructuresEmotions2014]. This section starts with a description of the tool and how it relates to the CPM. It then illustrates an empirical use of the tool, which resonates with emotional awareness. Finally, it assesses the limitations of the tool with respect to the features retained as a central tenet for the implementation of an EAT in the current contribution.

### Description of the Geneva Emotion Wheel

The GEW was initially created under the assumption that "it might be worth investing in the development of an instrument capable of combining the advantages of the precise differentiation provided by natural language labels with the simple organizational structure afforded by a two-dimensional space" [@schererGRIDMeetsWheel2013, p. 283], see also Section \@ref(ea-in-computer-mediated-environment). The assumption also posits that being emotion determined by the cognitive evaluation of the situation described in Section \@ref(cpm-appraisal-module), the two-dimensional space of the GEW should be determined by appraisal dimensions. In the meantime, the discrete emotions -- represented by lexicalized emotions as manifestations of the subjective feeling illustrated in Section \@ref(subjective-feeling) -- should be arranged according to the affective space that emerges from the combination of the two underlying dimensions [@schererWhatDeterminesFeeling2006; @schererWhatAreEmotions2005; @schererGRIDMeetsWheel2013]. The GEW, depicted in its third version in Figure \@ref(fig:gew-version-3-figure) [@schererGRIDMeetsWheel2013], thus, places 20 lexicalized emotions in the form of natural language words around a circumplex determined by the Valence dimension on the horizontal axis, and the Control/Power dimension on the vertical axis.

The choice of the two dimensions is warranted by the fact that there is a clear correspondence between the two dimensions and the sequential evaluation checks of the CPM (see Table \@ref(tab:tf-cpm-secs). The widely adopted dimension of Valence corresponds to the stimulus evaluation checks pertaining to the *Relevance* and *Implications/Consequences* groups, namely intrinsic pleasantness and goal conduciveness. The same applies to the stimulus evaluation check of the *Coping potential* group, which can be related to the dimension of Control/Power, often adopted in dimensional approaches [@osgoodNatureMeasurementMeaning1952; @broekensAffectButtonMethodReliable2013; @bradleyMeasuringEmotionSelfAssessment1994]. Previous studies on appraisals criteria have also confirmed that the two appraisal groups are also the ones that contribute the most to emotion differentiation [@schererGRIDMeetsWheel2013], even if they are not enough, as previously mentioned, to account for all the variation [@gilliozMappingEmotionTerms2016; @fontaineWorldEmotionsNot2007]. It is also worth noting that the authors discarded the most commonly adopted dimension of Arousal/Activation [@russellCircumplexModelAffect1980; @feidakisEndowingElearningSystems2011; @feidakisReviewEmotionAwareSystems2016; @brackettRULERTheoryDrivenSystemic2019] for it makes difficult to distinguish between the intensity of the subjective feeling from the intensity of the bodily excitation [@schererGRIDMeetsWheel2013]. Furthermore, the authors also point out that:

> while most lay persons have little problem evaluating the positivity or negativity of a feeling (or event) and the approximate degree of their felt arousal, the resulting point in two-dimensional space has no specific meaning for them and cannot be communicated to others. It would seem very strange to tell someone that I feel 2.3 positive and 1.6 aroused.\
> --- @schererGRIDMeetsWheel2013, p. 283

The 20 lexicalized emotions are thus positioned according to a value along the Valence and the Control/Power dimensions. As a consequence, each discrete emotion belongs to one of the four quadrants of the circumplex, determined by the combination of positive or negative Valence, and positive or negative Control/Power. The discrete emotions labels of version 3.0 are in clockwise order: *interest*, *amusement*, *pride*, *joy* and *pleasure* for the positive Valence and high/positive Control/Power quadrant; *contentment*, *admiration*, *love*, *relief* and *compassion* for the positive Valence and low/negative Control/Power quadrant; *sadness*, *guilt*, *regret*, *shame* and *disappointment* for the negative Valence and low/negative Control/Power quadrant; and *fear*, *disgust*, *contempt*, *hate*, and *anger* for the negative Valence and high/positive Control/Power quadrant.

Furthermore, from the origin of the axes stem 5 circles for each of the lexicalized emotions. The circles grow in size as they get closer to the edge of the circumplex, so that the first circle is the smallest, and the last one the biggest. Participants can therefore choose, first, the *row* of circles that corresponds to the subjective feeling they are experiencing and, second, the intensity of the emotion as a function of the circle's size. At the same time, respondents are also provided with the "None" and "Other" options available in the center of the circumplex, which is considered a good practice in emotion self-report [@mortillaroEmotionsMethodsAssessment2015].

(ref:gew-version-3-caption) The third version of the Geneva Emotion Wheel [@schererGRIDMeetsWheel2013]

```{r gew-version-3-figure, fig.cap="(ref:gew-version-3-caption)", fig.align="center", out.width="100%" }
include_graphics(here("figure/dew/gew-v3.png"))
```

It is worth noting that, whereas the two dimensions have been constant over the evolution of the tool, the number and labels of the lexicalized emotions have been modified with each of the three versions of the tool, even though the aim has been consistently to provide users with intuitive, widely adopted natural language words representative of major emotion families (i.e. modal emotions). In fact, the positioning of the discrete emotions proved to be particularly difficult. If the position of the lexicalized emotions for version 1.0 and 2.0 was empirically validated for most of them on the Valence dimension, the same was not true for the Control/Power dimension [@sacharinGenevaEmotionWheel2012]. This aspect will be further developed in Section \@ref(gew-limitations). For this descriptive passage, it is worth mentioning that the disposition of the 20 lexicalized emotion of the third version of the GEW has been determined using the GRID instrument mentioned in Section \@ref(subjective-feeling). The authors who have been working on the third version of the GEW also suggest that a custom choice of lexicalized emotions is possible, but should ideally be determined by the GRID instrument. In this regard, the MiniGRID or the CoreGRID [@schererCoreGRIDMiniGRIDDevelopment2013], which are shorter version of the GRID, can be adopted to limit the number of ratings needed to determine the position of each lexicalized emotion.

To sum up, the design of the GEW provides different interesting features from the point of view of an EAT. First, it implements an emotion structure in a self-report tool by combining appraisal dimensions and subjective feelings into a theoretically and empirically driven underlying structure. Second, the subjective feeling is represented by lexicalized emotions that are meant to be widely accessible in the emotional vocabulary due to their frequency in everyday language. Third, it allows the assessment not only of the kind of emotional experience, but also its intensity through the size of the circles. Fourth, the whole is *packed* into a user-friendly interface that can be immediately understood by respondents and produce reliable emotion self-report [@caicedoHowYouFeel2006].

### The Geneva Emotion Wheel as Emotional Awareness Tool

The GEW has been adopted in a wide variety of empirical contributions ranging from consumer attitudes towards a product to the use of the tool from an experience sample method perspective [@schererGRIDMeetsWheel2013]. Even though the primary aim of the GEW is the accuracy in individual self-report of the subjective emotional experience, there has also been attempts to use it at the inter-personal level.

In particular, @tranEmotionsDecisionMakingProcesses2012 adopted the GEW -- in what seems version 1.0, which is probably why the version is unspecified in the article -- to investigate the role of emotions in decision-making at the collective level in management teams. Participants formed groups of 4 to 7 to simulate the collective conduction of a company during fictitious long-term periods of 8 years, represented by *stints* of three hours in the study. Participants expressed on the GEW, using a pencil and paper version of the tool, two emotions at the beginning, at the mid-point, and at the end of each period for a total of 6 emotions. The emotions appeared on the same sheet, and each emotion was identified by a code composed by the letters B (beginning), M (middle) or E (end), as well as a sequential number from 1 to 6. The code of the emotion was placed in one of the circles of the interface representing the subjective feeling and its intensity. The individual rating of the emotional experience was then discussed with the other members of the team, who negotiated to define the two emotions the team perceived as prevailing during the decision process and reported them as *consensus emotions* on another sheet with the GEW. This fact created the conditions for emotional awareness to emerge in the teams. Among the practical implications of the study, in fact, the authors highlight what follows.

> Over the course of this study, it could be observed that participants often used the Emotion Wheel as a medium to discuss their emotions freely with their colleagues and it became part of the norms of the teams to do so. Thus, discussing emotions yields self-awareness and awareness at the group level when, for example, participants discuss their group consensus emotion. In addition, by mapping emotions on the Emotion Wheel on a regular basis, everyone can see the evolution of the emotional climate and team members can proactively manage it.\
> --- @tranEmotionsDecisionMakingProcesses2012, p. 22

Having their emotions expressed on the underlying structure represented by appraisal dimensions, in fact, allowed participants to notice not only the switch from a discrete emotion to another, but also the switch from a position in the circumplex to another, for instance a change from a quadrant to another. To sum up, the implementation of a theoretically driven emotion structure facilitated the emergence of emotional awareness, with the consistency and familiarity of the structure becoming a pivotal element in the consideration of emotions within the task at hand. This empirically corroborates the potential usefulness in implementing an emotion structure into an EAT.

### Limitations and Missing Features in the Geneva Emotion Wheel {#gew-limitations}

Notwithstanding the many features of the GEW that corroborate the intrinsic quality as a self-report instrument, as well as the possibility to adopt it in circumstances linked to emotional awareness, the tool presents a number of limitations and missing features, particularly from the point of view of an EAT with the characteristics sought after in the present contribution. Most of them are from a technical or user-experience perspective. Others, though, are grounded more at a conceptual level that interacts also with the theoretical underpinning of the tool. These are headed first, leaving more practical considerations as a follow-up.

As mentioned in the description of the GEW, the two underlying dimensions from which the emotional structure is denoted are Valence and Control/Power. In an attempt to empirically validate the disposition of the three versions, the Control/Power dimension was particularly hard to match [@schererGRIDMeetsWheel2013; @sacharinGenevaEmotionWheel2012; @schererSemanticStructureEmotion2018]. The problem was particularly exacerbated when the disposition of the lexicalized emotion was determined through direct rating on the two dimensions. In one case, for instance, the Valence dimension was depicted as "the situation is experienced as (un)pleasant and enjoyable (disagreeable) and/or is likely to have positive and desired (negative and undesired) consequences for the person". Control/Power was in turn stated as "the person believes that he/she can (cannot) influence the situation to maintain or improve it (if desired)" [@sacharinGenevaEmotionWheel2012]. Results highlighted a substantial overlapping, or correlation, between the Valence and the Control/Power dimensions, especially with the top-right (negative Valence and high/positive Control/Power) and bottom-left (positive Valence and low/negative Control/Power) quadrants. As a consequence, the perception of the two dimensions is not orthogonal as the underlying structure may imply. Another problem was also encountered with the GRID instrument, though, for the features related to the Control/Power dimension did not yield the theoretical importance associated with the Coping potential in emotion elicitation and differentiation [@schererSemanticStructureEmotion2018].

Two main reasons are posited for these difficulties [@schererGRIDMeetsWheel2013; @sacharinGenevaEmotionWheel2012; @schererSemanticStructureEmotion2018]. First, the notion of *Control* may be too abstract for non-psychologists. As a result, even the sheer way by which the dimension is instantiated through wording may be misleading. It may thus be a matter of trial and error before a viable description is found in order to align the theoretical and the perceived character of the dimension. To this extent, the CoreGRID already modified some wording in the rating of related features [@schererCoreGRIDMiniGRIDDevelopment2013]. Second, the Control/Power dimension may be intrinsically *valenced* [@shumanLevelsValence2013]. Situations with low control are perceived as generally unpleasant, whereas situations with high control are perceived as pleasant. As summarized by Scherer and Fontaine:

> It is exceedingly difficult to construct items that allow one to obtain valid assessments of control/power/coping appraisals, partly because of the strong relationship to valence (it is good to have high power).\
> --- @schererSemanticStructureEmotion2018, p. 9

Another limitation linked to the underlying appraisal dimensions is that, in the GEW, these dimensions are not manifest. The problem with the Control/Power dimension surfaces only from a retro-engineering mechanism, but on the tool itself, there is no explicit mention of neither Valence nor Control/Power. The two appraisal dimensions are used to organize the lexicalized emotion, but there is no explicit guarantee that a person choosing *shame* (bottom-left quadrant) is *aware* of having evaluated the situation as unpleasant and with little coping potential -- that is, unless the respondent is informed beforehand of the semantic value of the interface. Without this kind of training, even the emotional awareness role played by the GEW in @tranEmotionsDecisionMakingProcesses2012 may be reassessed. According to more thorough information about the procedure available in @tranInfluenceEmotionsDecisionmaking2004, participants received definitions of the emotions on the GEW taken from a dictionary. As a consequence, there was probably some information about Valence-like features, but less likely about an underlying theoretical construct such as Control/Power. When tracing the evolution of the emotional experience between the quadrants, participants may have not been completely aware of the *dimensional* leaps undertaken, if not by the inference that adjacent emotions on the interface were more akin than those afar.

From a more practical standpoint, the GEW is also doomed to occupy a considerable share of a screen, as it is the case for the *emot-control* [@feidakisProvidingEmotionAwareness2014; @feidakis2013] tool illustrated in the related works of Section \@ref(ea-in-computer-mediated-environment). The strength of this kind of interfaces is to provide an organized structure to the discrete emotions, for respondents to dispose at the same time of all the available options. As a consequence, this design is not very responsive to scale in proportion to the number of available options. A greater number of discrete emotions would shrink the interface to the point of overlapping boundaries, especially of the circles to rate the intensity. A lower number of options, without resizing the whole interface, would tear options far apart, injecting negative space in between, which would be of limited visuo-spatial use [@hegartyCognitiveScienceVisualspatial2011].

Another shortcoming of the GEW is its potential to fulfill the perceiving-monitoring function of an awareness tool. The size of the interface leaves little space to provide a dedicated space for contemplating the emotion expressed through the tool, especially from a longitudinal perspective. As in @tranEmotionsDecisionMakingProcesses2012, it would be possible to mark directly on the circles the expressed emotions with some form of sequential encoding to emulate time, but this mechanism may easily overcrowd the interface after a few responses. One may duplicate the interface, for instance leaving the upper GEW for expressing-displaying, and the bottom GEW for perceiving-monitoring; but the tool would in this case occupy twice the already considerable size of one GEW alone.

To sum up, The Geneva Emotion Wheel presents a number of theoretical and empirically validated features that are appealing even for an EAT. First, it is based on self-report, which entails the conscious, conceptual effort to investigate one's own emotional experience. Second, this introspection is guided by the implementation of an emotion structure combining appraisal dimensions and the subjective feeling in the form of a lexicalized emotion. Third, the structure also forms an affective space, which can be adapted by using appropriate steps in validating the characteristics of an alternative space. At the same time, the tool also presents some technical shortcomings and missing features that limit the possibility to be adopted *as-is* to perform both the expressing-displaying and the perceiving-monitoring function of an EAT. As a consequence, it was considered worth investigating the development of a new tool.

## The Dynamic Emotion Wheel

The Dynamic Emotion Wheel (DEW) was originally conceived as a web-based application aiming at meeting the EATMINT project's requirements outlined in Section \@ref(requirements-for-a-second-version-of-an-eat). It was therefore primarily driven by an inter-personal perspective about emotional awareness consistent with the EATMINT interest in computer-mediated collaboration [@fritzDynamicEmotionWheel2015; @fritzDynamicEmotionWheel2016; @fritzProvidingEmotionalAwareness2017; @fritzRealTimeEmotionalAwareness2016; @fritzReinventingWheelEmotional2015]. As the name implies, the tool is deeply inspired by the Geneva Emotion Wheel [@schererWhatAreEmotions2005; @schererGRIDMeetsWheel2013; @shumanConceptsStructuresEmotions2014] described previously. This section starts by laying out the core principle of the DEW -- consisting in the *dynamic* element of the acronym -- which represents the main conceptual and usability difference with the Geneva Emotion Wheel. Second, it describes how this core principle determine the whole interface of the tool. Next, it illustrates how the principle can be adapted to a different affective space by introducing the EATMINT circumplex [@fritzProvidingEmotionalAwareness2017]. The sections ends with the results of a usability test conducted in experimental conditions as the last step of a first iterative process in the interaction design method adopted to create and later incrementally improve the tool [@fritzReinventingWheelEmotional2015].

### The Core Principle of the Dynamic Emotion Wheel {#dew-core-principle}

The core principle of the DEW is rather straightforward: in a self-report condition, emotional awareness is determined by how the *encoding* of emotion is prompted. Everything follows from and depend on this process. As a consequence, the mechanism by which emotion is encoded should adhere as much as possible to the mechanism by which emotion is elicited, differentiated and symbolically represented in oneself and in communicating with others. This principle is implemented by the DEW with three sequential and coordinated steps, illustrated graphically by the low-fidelity wireframe in Figure \@ref(fig:dew-core-wireframe).

(ref:dew-core-wireframe-caption) Wireframe sketching the core principle of the Dynamic Emotion Wheel in three sequential and coordinated steps.

```{r dew-core-wireframe, fig.align="center", fig.cap="(ref:dew-core-wireframe-caption)", out.width="60%"}
knitr::include_graphics(here::here("./figure/dew/dew-core-principle-subset.png"))
```

The first two steps are the same type of action and are driven by the following assumption: rather than using appraisal dimensions to organize the lexicalized emotions as in the Geneva Emotion Wheel, the very same appraisal dimensions are used as active rating inputs. If how a person evaluates the situation on appraisal criteria is the determinant of elicitation and differentiation of the emotional response, than it is in both the intra-personal and inter-personal best interests that the cognitive evaluation of an event is explicitly manifested through the tool. Obviously, being a self-report measure, the ratings on the appraisal dimensions are only a proxy of the *true* profile of the sequential evaluation checks. It also means that, referring to the CPM's four levels of processing (sensori-motor, schematic, association, and conceptuel), the appraisal is performed at the conceptual level, the one which requires consciousness of the underlying evaluation and effort-full calculation in the pre-frontal cortex [@schererNatureDynamicsRelevance2013], see also Section \@ref(cpm-appraisal-module).

The first step consists thus in evaluating the Valence dimension, which spans over the *Relevance* and *Implications/Consequences* appraisal groups, particularly with respect to the intrinsic pleasantness and goal conduciveness sequential evaluation checks. As stated above and throughout the theoretical Part I, Valence is a widely adopted dimension in many theories of emotion, and roughly defines whether a situation is pleasant or unpleasant, even though many forms of Valence exist [@shumanLevelsValence2013; @erbasRoleValenceFocus2015]. The CPM more specifically identifies the intrinsic pleasantness sequential evaluation check as pleasure vs. pain detector, whereas the goal conduciveness check relates more thoroughly to whether the event hinders or facilitate the attainment of the agent objectives [@schererWhatAreEmotions2005; @schererDynamicArchitectureEmotion2009].

The second steps consists in evaluating the Control/Power dimension, which is a proxy for the CPM's *Coping potential* appraisal group. The coping potential has been a pivotal concept from the very onset of appraisal theories [@lazarusPsychologicalStressCoping1966; @smithPatternsCognitiveAppraisal1985]. It roughly refers to the extent by which the person can deal with a particular situation [@schererWhatAreEmotions2005; @schererDynamicArchitectureEmotion2009]. The CPM more specifically breaks down the *Coping potential* group in three sequential evaluation checks: (1) the *control check* dictates whether the agent can be a principal actor in determining events; (2) the *power check* quantifies the effort needed to modify the course of events if the previous check gave a positive outcome; and (3) the *adjustment capacity check* relates to the agent's capacity to accept the consequences of the event, for instance if its control and power are limited (*ibid.*).

The Valence dimension is rated before the Control/Power dimension as a means to mimic the unfolding process determined by the sequential evaluation checks of the CPM. As a reminder, the CPM posits that the sequential process is obtained by first ranked appraisals to reach preliminary closure before that information is conveyed to subsequent checks. In this regard, appraisals belonging to the *Relevance* and *Implication/Consequences* groups (coalescing into Valence) are evaluated before checks in the *Coping potential* group (representing Control/Power). So, even though the respondent is self-reporting a process that has already taken place, it could be useful to maintain the appropriate order as a means to enhance self-reflection on how the emotional episode was enacted.

The third step concerns the subjective feeling and consists in choosing a lexicalized emotion that best represents the whole emotional process. This is where the *dynamic* happens. Once the cognitive evaluation of the situation has been rated, the DEW builds on the probabilistic link between appraisal dimensions and the subjective feeling by suggesting a subset of discrete/lexicalized emotions that are *most likely* to occur, given the particular appraisal profile at hand. To determine which discrete emotions are most likely to occur, the DEW uses a parsimonious computational model -- described in details in Chapter \@ref(computational-model) -- that considers the underlying affective space as a *reference frame.* Taking the structure of the GEW as an example, if the person rates the situation as pleasant (positive Valence) and thinks she is able to modify it if desired (high Control/Power), than the subjective feeling is most likely to be represented by one of the lexicalized/discrete emotions in the top-right quadrant of the GEW, namely *interest*, *amusement*, *pride*, *joy*, or *pleasure* (see Figure \@ref(fig:gew-version-3-figure)). At the same time, depending on the specific values of the Valence and Control/Power dimensions, labels adjacent to the quadrant such as *anger* (top-right quadrant) or *contentment* (bottom-right quadrant) are also more likely to occur than, say, *regret* or *guilt*, which are at the *antipodes* of the affective space. For instance, if the person evaluates her coping potential to be elevate, but is less sure about whether the situation is pleasant or unpleasant, *anger* is probably more likely to occur than *pleasure*, which is lower in Control/Power but more positive on Valence.

Finally, the mechanisms must also reckon its limitations. For instance, the appraisal is only a proxy, and also a limited proxy since it selects a partial number of sequential evaluation checks, coalescing them in two overarching dimensions. Moreover, the suggested lexicalized emotions are based on a probabilistic model, which is additionally contingent to the *adequate* theoretical appraisal of the situation (see Section \@ref(appraisal-competence) on the appraisal competence). In other words, the respondent interpretation of the Valence and Control/Power dimensions should be aligned with the theoretical dimensions, which determine the disposition of the subjective feelings in the affective space. For these reasons, but also to comply with the GEW interface and good practices in emotion self-report more generally [@mortillaroEmotionsMethodsAssessment2015], the third step also include a "No emotion" and an "Other..." field. In this way, the system gives respondents the possibility to by-pass the suggested options and provide a custom response. Figure \@ref(fig:dew-core-wireframe-with-options) depicts the additional elements.

(ref:dew-core-wireframe-with-options-caption) Extension of the core concept with a "no emotion" and "Other..." options.

```{r dew-core-wireframe-with-options, fig.align="center", fig.cap="(ref:dew-core-wireframe-with-options-caption)", out.width="60%"}
knitr::include_graphics(here::here("./figure/dew/dew-core-principle-subset-with-options.png"))
```

The core principle of the DEW consists thus in projecting an emotion structure into the way the emotion is self-reported. Following appraisal theories principles, and the CPM more specifically, the emotion structure is represented by the Appraisal module and the Integration/Categorization module (see Section \@ref(cmpm-section) and Figure \@ref(tf-cpm-general-model-adapted) in particular). The Appraisal module is represented by the cognitive evaluation on the Valence and Control/Power dimensions, also adopted by the Geneva Emotion Wheel. The Integration/Categorization module is represented by the choice between lexicalized emotion provided by the system, a "no emotion", and a custom response. The lexicalized emotion suggested by the system are only a subset of the underlying affective space which links both modules. This subset is determined by a parsimonious computational model based on the probabilistic link between the cognitive evaluation of an event and the form by which the resulting experience, the subjective feeling, can be integrated and categorized using lexicalized emotions. This is consistent with the CPM's assumption reported from Section \@ref(subjective-feeling) and empirically validated by a number of studies [@schererHumanEmotionExperiences2013; @fontaineComponentsEmotionalMeaning2013; @fontaineWorldEmotionsNot2007; @gilliozMappingEmotionTerms2016; @schererSemanticStructureEmotion2018; @gentschEffectsAchievementContexts2017]:

> if one knows the results of an individual's event appraisal on major checks, one can approximately predict what kind of emotion he or she will most likely experience (or more precisely, what label the person is likely to use to refer to the experience).\
> -- @schererDynamicArchitectureEmotion2009, p. 1326

To sum up, the quest for defining the *unit* of measure to encode and convey emotional awareness that has started from broad emotion theories has now come to an end. An emotion for the DEW is represented by the value on two appraisal dimensions, combined with the subjective feeling in the form of a lexicalized emotion which can be either part of a predefined set, or provided by the user.

### The Principle Implemented Into a Graphical User Interface

The core principle of the DEW paved the way, conceptually, for the system to prompt the *unit* of measure to encode and convey emotional awareness. As it is the case in user experience design, though, concepts must find the appropriate correspondence in the Graphical User Interface through which the user interact with the system. Since the DEW was originally conceived as a means to provide inter-individual emotional awareness, the user interface must provide both the expressing-displaying and the perceiving-monitoring function of awareness.

The former is almost charted by the core principle. The low-fidelity wireframe of Figure \@ref(fig:dew-core-wireframe-with-options) already provide a good idea of how emotion can be self-reported. An important missing part, though, concerns the specific way by which the appraisal dimensions are labelled. Valence and Control/Power are scientific terms, unusual in everyday language. Both would therefore require translation in more intuitive and comprehensible forms. As described in the attempts to validate the disposition of feelings with direct rating for the GEW in Section \@ref(gew-limitations), this task may prove to be complicated, in particular considering the requirement for the tool to occupy a limited share of the screen. This excludes long description of the dimension as the ones adopted in direct rating for the GEW (e.g., "the situation is experienced as (un)pleasant and enjoyable (disagreeable) and/or is likely to have positive and desired (negative and undesired) consequences for the person").

The perceiving-monitoring function, on the other hand, needs to be almost invented. As highlighted in Section \@ref(ea-in-computer-mediated-environment), scant attention has been given so far to how emotion can be graphically represented in a computer-mediated (learning) environment [@ez-zaouiaEmodashDashboardSupporting2020; @leonyProvisionAwarenessLearners2013; @derickEvaluatingEmotionVisualizations2017]. The building block for decoding emotional awareness is therefore the information that has been encoded: the value on appraisal dimensions and the subjective feeling.

The attempt to integrate the different requirements with the concrete implementation of the core principle to convey emotional awareness is represented by the overall interface depicted in Figure \@ref(fig:dew-overall-commented-interface)[^2]. The interface occupies around a fifth of the width and the whole height of a *modern* screen (depending on the resolution). It is divided in two main areas: the upper part is devoted to the expressing-displaying function, whereas the bottom part to the perceiving-monitoring function of awareness tools.

(ref:dew-overall-commented-interface-caption) The overall interface of the prototype, with visual cues about the role of each element. The size of the tool is not representative in proportion to the browser's window. The actual size is closer to one-fifth of the width.

```{r dew-overall-commented-interface, fig.align="center", fig.cap="(ref:dew-overall-commented-interface-caption)", out.width="100%"}
knitr::include_graphics(here::here("./figure/dew/dew-overall-commented-interface.png"))
```

The expressing-displaying function implements the core principle as described by the wireframes, using a uniform orange color for most of the elements of the interface that the user can manipulate. The two appraisal dimensions are represented by two horizontal sliders, each one with a continuum ranging from a negative *not at all* to a positive *yes, absolutely* poles. The neutral point is highlighted with a cue in the middle of the slider range. The Valence dimension is prompted by the label *VALENCE - Is the situation pleasant?* whereas the Control/Power with the label *POWER - Is the situation under your control?*. The choice of wording is adapted from the complementary material available with the Geneva Emotion Wheel[^3]. The name of the dimension in uppercase has been provided as a cue for the appraisal dimensions in the lower part of the screen, described below.

The suggested subjective feelings are represented by three orange buttons, labelled with the lexicalized emotions that are most likely to occur given the values of the two appraisal-sliders. Below the three buttons, a text-input allows user to enter a custom response, which must be confirmed with a *Send* button. When the field is activated, a drop-down menu shows all the available lexicalized emotion. Beside the custom response field, a *No emotion* completes the options to express encode an emotional episode into the tool. The overall interaction workflow is depicted with three screen captures disposed side-by-side in Figure \@ref(fig:dew-expressing-sequence).

(ref:dew-expressing-sequence-caption) The sequence to express-display an emotion through the Dynamic Emotion Wheel.

```{r dew-expressing-sequence, fig.align="center", fig.cap="(ref:dew-expressing-sequence-caption)", out.width="32%", fig.show="hold"}
knitr::include_graphics(c(
  here::here("./figure/dew/dew-expressing-step1.png"), 
  here::here("./figure/dew/dew-expressing-step2.png"), 
  here::here("./figure/dew/dew-expressing-step3.png")
))
```

The user is first prompted to rate the appraisal sliders. This message appears only the very first time the DEW interface appears and covers the space where the subjective feelings will appear. In this way, the dynamic nature of the link between the sliders and the buttons is perceived from the very onset of the interaction. The two sliders are also numbered to enforce the rating order corresponding to the sequential evaluation checks. As soon as the user moves one of knobs of the appraisal sliders, the options to express the subjective feelings appear. The number 3 besides the appearing zone completes the sequence of steps necessary to express the emotion. The user can at this moment observe the computed subset of discrete emotions and assess whether any of them is suitable to represent the actual subjective feeling. In that case, the corresponding button can be clicked. Otherwise, the "Other.." field or the "No emotion" buttons can be used instead. Once one of the options to express the subjective feeling is triggered, the system confirms the emotion has been encoded, showing also the time of the action. The confirmation message also inform the user that in order to express another emotion, the sliders must be moved again. A link can be clicked if the cognitive evaluation hasn't changed. This feature is intended especially in the case of blended or mixed emotions [@schererWhatAreEmotions2005; @schererHumanEmotionExperiences2013], which can be expressed in rapid succession by modifying only the subjective feeling, leaving the appraisal dimensions at the same values.

The perceiving-monitoring part of the screen mirrors the emotion structure encoded by the system. The upper part is devoted to the subjective feeling, whereas the bottom part to the appraisal dimensions.

For the subjective feelings, an emotion timeline shows the chronology of the lexicalized emotion for the person herself (top) and the partner (bottom). The lexicalized emotions are added on the right of the line, pushing the older ones back. The two lines are synchronized, so that the last visible emotions are those more recent in time, regardless of whom has expressed them. In Figure \@ref(fig:dew-overall-commented-interface), for instance, the last subjective feeling is *Relief* and was encoded by the person using the tool, whereas the second-to-last is *Fear*, expressed by the partner. A scrolling bar allows participants to scale back and forth if desired. The aim of emotion timeline is to provide both an up-to-date and a chronological comparison of the emotional experience between the person and the partner.

Below the emotion timeline, two line charts report the chronology of the appraisal dimensions: the top one for the person herself, the bottom one for the partner. Each dimension has its own line on each chart. The lines also shrink and adapt when a new emotion is inserted into the system, even though each chart shrinks independently from the other. In Figure \@ref(fig:dew-overall-commented-interface), we can for instance see that the line chart for the person using the tool is more nuanced compared to the partner, whose appraisals tend to jump from one extreme of the continuum to the other, and also overlap considerably. The aim of the charts is to pass into perception the evolution of the cognitive evaluation over time [@hegartyCognitiveScienceVisualspatial2011].

To sum up, the DEW thus maintains most of the theoretically and empirically validated characteristics of the Geneva Emotion Wheel, but adapting and extending some functions to better fit with the perspective of an awareness tool rather than a self-report tool. An important missing feature compared to the GEW is the possibility to rate the intensity of the emotional episode. The values of the appraisal dimensions is in fact not to be confused with the intensity of the emotion.

Furthermore, the interface allows to meet most of the requirements set forth with the EATMINT project's members, listed in Section \@ref(eatmint-requirements). First, the tool clearly maintains its self-report perspective. Second, it implements an emotion structure, based on the Component Process Model theoretical framework. Third, it reduces the number of concurrent choices on the screen, leveraging on the dynamic mechanisms of sub-setting the underlying affective space. Fourth, the space gained from a reduced expressing-displaying part is used to provide graphical representation of emotions, which are meant to increase the perception of the evolution of the emotional experience over time, as well as foster comparison between the person and the partner. Finally, by abstracting the computational model and harnessing the construction by modules of the graphical representation, it is also possible to adapt the inner-functioning and/or the appearance of the tool. In this regard, the next section shows a first adaptation that was made by creating an underlying affective space with starting from the discrete emotion used in the EATMINT tool.

### The EATMINT Circumplex {#eatmint-circumplex}

A first theoretical, rather than technical, distinction from the Geneva Emotion Wheel consisted in adapting the underlying affective space to lexicalized emotions more likely to occur in computer-mediated collaborative task. The 20 lexicalized emotions of the GEW have been in fact chosen for their relative frequency in everyday experience at large [@schererWhatAreEmotions2005; @schererGRIDMeetsWheel2013; @shumanConceptsStructuresEmotions2014]. The EATMINT team had already provided a list of discrete emotions listed in Table \@ref(tab:eatmint-original-emotions-table) of Section \@ref(description-of-the-eatmints-first-version-of-an-eat). It was thus possible to exploit this list, provided that each lexicalized emotion could be placed on an underlying circumplex.

As suggested by the authors having worked on the GEW, one valid way to perform this task would have been the use of the GRID instrument [@schererGRIDMeetsWheel2013; @fontaineComponentsEmotionalMeaning2013]. Nevertheless, setting up a study asking participants to rate the discrete emotions seemed too risky without a prior test of the prototype. As a consequence, the discrete emotions used by the EATMINT team were placed by searching correspondences in existing bi-dimensional affective spaces. In particular, the four circumplex-like affective spaces were identified: versions 2.0 and 3.0 of the Geneva Emotion Wheel [@schererGRIDMeetsWheel2013], the circumplex model of affect @russellCircumplexModelAffect1980, and the alternative dimensional structures of the semantic space for emotions built by Scherer [@schererWhatAreEmotions2005], which also integrates the circumplex from the pan-cultural study by Russel [@russellPanculturalAspectsHuman1983]. Whereas the former two affective spaces use the Valence x Control/Power dimensions, the latter use the Valence x Arousal dimensions. In this regard, though, Scherer [-@schererWhatAreEmotions2005, p. 722] notes that "a 45° rotation of the axes [of Russell's circumplex] corresponds rather nicely to an explanation of the distribution of the terms in a two-dimensional space formed by goal conduciveness and coping potential".

Using these sources and conceding a certain degree of approximation due to the translation, it was possible to find a match for 16 out of the 20 EATMINT discrete emotions. Table \@ref(tab:matching-eatmint-emotions) lists the original EATMINT label, the label and the affective space of the source, and the value on the Valence and Control/Power dimensions.

(ref:matching-eatmint-emotions-caption) Matching in existing affective spaces to create the EATMINT circumplex

```{r matching-eatmint-emotions}
matching_table <- tribble(
  ~"EATMINT", ~"Source", ~"Affective space", ~"Val.", ~"C./P.",
  "Amused", "Amusement", "GEW 3.0", "+", "+",
  "Attentive", "Attentive", "Scherer, 2005", "+", "+",
  "Confident", "Self-confident", "Scherer, 2005", "+", "+",
  "Empathetic", "Compassion or Empathetic", "GEW 3.0 or Scherer, 2005", "+", "-",
  "Interested", "Interest", "GEW 3.0", "+", "+",
  "Delighted", "Joy or Elation", "GEW 2.0 or 3.0", "+", "+",
  "Satisfied", "Contentment", "GEW 3.0", "+", "-",
  "Relieved", "Relief", "GEW 3.0", "+", "-",
  "Annoyed", "Annoyed", "Scherer, 2005", "-", "+",
  "Envious", "Envy", "GEW 2.0", "-", "+",
  "Frustrated", "Frustrated", "Scherer, 2005", "-", "-",
  "Disappointed", "Disappointed", "GEW 3.0", "-", "-",
  "Irritated", "Irritation", "GEW 2.0", "-", "+",
  "Bored", "Bored", "Scherer, 2005 or Russel, 1980", "-", "-",
  "Surprised", "Surprise", "GEW 2.0", "+", "-",
  "Stressed", "Stressed", "Russel, 1980", "-", "+"
)

matching_table |> 
  arrange(EATMINT) |> 
  kable(
    caption = "(ref:matching-eatmint-emotions-caption)\\label{tab:matching-eatmint-emotions}",
    caption.short = "Matching in existing affective spaces to create EATMINT circumplex",
    longtable = FALSE,
    booktabs = TRUE,
    align = c("l", "l", "l", "c", "c")
  )
```

Two other discrete emotions had a partial matching in the sources. *Anxious* could be related to Worry (GEW 2.0) or Anxious (Russel, 1980). In one case, though, the Valence was positive and in the other negative, whereas the Control/Power was negative in both sources. *Relaxed* was matched with Relaxed or Calm in Scherer (2005), in which case the Valence was positive, but the Control/Power was positive for one and negative for the other. It was decided to place the *Anxious* in the quadrant with both negative values, whereas *Relaxed* was placed in the positive Valence and negative Control/Power quadrant. With this configuration, the 18 discrete emotions placed so far formed a nicely balanced circumplex, with 5 emotions in the top-right and bottom-right quadrants, and 4 emotions for the quadrants on the left side.

The two lasting discrete emotions did not have even a partial matching. So it was decided using an heuristic approach to place *Confus*ed in the quadrant with both negative dimensions. The very last emotion, *Grateful*, seemed more adequate in the positive Valence and negative Control/Power quadrant, but this quadrant tallied already 5 emotions. The only quadrant with a missing discrete emotion was the negative Valence, positive Control. It was thus decided to leave *Grateful* out of the circumplex, and replace it with *Dégoûté*, translated by *Disgusted*. The final disposition is depicted in Figure \@ref(fig:theoretical-feelings-graph).

(ref:theoretical-feelings-graph-caption) Disposition of 19 out of 20 discrete emotion used in the EATMINT project, with *Grateful* replaced by *Disgusted* to balance 5 items in every quadrant. The result is the EATMINT circumplex.

```{r theoretical-feelings-graph, fig.align='center', out.width="100%", fig.height=9, fig.cap="(ref:theoretical-feelings-graph-caption)", fig.pos="p"}
source(here::here("./data/study-comparison/src/02-eda.R"), local = knitr::knit_global(), encoding = "UTF-8") 
sc.theoretical_feelings_disposition_circumplex.graph +
  ggtitle("EATMINT circumplex")
```

The resulting EATMINT circumplex has a double interest. On a practical standpoint, it is an affective space that is meant to provide users with lexicalized emotions tailored to computer-mediated collaboration, which may be extended to Computer-Supported Collaborative Learning (see Section \@ref(mutual-modeling). On a more abstract level, it is a first step in the customization of the Dynamic Emotion Wheel, which can be driven by theoretical and/or empirical foundations. Before heading this subject more thoroughly, the results of a usability test are illustrated first to provide a preliminary assessment of the prototype.

## Usability Test of the Dynamic Emotion Wheel in Experimental Conditions {#dew-ux-test}

The interaction design method implies that an iterative cycle ends with a usability test, from which useful information can be gathered in order to corroborate design choices or solve issues that may emerge from the concrete use of the product [@cooperFaceEssentialInteraction2007; @rogersInterctionDesignHumanComputer2011]. Oftentimes, the usability test consists in asking to a number of users to execute a series of guided tasks individually, which aim at a specific solution, such as performing a determinate manipulation on the interface or point to the correct information available [@lallemandMethodesDesignUX2017]. Nevertheless, the characteristics of an EAT do not really match with this testing conditions. First, the task to execute on an EAT consists in more or less the same procedure, which takes on value depending on how expressing-displaying and perceiving-monitoring information is integrated into the task at hand. Second, from the inter-subjective point of view of the computer-mediated collaboration and Computer-Supported Collaborative Learning perspectives of the EATMINT project, an individual test did not respond to the ecological situation in which the tool should be deployed.

At the same time, a usability test must provide similar and controlled conditions for the information gathered to be reliable and summarized over trials. To strike a balance between the two seemingly opposing requirements, it was decided to perform a usability test in experimental conditions, which also happen to coincide with one of the aimed domain for the implementation of the tool, namely research. Participants were therefore asked to take part in a computer-mediated collaborative task consisting in the resolution of 4 enigmas. Participants were made to believe that another person was collaborating with them from another location, but actually the collaboration was simulated. The details of the experimental settings will be described thoroughly in the first empirical contribution of Part III, who adopted the very same principle, with the very same material and procedure. In this section, the main results of the usability test are illustrated, for some measure obtained through it also play a prominent role in the empirical part of the thesis. Given the experimental nature of the usability test, the section is organized with a brief overview of the method first, followed by a discussion of the main findings. A last subsection gathers observed measures that will be referred to in the rest of the contribution, so the section is meant as a look-up reference. In this regard, all results have been re-computed and are therefore to be considered more reliable than in @fritzReinventingWheelEmotional2015 in case of inconsistencies.

### Method

$N = 16$ participants (8 women and 8 men, $M_{age} = 26.9, SD_{age} = 6.1$) voluntarily participate to the test, without any remuneration. They were recruited in the main building of the Psychology and Educational Sciences Faculty, whereas the test took place in an adjacent building. Participants were not expert neither in the field of emotion psychology nor human-computer interaction. Two women nevertheless followed a specific course about emotion psychology in their bachelor program, and were thus familiar with concept such as Valence or Control/Power. One man and one woman followed a specific course about human-computer interaction in their master program, and were thus familiar with concept such as usability and usability testing.

Participants disposed of an overall interface composed by the Dynamic Emotion Wheel as illustrated in Figure \@ref(fig:dew-overall-commented-interface), but adopting the EATMINT circumplex as underlying affective space, and by a custom interface for the joint problem-solving (simulated) task on the right-side. (The overall interface can be inferred from the heatmap in Figure \@ref(fig:ux-heatmap-duration) in this Section, or in the Method section of Chapter \@ref(study-1).) The task consisted in reading the text of the enigma and write the reasoning as well as the solution to the problem. While performing the task, participants were asked to express at least one emotion for each step in the enigma resolution: reading the problem, writing the reasoning and solution, and finding out the correct answers. There was nevertheless not any mechanism that reminded users to express them or prevent them for expressing more. According to the awareness tool perspective, they could use the tool as they saw fit.

The simulation was created by the *playback* of the interaction with the overall interface, which was recorded beforehand while two persons were actually performing the very same task in real-time. Everything one of the two persons did during that trial was *re-injected* into the interface at the very same time it happened on the synchronous trial. Being the problem-solving task determined by a fixed time to solve the problem (20 minutes overall, 5 minutes for each of the 4 enigmas), all participants were exposed to the same events on the interface. On the one hand, the reasoning and solutions to the enigmas were the same and appeared at the very same time. On the other, the emotions expressed by the recorded person appeared in the perceiving-monitoring part of the DEW. Consequently, participants could see the subjective feelings popping up in the emotion timeline, and the evolution of the cognitive evaluation appeared on the two line charts.

Participants were instructed not to communicate directly with the partner (to maintain the illusion of collaboration), for instance by asking questions through the text input used to write the reasoning. A system of points was implemented to foster the (simulated) collaboration: 1 point for each correct response given by either member of the dyad, 0 points for every response not given, and -1 points for every incorrect response. Once again to maintain the illusion of the collaboration, each member of the dyad could provide their own response and the collaboration consisted thus in building on each other reasoning in order to maximize the acquisition of points.

The screen on which the test was taken was equipped with an eye-tracking device [@pooleEyeTrackingHumanComputer2005; @blascheckVisualizationEyeTracking2017], which allowed the gaze of participants to be tracked during their interaction with the overall interface of the task. Consequently, the test provided measures from the DEW, from the eye-tracker device, and from an end-of-task survey, comprising the System Usability Scale (SUS) created by @brookeSUSQuickDirty1996, a widely adopted usability measure illustrated in more details in Chapter \@ref(study-comparaison).

### Main Results and Discussion

The illustration of the main indications retrieved from the test are organized as follows: first, general indications about the results and the overall task; second cues about the expressing-displaying function; then about the perceiving-monitoring function; and last about the overall user experience.

The results are based on $N = 14$ for all measures, except for eye-tracking indicators, which are based on $N =12$ participants. Two participants were excluded only from the eye-tracking measures due to a poor sampling percentage, that is, the number of time the eye-tracker system could detect the position of participants' gaze. This is not unusual since the eye-tracking device may be sensitive to head movements, light conditions in the room, or lenses of glasses. Other two were excluded overall because they had a total time of detection of their gaze on the task side of less than 3 minutes out of the 20 minutes of the task, against a mean of the other participants superior to 10 minutes ($M =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_TASK_Sum |> mean() |> printnum()`, $SD =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_TASK_Sum |> sd() |> printnum()` seconds). The time on the task part of the zone was chosen as a filter since a participant could genuinely not be interested in the EAT, but not looking at the task could either suggest a technical problem or disinterest in the experience. The gaze in the EAT side of the screen, as a comparison, was detected for almost 4 minutes on average ($M =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_EAT_Sum |> mean() |> printnum()`, $SD =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_EAT_Sum |> sd() |> printnum()` seconds). Summing the two measures, we obtain thus around 14 minutes of gaze detection. The lagging time is due to fact that participants had to write on their keyboard or manipulate the mouse and therefore turn away the eyes from the screen.

For the expressing-displaying function, the use of the two appraisal sliders confirmed a substantial overlapping between Valence and Control/Power, which tended to moderately co-variate: the average correlation computed first by averaging over each participant (except one who kept the sliders unchanged during the whole task) was of $M_r =$ `r ux.appraisals$cor |> mean(na.rm = TRUE) |> printnum()` ($SD_r =$ `r ux.appraisals$cor |> sd(na.rm = TRUE) |> printnum()`). The lack of orthogonality of the two sliders reflects the problem already cited in the limitations of the Geneva Emotion Wheel in Section \@ref(gew-limitations). Even if it is not possible to infer this from a correlation, it is safe to assume that Valence has the upper-hand over the overall evaluation of the situation, with the Control/Power evaluation following suit without, in most cases, providing additional value in terms of self-reflection and communication. In the meantime, measures gathered through the appraisal sliders confirmed one of the central tenet of appraisal theories, namely that it is the evaluation of the situation, rather than the situation *per se*, that determines the emotional experience. In spite of participants being exposed to the same stimuli in the simulated collaboration, the evolution of the appraisal profiles throughout the task were very different from participant to participant.

The assessment of the subjective feeling function also yielded mixed results. On the one hand, the EATMINT circumplex seems to provide an overall list of pertinent lexicalized emotion for computer-mediated collaboration. Out of the `r fritz2015_emotions_filtered |> nrow()` emotions expressed overall, only `r fritz2015_emotions_filtered |> filter(listed == 0, feeling != "None") |> pull(feeling) |> unique() |> length()` were typed-in by participants. The "none" option was taken only 4 times by 4 different participants. On the other hand, users took advantage of the computational suggestion of the most likely subjective feelings a little bit more than 50% of the times. With a mean across participants of $M =$ `r ux.expressing$tot |> mean() |> printnum()` ($SD =$ `r ux.expressing$tot |> sd() |> printnum()`) emotions expressed, $M =$ `r ux.expressing$button |> mean() |> printnum()` ($SD =$ `r ux.expressing$button |> sd() |> printnum()`) were encoded by using one of the three buttons labelled with a lexicalized emotion, whereas $M =$ `r ux.expressing$other |> mean() |> printnum()` ($SD =$ `r ux.expressing$other |> sd() |> printnum()`) through the use of the "other..." field. The large standard deviations around the means highlight that the use of the tool for expressing one's emotions is subject to great inter-individual variability. This may suggest different approaches taken by participants to the computational link between appraisal dimensions and subjective feelings.

Using the number of times the gaze of the participant entered each zone of the interface (*i.e.*, the number of visits), it was possible to note that the expressing-displaying area of the tool was sought after ($M =$ `r fritz2015_eyetracking_filtered$Visit_Count_Displaying_Sum |> mean() |> printnum()`, $SD =$ `r fritz2015_eyetracking_filtered$Visit_Count_Displaying_Sum |> sd() |> printnum()` visits) more frequently than the perceiving-monitoring area ($M =$ `r fritz2015_eyetracking_filtered$Visit_Count_Monitoring_Sum |> mean() |> printnum()`, $SD =$ `r fritz2015_eyetracking_filtered$Visit_Count_Monitoring_Sum |> sd() |> printnum()` visits). This metric is also corroborated by the sum of the visit duration, that is the time while the gaze of participants stayed inside each area. The expressing-displaying zone was processed for $M =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_Displaying_Sum |> mean() |> printnum()` ($SD =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_Displaying_Sum |> sd() |> printnum()`) seconds, against $M =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_Monitoring_Sum |> mean() |> printnum()` ($SD =$ `r fritz2015_eyetracking_filtered$Total_Visit_Duration_Monitoring_Sum |> sd() |> printnum()`) seconds for the perceiving-monitoring zone. Participants thus spent more time at seeking and processing information to produce rather than to consume emotional awareness. This comparison must therefore consider that encoding an emotion in self-report takes more effort and time than decoding.

Within the perceiving-monitoring area of the EAT, the emotion timeline with subjective feelings was sought after more frequently ($M =$ `r ux.perceiving$timeline_visits |> mean(na.rm = TRUE) |> printnum()`, $SD =$ `r ux.perceiving$timeline_visits |> sd(na.rm = TRUE) |> printnum()` visits) than the two line charts with the appraisal dimensions combined ($M =$ `r ux.perceiving$linechart_visits |> mean(na.rm = TRUE) |> printnum()`, $SD =$ `r ux.perceiving$linechart_visits |> sd(na.rm = TRUE) |> printnum()` visits). Information on the emotion timeline was also processed longer ($M =$ `r ux.perceiving$timeline_duration |> mean(na.rm = TRUE) |> printnum()`, $SD =$ `r ux.perceiving$timeline_duration |> sd(na.rm = TRUE) |> printnum()` seconds) compared to the line charts ($M =$ `r ux.perceiving$linechart_duration |> mean(na.rm = TRUE) |> printnum()`, $SD =$ `r ux.perceiving$linechart_duration |> sd(na.rm = TRUE) |> printnum()` seconds). The subjective feelings were thus looked up and processed more frequently than the appraisal dimensions, suggesting they provide a more useful representation of participants' emotional experience. Once again, though, the two graphical representation are not equivalent in term of cognitive processing required to peruse the content [@hegartyCognitiveScienceVisualspatial2011]. The line charts provide a more immediate, perception-based understanding of the content, even though this process may be limited to expert [@pinkerTheoryGraphComprehension1990]. A holistic representation of how the overall interface was perused is provided by the heatmap in Figure\@ref(fig:ux-heatmap-duration), which depicts the duration of information processing, but the visits for information seeking are almost overlapping. The gaze on the red zones have lasted longer compared to the zone of the interface without a colored over-layer.

(ref:ux-heatmap-duration-caption) Heatmap representing the time the gaze has lasted on each part of the interace. Red zones represent long-gazed elements.

```{r ux-heatmap-duration, fig.align="center", fig.cap="(ref:ux-heatmap-duration-caption)", out.width="80%"}
knitr::include_graphics(here::here("./figure/dew/ux-test-heatmap.png"))
```

Finally, the usability and overall perception of the user experience were assessed by using the SUS [@brookeSUSQuickDirty1996] and through an end-of-task survey and debriefing, in which participants were also informed of the faked collaboration. The overall rating on the SUS score has been of $M =$ `r ux.sus_total$score |> mean() |> printnum()` ($SD =$ `r ux.sus_total$score |> sd() |> printnum()`) on a scale from 0 to 100. A comprehensive assessment of the perceived usability of the DEW is provided in Chapter \@ref(study-comparaison), where the score will be integrated by another evaluation on the SUS in an empirical contribution, and matched against benchmarks. For the moment, it suffices to retain that the usability was perceived somehow in favorable terms. This was corroborated by open-ended questions during the debriefing, in which participants confirmed, first, the novelty of sharing emotion during a computer-mediated collaborative task. They found the concept intriguing, and found that the EAT increased their attention on their own, as well as their partner's emotional experience. On the other hand, though, they were less convinced about the extent by which the emotional information was integrated in instrumental terms with the problem-solving task at hand.

The test provided thus mixed but, all things considering, encouraging indications about the usability and the overall user experience with the tool. It also highlighted, though, some issues that corroborated previous findings in the self-assessment of emotion based on the Valence and the Control/Power dimensions.

### Retained Measures for Further Empirical Contributions

In this subsection, a selection of measures observed in the usability test are grouped into a reference table. These measures will be used in analysis and comparisons in the empirical part of the thesis.

(ref:ux-lookup-table-caption) Reference measures from the usability test in Fritz (2015)
```{r ux-lookup-table}
ux_measures <- tribble(
  ~Description, ~N, ~M, ~SD,
  
  "Visits duration in the Task Area (seconds)", 12, fritz2015_eyetracking_filtered$Total_Visit_Duration_TASK_Sum |> mean(), fritz2015_eyetracking_filtered$Total_Visit_Duration_TASK_Sum |> sd(),
  
  "Visits duration in the EAT Area (seconds)", 12, fritz2015_eyetracking_filtered$Total_Visit_Duration_EAT_Sum |> mean(), fritz2015_eyetracking_filtered$Total_Visit_Duration_EAT_Sum |> sd(),
  
  "Number of emotion expressed by participant", 14, ux.expressing$tot |> mean(), ux.expressing$tot |> sd(),
  
  "Visits count in the Perceiving-Monitoring Area", 12, fritz2015_eyetracking_filtered$Visit_Count_Monitoring_Sum |> mean(), fritz2015_eyetracking_filtered$Visit_Count_Monitoring_Sum |> sd(),
  
  "Visits duration in the Perceiving-Monitoring Area (seconds)", 12, fritz2015_eyetracking_filtered$Total_Visit_Duration_Monitoring_Sum |> mean(), fritz2015_eyetracking_filtered$Total_Visit_Duration_Monitoring_Sum |> sd()
)

ux_measures |> 
  kable(
    caption = "(ref:ux-lookup-table-caption)\\label{tab:ux-lookup-table}",
    caption.short = "Reference measures from the usability test in Fritz (2015)",
    longtable = FALSE,
    booktabs = TRUE,
    digits = 2
  )
```


## Extending the Prototype Into a Proof of Concept {#dew-extension-illustration}

### Theoretical Extension

### Technical Extension

## Synthesis

[^1]: As a consequence, some short passages of this chapter are reproduced from the unpublished Master thesis's manuscript, especially description of interfaces or settings, for which little or no additional value could be derived from modifications.

[^2]: The images actually are taken from the last version of the tool available at the time of writing and may thus differ from the images in the Master thesis. The main features are nonetheless equivalent.

[^3]: Available at <https://www.unige.ch/cisa/gew> at the time of writing
