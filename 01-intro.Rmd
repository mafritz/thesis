# Introduction {.unnumbered}

```{r itro-setup, include=FALSE, echo=FALSE}
library(tidyverse)
library(papaja)
library(here)
library(knitr)
library(kableExtra)

```

Imagine that you are co-authoring a text with a colleague for an upcoming assignment that you must submit in a course: you are at home, she can be anywhere in the world. You are using an online text processor, which allows you to edit the document simultaneously. This particular text editor has the feature of attributing animals names to authors, so that you are currently identified in the work-space as *anonymous hippo*, and your partner is *anonymous turtle*. The only thing you can see about the *turtle* is the flow of letters that stems from the position of her cursor in the document whenever she is typing on her keyboard, and *vice versa*. Imagine being in this situation: what kind of information about the *turtle* would you like to know to better assess how the learning task is going? And what kind of information about yourself would you like the *turtle* to know, for her to better assess how the learning task is going?

You have probably guessed from the title of the thesis -- the answer put forward in the present contribution is: *emotions*. In the last few decades, emotions have been widely studied from different perspectives, giving rise to the interdisciplinary field of affective sciences [e.g., @davidsonHandbookAffectiveSciences2003; @sanderOxfordCompanionEmotion2009]. There is nowadays a theoretical convergence on some characteristics of emotions, which have deeply modified many of the common (mis)conceptions about what they are, why do we have them for, which causes and consequences they have, and how we can take advantage from them in various circumstances of life both at individual and collective levels [for a recent overview, see among others @adolphsNeuroscienceEmotionNew2018; @barrettHowEmotionsAre2018; @damasioStrangeOrderThings2018; @foxNatureEmotionFundamental2018; @grossEmotionRegulationCurrent2015; @plamperHistoryEmotionsIntroduction2015; @pessoaCognitiveemotionalBrainInteractions2013; @rimePartageSocialEmotions2005; @sanderAppraisalDrivenComponentialApproach2018; @sanderModelsEmotionAffective2013; @schererWhatAreEmotions2005; @vankleefInterpersonalDynamicsEmotion2018].

Education and learning have also been implicated in the *affective revolution*: current trends in the field of learning psychology and education sciences advocate the integration of cognitive, social and affective interactions as a means to improve both learning processes and outcomes [see @bakerAffectiveLearningTogether2013; @pekrunInternationalHandbookEmotions2014; @pekrunEmotionsSchool2018 for recent and overarching perspectives]. Be it in the classroom, in blended, or in distance learning environments, the affective components of learning are receiving greater attention at various levels of formal and informal education. There is in fact a growing consensus in considering that learning processes and outcomes influence students' affective states and, conversely, that students' affective states influence learning processes and outcomes [for a recent overview, see @brackettRULERTheoryDrivenSystemic2019; @dixonEducatingEmotionsGradgrind2012; @dmelloSelectiveMetaanalysisRelative2013; @immordino-yangEmotionsLearningBrain2016; @jarvenojaRegulationEmotionsSocially2013; @mantySocioemotionalInteractionCollaborative2020; @pekrunMeasuringEmotionsEpistemic2016; @pekrunProgressOpenProblems2005; @petridesRoleTraitEmotional2004; @reisAffectiveStatesComputersupported2018; @reisAffectiveStatesCSCL2015].

Especially in distance learning, though, the integration of socio-emotional information is particularly challenging, since the para-verbal cues that are available in face-to-face interactions are often limited or absent [@baltesComputerMediatedCommunicationGroup2002; @derksRoleEmotionComputermediated2008; @kreijnsSocialAspectsCSCL2013; @marchandRoleEmotionLearning2012; @parkinsonEmotionsDirectRemote2008; @riordanEmotionEncodingInterpretation2010]. This shortcoming is particularly relevant if we consider how good or accurate people are in recognizing affective states in others through efferent manifestations such as facial expressions, vocal prosody or body posture, in a process that is relatively effortless -- but not trivial -- and consistent in different contexts and cultures [@hallSocialPsychologyPerceiving2018; @mumenthalerAutomaticIntegrationSocial2015; @schlegelEmotionRecognitionUnidimensional2012; @schlegelNomologicalNetworkEmotion2017; @shumanEmotionPerceptionComponential2017]. Information derived through affective cues is then applied to infer causes and consequences of behavior in others, and can thus serve as useful information for one's own behavior [@fischerSocialFunctionsEmotion2016; @parkinsonEmotionsInterpersonalInteractions2010; @rimePartageSocialEmotions2005a; @vankleefInterpersonalDynamicsEmotion2018].

One of the prospected solution to overcome this shortcoming is the implementation of awareness tools, that is, technological artifacts implemented in the learning environment providing information about others, which is instrumental to the task at hand [@buderGroupAwarenessTools2011; @dourishAwarenessCoordinationShared1992; @janssenCoordinatedComputerSupportedCollaborative2013; @janssenGroupAwarenessTools2011; @kirschnerAwarenessCognitiveSocial2015; @millerScriptingAwarenessTools2015; @schmidtProblemAwareness2002]. Whereas, originally, awareness tools aimed preeminently at displaying whether a person was connected to the environment and, possibly, what she was doing, current trends in the field advocate a more thorough and holistic perspective. For instance, awareness tools should resist the temptation to mimic co-located contexts, by trying to provide exactly the same information that is available in face-to-face conditions. On the contrary, awareness tools should rather focus on information that is not available -- or difficult to perceive, process or remember -- even face-to-face. An example of this perspective is provided by *Knowledge Awareness Tools* [@dehlerGuidingKnowledgeCommunication2011; @engelmannKnowledgeAwarenessCSCL2009; @sanginFacilitatingPeerKnowledge2011], that is, tools that provide information on what other members of a group know --- or, conversely, don't know -- about, for instance, the subject at hand. This kind of information is not readily available in face-to-face interactions, unless it is overtly manifested in the activity. Through a knowledge awareness tool, though, learners can monitor their colleagues' knowledge when needed, and take advantage from it, for instance, by asking for help, building on common ground, tailoring exchanges on the expertise of the other, and so on.

Awareness tools can vary greatly along different technical, pedagogical and contextual dimensions. There are nevertheless some common abstract features and overarching perspectives on their integration in learning environments that have emerged over the last decades [@buderGroupAwarenessTools2011; @gutwinDescriptiveFrameworkWorkspace2002; @janssenCoordinatedComputerSupportedCollaborative2013; @kirschnerAwarenessCognitiveSocial2015; @schmidtProblemAwareness2002]. For instance, all functions of an EAT can be roughly divided in two: (1) the *displaying* function, consisting in making the relevant information available into the system; and (2) the *monitoring* function, which allows users to retrieve and process that same relevant information [@buderGroupAwarenessTools2011; @schmidtProblemAwareness2002].

The present contribution focuses on a particular type of awareness tool, namely an *Emotion Awareness Tool* (EAT), which has received so far little, but growing, attention [@arguedasOntologyEmotionAwareness2015; @chanelGrandChallengeProblem2016; @chenEmpatheticonsDesigningEmotion2014; @feidakisProvidingEmotionAwareness2014; @fritzProvidingEmotionalAwareness2017; @fritzDynamicEmotionWheel2015; @lavoueEmotionAwarenessTools2020; @molinariEmotionFeedbackComputermediated2013; @cerneaSurveyTechnologiesRise2015]. An EAT combines features of an awareness tool with that of affective systems, such as affect-aware or emotion-aware technologies, through which affective information is integrated into the technology enhanced learning environment [for a recent overview see among others @arguedasOntologyEmotionAwareness2015; @calvoFeelingThinkingComputing2015; @calvoFrontiersAffectAwareLearning2012; @feidakisReviewEmotionAwareSystems2016; @grawemeyerAffectiveLearningImproving2017; @harleyDevelopingEmotionAwareAdvanced2017; @cerneaSurveyTechnologiesRise2015]. Such systems, though, may vary greatly in their features and objectives, for instance with respect to how they conceptualize affect and what affective dynamics they aim to enhance in the learning process.

From an affective standpoint, affective systems can be categorized according to the aims of affective computing more generally [@picardAffectiveComputing2000; @schererBlueprintAffectiveComputing2010], which Picard [-@picardAffectiveComputing2009] categorizes in four non mutually exclusive areas: (1) technologies for sensing, recognizing, modeling, and predicting emotional and affective states; (2) methods for computers to respond intelligently and respectfully to handle perceived affective information; (3) technology for displaying emotional information or mediating the expression or communication of emotion; and (4) computational mechanisms that stimulate internal emotions or implement their regulatory and biasing functions. Furthermore, affective systems may focus on one or more phenomena within the affective spectrum, such as preferences, dispositions, moods or emotions [@schererWhatAreEmotions2005]. Finally, they can target one or more processes within the same affective phenomenon such as elicitation, recognition, understanding, communication or regulation [@boehnerHowEmotionMade2007; @derksRoleEmotionComputermediated2008; @eligioEmotionUnderstandingPerformance2012; @grandjeanConsciousEmotionalExperience2008; @grossEmotionRegulationCurrent2015; @reeckSocialRegulationEmotion2016; @schererAppraisalConsideredProcess2001; @schererComponentialEmotionTheory2007; @schlegelEmotionRecognitionUnidimensional2012; @siemerSameSituationdifferentEmotions2007].

From the point of view of the learning process, affective systems can be oriented -- exclusively, primarily or equally -- towards the learner's individual affective states, the collective affective states of a group sharing common learning processes and outcomes, the affective states of teachers, or even the affective states of computerized agents implemented into the system, such as embodied tutors [@cerneaGroupAffectiveTone2014; @craigEmoteAloudLearning2008; @lavoueEmotionAwarenessTools2020; ; @leeTeachersEmotionsEmotion2016; @mantySocioemotionalInteractionCollaborative2020; @naykkiSocioemotionalConflictCollaborative2014]. The aim of the affective system may also be inherently linked to the subject at hand, such as support in a computer science course, or overtly concerned with the acquisition of affect-related skills such as social and emotional learning [@brackettRULERTheoryDrivenSystemic2019; @osherAdvancingSciencePractice2016], emotional competence [@schererComponentialEmotionTheory2007; @schlegelGenevaEmotionalCompetence2018], emotional intelligence [@chernissEmotionalIntelligenceClarification2010; @hodzicHowEfficientAre2018; @nathansonCreatingEmotionallyIntelligent2016; @saloveyEmotionalIntelligence1990; @mayerAbilityModelEmotional2016], or emotion self- or social-regulation [@hoffmannTeachingEmotionRegulation2020; @jarvenojaEmotionControlCollaborative2009; @jarvenojaRegulationEmotionsSocially2013].

In this regard, the thesis proposes the implementation and assessment of a 

With a provisional definition of an EAT at hand, let us go back to the case of the *hippo* and the *turtle* co-authoring a paper. Imagine that you, the *hippo*, have just typed a long paragraph in the shared document. Shortly after, through the EAT that both you and the *turtle* have at disposal, you notice that the *turtle* is feeling *angry*. What would you infer about this information? What would you infer if, in exactly the same scenario, the *turtle* felt *happy*, or *confused*, or any other state with an affective stance? Chances are that the emotional information you came to be aware of would represent a trigger for you to reorient your attention [@andriessenSociocognitiveTensionCollaborative2011; @eligioEmotionUnderstandingPerformance2012; @posnerOrientingAttentionThen2014]. For instance, you can stop and think about the paragraph you have just written and ask yourself if anything in that paragraph could have elicited the affective state of your partner. Furthermore, independently that your action is the direct cause of *anger*, *happiness*, or *confusion* in your partner, the affective state of the *turtle* will probably influence the way she will behave [@vankleefEmergingViewEmotion2010; @vankleefInterpersonalDynamicsEmotion2018]. You may expect an *angry* partner to be less receptive, motivated or open to confrontation compared to an *happy* partner [@hareliWhatEmotionalReactions2010]. Or you may think your *confused* partner could benefit from an explanation or a pause to reassemble her thoughts [@dmelloConfusionCanBe2014]. If you are able and willing to take the *turtle*'s emotional state into account, then, you can modify the course of your actions in order to act upon the affective state of your partner [@reeckSocialRegulationEmotion2016; @schererComponentialEmotionTheory2007]. In the meantime, the very same affective state of your partner may represent a trigger for your own emotional state [@miceliMetaemotionsComplexityHuman2019; @vankleefEmergingViewEmotion2010]. For instance, the *confusion* of your partner may prompt you to feel *anger*, if you consider it to be unjustified; *surprise*, if you consider it unexpected; or *shame*, if you consider that the quality of your own contribution is undermined [@pekrunControlValueTheoryAchievement2006; @sanderAppraisalDrivenComponentialApproach2018; @schererWhatAreEmotions2005; @schorrAppraisalEvolutionIdea2001; @siemerSameSituationdifferentEmotions2007].

The dynamics illustrated in this example depends on a complex interaction of factors, with a potentially infinite combination of cognitive, social and affective outcomes that may determine what happens next between the *hippo* and the *turtle* [@andriessenSociocognitiveTensionCollaborative2011; @bakerAffectiveLearningTogether2013; @dmelloDynamicsAffectiveStates2012]. Nonetheless, if we consider the situation as prototypical of what may happen in distance learning, we can make abstraction of specific details about the *hippo*, the *turtle* and the paper they are writing and focus on the following assumptions.

First, learning elicits emotions, that is, short-term, affectively charged experiences that have consequences on learners' behavior. For instance, Pekrun

First, emotions play an intra-personal role that influence the organism [see among others @adolphsNeuroscienceEmotionNew2018; @broschImpactEmotionPerception2013; @levensonIntrapersonalFunctionsEmotion1999; @leventhalRelationshipEmotionCognition1987; @pessoaCognitiveemotionalBrainInteractions2013; @sanderAppraisalDrivenComponentialApproach2018; @schererDynamicArchitectureEmotion2009; @schererWhatAreEmotions2005; @frijdaEmotions1986; @schererEmotionProcessFunction1982; @adolphsInvestigatingEmotionsFunctional2018]. For instance, emotions are known to influence high-level cognitive functions such as perception, attention, memory and decision-making [@broschImpactEmotionPerception2013], which are all implicated in learning. A functional perspective on the intra-personal role of emotions is, for instance, posited by the Component Process Model theoretical framework [@sanderAppraisalDrivenComponentialApproach2018; @schererAppraisalConsideredProcess2001; @schererDynamicArchitectureEmotion2009] based upon the assumption that emotions have replaced reflexes to warrant a more flexible and adaptive response of the organism to the changing environment. A compatible perspective is also purported by neuroscience evidence identifying the functional role of emotions across species, independently of how emotions are *wired* into the organism [@adolphsInvestigatingEmotionsFunctional2018; @adolphsNeuroscienceEmotionNew2018]. Rather than positive or negative per se, emotions therefore represent functional or dysfunctional phenomena, that a person can either exploit to better adapt to a complex environment -- as the one represented by distance, technology enhanced learning -- or suffer if the emotional episode hinders the possibility to carry on the learning activity [*e.g.*, @brackettRULERTheoryDrivenSystemic2019; @dmelloConfusionCanBe2014; @dmelloSelectiveMetaanalysisRelative2013; @schererComponentialEmotionTheory2007; @siemerSameSituationdifferentEmotions2007].

Second, emotions play an inter-personal role in social interactions [see among others @butlerEmotionsAreTemporal2017; @fischerSocialFunctionsEmotion2016; @fischerWhereHaveAll2010; @keltnerSocialFunctionsEmotions1999; @parkinsonCurrentEmotionResearch2015; @rimeEmotionElicitsSocial2009; @vankleefInterpersonalDynamicsEmotion2018].

Fourth, learners involved in a computer-mediated, technology enhanced learning activity can benefit from cues about the presence of their colleagues and -- especially in a collaborative setting -- from a shared understanding of the situation at hand [see among others @molinariKnowledgeInterdependencePartner2009; @roschelleConstructionSharedKnowledge1995; @sanginFacilitatingPeerKnowledge2011; @suthersTechnologyAffordancesIntersubjective2006; @engelmannKnowledgeAwarenessCSCL2009; @kirschnerAwarenessCognitiveSocial2015; @kreijnsSocialAspectsCSCL2013; @janssenGroupAwarenessTools2011; @kreijnsIdentifyingPitfallsSocial2003; @dillenbourgEvolutionResearchComputersupported2009; @dillenbourgWhatYouMean1999; @janssenCoordinatedComputerSupportedCollaborative2013; @tuRelationshipSocialPresence2002].

(ref:thesis-scm-caption) The EAT determines how an intra-personal emotion becomes inter-personal, and how the inter-personal emotions contribute to improve the shared understanding of the situation at hand. The situation may then trigger other intra-personal emotions.

```{r intro-thesis-scm-model-figure, fig.cap="(ref:thesis-scm-caption)", fig.align="center", out.width="100%" }
include_graphics(here("figure/intro/thesis-scm-model.png"))
```

## Thesis Perspective

The thesis adopts primarily an affective science perspective implemented with a human-computer interaction approach. That is, the theoretical framework of reference will be mainly drawn from the inter-disciplinary field of affective science -- favoring the psychological perspective in case of *conflict* -- with the intent to implement these theories in a computational system (hopefully) adopted by users in a distance learning environment. Theories from learning and education sciences will be, thus, integrated as corollary, with a lesser involvement in critically evaluating or contributing to them (see next section). In other words, it is beyond the scope of the thesis to contribute in determining whether emotional awareness can lead to improving learning processes and, especially, outcomes. 

## Thesis Contributions {.unnumbered}

The overall purpose of the thesis can be divided in two intertwined objectives: one methodological, and one empirical.

### Methodological Contribution {.unnumbered}

From the methodological standpoint, the way emotional awareness is expressed and perceived is a pivotal element in determining to what extent it is possible to take full advantage from the use of an EAT. In other words, the EAT is not purely an auxiliary instrument [@meehlAppraisingAmendingTheories1990], but an integral part of the subject matter that requires careful assessment on its own [@buderGroupAwarenessTools2011; @janssenGroupAwarenessTools2011].

In previous works, I have outlined the basis for an emotion awareness tool, the Dynamic Emotion Wheel [DEW; @fritzDynamicEmotionWheel2015; @fritzDynamicEmotionWheel2016; @fritzProvidingEmotionalAwareness2017; @fritzReinventingWheelEmotional2015], derived from the Geneva Emotion Wheel [GEW; @schererGRIDMeetsWheel2013; @schererWhatAreEmotions2005], a widely adopted emotion self-report instrument built upon the Component Process Model theoretical framework [@sanderAppraisalDrivenComponentialApproach2018; @schererAppraisalConsideredProcess2001; @schererDynamicArchitectureEmotion2009]. The GEW (*op. cit*) comprises the graphical representation of a circumplex [@russellCircumplexModelAffect1980], in which the position of 20 subjective feelings (e.g. Joy, Relief, Shame or Anger) is determined by two orthogonal appraisal dimensions: valence, which determines to what extent the situation is pleasant or unpleasant, and control/power, which defines to what extent the situation can be acted upon by the person [@schererAppraisalConsideredProcess2001; @schererGRIDMeetsWheel2013]. As a consequence, users can point to one of the 20 subjective feelings, each of them varying according to a combination of positive or negative valence, and positive or negative control/power. The GEW hence combines the two most widely adopted emotion self-report techniques -- the dimensional and the discrete approaches -- by implementing an emotion structure into the tool [see also @schererWhatDeterminesFeeling2006], rather than presenting an arbitrary set of discrete natural language words or idioms with affective connotation [@schererWhatAreEmotions2005].

The DEW (*op. cit.*) is a web-based application that adopts the same logic, but uses the circumplex as an underlying affective space as a source from which retrieve the valence and control/power *coordinates* of each subjective feeling. At this point, the two appraisal dimensions can be used as active measures, for users to rate to what extent the situation is pleasant or unpleasant, and to what extent they can modify the current course of events. Based on the active appraisal of the affective dimensions, the DEW uses a parsimonious computational model to propose a subset of most likely subjective feelings to occur, given the rating of valence and control/power provided. The user can then decide whether one of the suggested subjective feelings corresponds to her conscious experience [@grandjeanConsciousEmotionalExperience2008], in which case she can click on a button labeled with the feeling, or provide another natural language word that better represents her current emotional state.

In the thesis, I present a generalization of the DEW underlying mechanism, which I implemented into a web-based platform, the Dynamic Emotion Wheel Research Toolbox (DEW-RT). The toolbox, that can be used on- and off-line, allows researchers in affective science and related fields, as well as practitioners in education who wants to implement an affective system in their course, to set up and configure the Dynamic Emotion Wheel for their own purpose. The toolbox presents the following main features.

*Self-Reported Emotions*. Contrary to other affective systems that use autonomic emotion recognition, the DEW-RT is built around the principle of self-reported emotions [@harleyMeasuringEmotionsSurvey2015; @mortillaroEmotionsMethodsAssessment2015; @schererWhatAreEmotions2005]. One the one hand, this choice implies cognitive and procedural efforts in order to express emotions [@harleyMeasuringEmotionsSurvey2015; @pashlerDualtaskInterferenceSimple1994], but, on the other, it also fosters a deeper implication of the person in the emotional experience. This view is consistent, for instance, with Boehenr and collaborators [-@boehnerHowEmotionMade2007], who advocate for an *interactional* approach to affective systems. According to this view, "the role of affective systems is not to transmit pre-existing emotional units, but to provide a resource for emotional meaning-making" (*ibid.*, p. 287).

*Theory-Driven*. Following Scherer's suggestion that an emotion self-report instrument should implement an emotion structure into the tool [@schererWhatAreEmotions2005], as the Geneva Emotion Wheel does, the DEW-RT abstacts the mechanism of sorting and sub-setting from two different structures of affective spaces: a circumplex and a Cartesian plane, which are both determined by two orthogonal affective dimensions. Even though recent evidence in the study of the structure of emotional meaning suggests that two dimensions are not enough to account for the wide variety of emotional experiences [@fontaineComponentsEmotionalMeaning2013; @fontaineWorldEmotionsNot2007], in an active, self-reporting context they may still represent a trade-off between accuracy and immediacy. In the circumplex structure [@russellCircumplexModelAffect1980], the feelings are positioned alongside a circle, with an equivalent radial distance from the center. In the Cartesian plane, feelings can be placed on any combination of *x* and *y* coordinates. In both cases, researchers and practitioners can chose among different underlying affective space, determined by other affective dimensions -- such as valence and arousal [@russellCircumplexModelAffect1980], or arousal and novelty [@gilliozMappingEmotionTerms2016] -- and comprising the kind and number of subjective feelings that best fit their theoretical or practical needs. Some affective spaces already exist or may be derived from the literature [e.g., @gilliozMappingEmotionTerms2016; @pekrunControlValueTheoryAchievement2006; @russellCircumplexModelAffect1980; @schererGRIDMeetsWheel2013], whereas others can be theoretically or empirically created for specific purposes [@fontaineWhyWhatHow2013; @schererCoreGRIDMiniGRIDDevelopment2013].

*Moment-to-Moment*[^1]. One of the identified drawbacks of emotion self-reporting in ongoing activities is that emotions are often expressed at fixed moment during the task, which is momentarily suspended [*e.g.*, @eligioEmotionUnderstandingPerformance2012; @harleyMeasuringEmotionsSurvey2015]. This procedure has two critical shortcomings. First, it may have disruptive consequences on the task itself, since the pause may occur in the middle of a critical situation. Second, it is not fully compatible with the temporal dimension of emotions. As emotions are limited in duration and elicited by a specific event in time, there is a loss of contextual meaning-making if emotions are self-reported with an imposed latency time. For instance, participants may report only the emotions they recall or *averaging* their emotional state over the elapsed segment. Due to its compact size and web-based nature, the DEW can be implemented alongside a wide varieties of technology enhanced activities, and even share the screen with them. As a consequence, users can express their emotions on a moment-to-moment basis [see @graesserEmotionsAdvancedLearning2014 for an overview and a list of further references], for the temporal dimension conveys meaningful and contextual information.

[^1]: In previous works (*op. cit.*) and possibly in some parts of the present contribution, I use the term *real-time*, but I reckon that the moment-to-moment perspective is more appropriate. In fact, self-reporting implies a latency time between the moment the emotional episode occurs and the time it takes to report it into the system. Even if the DEW tries to minimize this latency time, it is inaccurate to talk about *real-time*, which rather occurs in autonomic emotion recognition

*Graphical representations of emotions*. Whereas a self-report instrument is concerned only by the expressing-displaying function, an awareness tool also implements the perceiving-monitoring function, through which the information is made available to others [@buderGroupAwarenessTools2011; @schmidtProblemAwareness2002]. In computer-mediated communication, emotions can be conveyed through a variety of media including written words, emoticons, avatars, *memes*, artworks and sounds [for an overview, see among others @bersetVisualisationDonneesRecherche2018; @blundenEmoticonAreThere2020; @chenEmpatheticonsDesigningEmotion2014; @derksRoleEmotionComputermediated2008; @gliksonDarkSideSmiley2018; @leonyProvisionAwarenessLearners2013]. The DEW-RT allows researchers to chose between a -- limited, for the time being [@bersetVisualisationDonneesRecherche2018; @fritzRealTimeEmotionalAwareness2016] -- set of graphical representations [@hegartyCognitiveScienceVisualspatial2011], both individual and collective.

*Open Science principles*. The last decade has been characterized by rising concerns about replication of findings in social sciences, and psychology in particular, in what is generally referred to as the replication crisis [*e.g.*, @anvariReplicabilityCrisisPublic2019; @fritzOverviewReplicationCrisis2019; @opensciencecollaborationEstimatingReproducibilityPsychological2015; @schmidtShallWeReally2009]. Solutions to increase the reproducibility and replication of scientific results, usually grouped under the umbrella term of *Open Science*, have been proposed at various stages of the research process including: the need for better substantive theories from which to draw hypothesis; clearer definition of and discrimination between concepts; the validation of instruments and experimental material; the justification of the sample size; the pre-registration of research hypothesis, protocols and planned data analyses; the full disclosure of unprocessed data and the computational steps implicated in obtaining results; more transparency in the reviewing and publication processes; and open access to scientific knowledge [see among others @chambersSevenDeadlySins2017; @cruwellSevenEasySteps2019; @fergusonVastGraveyardUndead2012; @fiedlerCycleTheoryFormation2004; @lowndesOurPathBetter2017; @mayoPValuesTrialSelective2020; @moreyPeerReviewersOpenness2016; @Nosek1422; @scheelWhyHypothesisTesters2020; @simmons21WordSolution2012]. In an effort to comply to some of these principles, the DEW-RT is programmed in such a way that configuration of affective spaces and studies can be exported and shared with other researchers or practitioners, who can then reproduce exactly the same conditions.

### Empirical Contribution {.unnumbered}

The methodological intent of the DEW-RT is to provide a multipurpose EAT that can be adapted to different needs and purposes, but at the same time maintain a tight relationship with an underlying emotional structure. From an empirical standpoint, it is therefore worth investigating to what extent users can take full advantage of the main features illustrated in the previous section in an applied context. To this intent, the present contribution aims at assessing and comparing the adoption, use and perception of an EAT in two prototypical situations in distance, technology enhanced learning.

The first situation is synchronous and collaborative, and relates to the interdisciplinary field of Computer-Supported Collaborative Learning [CSCL; see @dillenbourgEvolutionResearchComputersupported2009; @dillenbourgWhatYouMean1999; @stahlComputersupportedCollaborativeLearning2006; @suthersTechnologyAffordancesIntersubjective2006 for an overview]. There is in fact a wide consensus in this field in considering that one of the main determinants of fruitful collaborative learning resides in the effort that learners put in building and updating a holistic representation of their partners, which is instrumental to a shared understanding of the task at hand [*e.g.*, @dillenbourgSymmetryPartnerModelling2016; @kreijnsIdentifyingPitfallsSocial2003; @roschelleConstructionSharedKnowledge1995; @sanginFacilitatingPeerKnowledge2011; @buderGroupAwarenessTools2011 and @janssenCoordinatedComputerSupportedCollaborative2013].

The second situation, by contrast, is asynchronous and individual, and relates to one of the greatest challenges in distance learning: provide learners with a social presence in the learning environment. In fact, one of the identified pitfalls in distance learning is that students are isolated and have limited contact with their peers. In this respect, technology enhanced learning represents a resource to contribute in solving the problem, but also a danger in aggravating it. On the one hand, technology can be used to alleviate the sentiment of lonliness by providing learners with perceptible cues in the environment about their colleagues. On the other hand, the increasing complexity and potential of learning technologies may also force learners in focusing on the individual task they are performing.

On the other hand, though, every assessment is done on some values or criterion of demarcation, which force to take position towards the subject at hand. Henceforth, I provide a general assumption, which drives and underlies the overall empirical objective of the thesis. I posit that an EAT serves as an affordance for learners to socially share their emotions in order to build. In more concrete words, that may translate in the following example:

*Jane is prompted, by the presence of the EAT in her technology enhanced learning environment, to share her emotions with her colleague Paul because this information helps Paul to build and maintain a more accurate shared understanding of the situation at hand, which he can harness for his own activity. For the same reason, Jane is prompted to monitor and take into account Paul's emotions as instrumental information for her own activity*.

## Preliminary Definition and Clarification about Main Concepts

Considering the multi- and inter-disciplinary perspective of the thesis, it is useful to provide preliminary definition of the main and recurrent concepts, as they are used throughout the text, and whose interpretation may vary according to the field of reference. These preliminary definitions will be further developed in the reminder of the text, especially in the next chapter, but presenting them earlier will also, hopefully, help readers with a clarification of how these terms are used in the thesis. 

**Affect** refers to a *flexible* container of internal mental states including emotion, moods, attitudes, interpersonal stances, preferences, feelings, and others [@frijdaAffectPsychologicalPerspectives2009; @colombettiFeelingBodyAffective2014]. Frijda and Scherer [-@frijdaAffectPsychologicalPerspectives2009, p.10] posit that "[t]he term *affect* and the corresponding adjective *affective* are generally used in an overarching generic sense for a mental state that is characterized by emotional feeling as compared with rational thinking" (italic in the text). From a complementary point of view, Colombetti [-@colombettiFeelingBodyAffective2014, p. 19] defines *affectivity* as "a *lack of indifference*, and rather a *sensibility* or *interest* for one's existence" (italic in the text). Throughout the text, an effort will be made to (1) respect authors original labeling of affective phenomena, and (2) maintain consistency between affect-related terms. Occasionally, though, declination of *affect*, such as *affective state* or *affective episode* may be used as a synonym of *emotion* (see below). Hopefully, in these cases, it would be clear from the context when those terms are used as synonymous because the distinction, in that precise passage of the text, is not of crucial importance for theoretical understanding or positioning. 

**Awareness** often relates to the phenomenon by which someone *notices* something, which may happen at various levels, from pre-conscious to fully processed. In the context of the thesis, the term will always refer to a fully conscious state [@gazzanigaConsciousnessInstinctUnraveling2019], with nevertheless some ambiguity on the level of processing, which may become clearer according to the context. Furthermore, a distinction will be drawn between **self-awareness**, used to denote the conscious experience of one's own mental states, and **group-awareness** (for two or more people), which more closely relates to how the term awareness is used in computer-mediated environment. In fact, Dourish and Belotti [-@dourishAwarenessCoordinationShared1992, p. 1] define (group-)awareness as "an *understanding of the activities of others*, which provides a *context for your own activity*" (italic in the text). When the distinction between self- and group-awareness is not explicit, a combination of the two is to be intended, that is, the fact of one becoming aware of information about oneself (self-awareness) and/or others (group-awareness).

**Emotion**'s definition is a crucial element of the theory-driven perspective adopted for the implementation of the EAT and, thus, is discussed at length in the next chapter. At this point, it is sufficient -- but pivotal -- to retain that *emotion* throughout the text will be used consistently to refer to a specific affective phenomena, distinguished from *general* affect (see above) or other affective phenomena such as moods or preferences. An important distinction will be made and maintained between *emotion*, *feeling* and *subjective feeling*, which will never be used as synonyms nor interchanged. Emotion refers to a bounded, unfolding phenomenon that comprises different components illustrated later in the text. One of this component is the feeling, which relates to the philosophical concept of *qualia*, that is, something difficult or impossible to fully define. The subjective feeling is the *best attempt* to define the *feeling-qualia*. This nomenclature is consistent with the main theoretical model ultimately adopted by the thesis [@grandjeanConsciousEmotionalExperience2008; @schererWhatAreEmotions2005; @schererDynamicArchitectureEmotion2009a], which will be discussed at length -- and compared with others -- in the next chapter.  

**Emotion Awareness Tool (EAT)** will be a persistent acronym used in the text. In this regard, a pivotal part of the thesis is the implementation of a multipurpose EAT, that is, a specific EAT -- named the Dynamic Emotion Wheel (DEW) -- that has nevertheless the vocation to provide prototypical functions of an EAT. For this reason, the acronym EAT will be used in prevalence, unless the text refers specifically to a particular feature of the DEW.  

## Thesis Outline {.unnumbered}

In which I set forth the organization of the manuscript.

## Data and Code in Open Access {.unnumbered}

In which I provide the link to the repository containing all the data and code used to analyze the results.
